{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unexpected-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from inltk.inltk import tokenize\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import sys\n",
    "import time\n",
    "from inltk.inltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trained-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~।]'''\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return [tok for tok in spacy_eng.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latest-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = data.Field(tokenize=tokenize_hi)\n",
    "english = data.Field(tokenize=tokenize_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "orange-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for hindi.build_vocab was 2.9937100410461426\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))\n",
    "hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "english.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "\n",
    "print(f'Total time taken for hindi.build_vocab was {time.time() - st}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-monkey",
   "metadata": {},
   "source": [
    "### Total time taken for hindi.build_vocab was 2783.8125097751617\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fifth-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('hindi_vocab_1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(hindi, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('english_vocab_1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(english, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('hindi_vocab.pickle', 'rb') as handle:\n",
    "#     hindi = pickle.load(handle)\n",
    "\n",
    "# with open('english_vocab.pickle', 'rb') as handle:\n",
    "#     english = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "necessary-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "enabling-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input_size_encoder is 120\n",
      "length of input_size_decoder is 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "# num_epochs = 100\n",
    "learning_rate = 3e-4\n",
    "# batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0\n",
    "\n",
    "print(f'length of input_size_encoder is {input_size_encoder}')\n",
    "\n",
    "print(f'length of input_size_decoder is {input_size_decoder}')\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "model_file_name = \"checkpoint_attn_v2.pth.tar\"\n",
    "\n",
    "# train_iterator = data.BucketIterator(\n",
    "#      dataset=mt_train, batch_size=batch_size,\n",
    "#      sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesbian-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk_ext/nlp/seq2seq_attention\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "removed-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([12689, 300]) from checkpoint, the shape in current model is torch.Size([12668, 300]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([13005, 300]) from checkpoint, the shape in current model is torch.Size([15002, 300]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([13005, 1024]) from checkpoint, the shape in current model is torch.Size([15002, 1024]).\n\tsize mismatch for decoder.fc.bias: copying a param with shape torch.Size([13005]) from checkpoint, the shape in current model is torch.Size([15002]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-709e44950e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msave_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_checkpoint.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-5e990c3fd6f7>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint, model, optimizer)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Loading checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([12689, 300]) from checkpoint, the shape in current model is torch.Size([12668, 300]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([13005, 300]) from checkpoint, the shape in current model is torch.Size([15002, 300]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([13005, 1024]) from checkpoint, the shape in current model is torch.Size([15002, 1024]).\n\tsize mismatch for decoder.fc.bias: copying a param with shape torch.Size([13005]) from checkpoint, the shape in current model is torch.Size([15002])."
     ]
    }
   ],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "# if load_model:\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "load_checkpoint(torch.load(model_file_name), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-blues",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "#     spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "#         tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "        tokens = [i.lower() for i in tokenize(sentence, \"hi\")]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in tqdm(data):\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=model_file_name):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atmospheric-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electoral-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_torch/pmindia.v1.hi-en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['english_sentence', 'hindi_sentence'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "devoted-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " अग्रिम धन राशि इन अस्पतालों को चिकित्सा निरीक्षकों को दी जाएगी, जो हर मामले को देखते हुए सहायता प्रदान करेंगे। \n",
      " and translated_sent is \n",
      "resources is spreading to <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][0]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "earlier-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " इस तरह आरएएन का कामकाज स्वास्थ्य एवं परिवार कल्याण विभाग के अधीन लाया जाएगा। \n",
      " and translated_sent is \n",
      "to provide the up of this health and family welfare with <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][2]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "modern-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " इस प्रकार एक स्वायशासी निकाय के रूप में जेएसके को बंद किया जा सकता है क्योंकि निधि के तौर पर उसका कामकाज विभाग द्वारा संभव है। \n",
      " and translated_sent is \n",
      "as a result is to be utilized as it can be administered by the department as a fund possible can be <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][10]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "expensive-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " महारानी मैक्सिमा ने इन कदमों के जरिए हुई प्रगति की सराहना की। \n",
      " and translated_sent is \n",
      "ceos appreciated the progress made by these initiatives through these progress achieved made in these initiatives these initiatives made by these initiatives from ‘ <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][16]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intelligent-delicious",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " प्रधान मंत्री ने कहा कि 16वीं लोकसभा में करीब 315 पहली बार सांसद चुनकर आए हैं, जो पहली लोकसभा के समान है । \n",
      " and translated_sent is \n",
      "on the same the prime minister said that the sixteenth lok sabha was comparable to the <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][20]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "respective-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " उन्होंने कहा कि इस कार्य को 2022 तक पूरा कर लेने का लक्ष्य है। \n",
      " and translated_sent is \n",
      "that the aim is to achieving this task by 2022 out this target to by 2022 out this target is by 2022 out this target is by 2022 out this target is by 2022 objectives of this purpose by 2022 this is by 2022 objectives of this purpose by 2022\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][40]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "simple-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " सेना ने हमेशा देश को प्राथमिकता दी है। \n",
      " and translated_sent is \n",
      "nations the nation the country given the country to accorded to the nation and the nation is affordable youth country country has accorded the nation ’s priority ” the nation nation priority ” the country ’s priority on priority ” the nation nation its priority on priority ” the nation\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][80]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "searching-limit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " भारत की उत्सव परम्परा, प्रकृति-प्रेम को बलवान बनाने वाली, बालक से लेकर के हर व्यक्ति को संस्कारित करने वाली रही है। \n",
      " and translated_sent is \n",
      "if india ’s land is a <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][1100]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "metallic-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " परस्पर सहयोग के लिए दिमाग में कुछ विचार आए हैं, जिसे मैं यहां साझा कर रहा हूं। \n",
      " and translated_sent is \n",
      "possible here with a <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][10000]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "emotional-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " और अगर वो नहीं हुआ तो कहते हैं कि रिफॉर्म नहीं हुआ। \n",
      " and translated_sent is \n",
      "if you n’t n’t have enough then do n’t have <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][3000]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "honey-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_val', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(data, model, german, english, device):\n",
    "#     targets = []\n",
    "#     outputs = []\n",
    "    all_scores = []\n",
    "    for example in tqdm(data):\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        \n",
    "#         targets.append([trg])\n",
    "#         outputs.append(prediction)\n",
    "        \n",
    "        try:\n",
    "#             score = bleu_score([prediction], [trg], max_n=2)\n",
    "#             score = sentence_bleu(prediction, trg)\n",
    "#             all_scores.append(score)\n",
    "#             if score>0:\n",
    "            print(f'trg is {trg}')\n",
    "            print(f'prediction is {prediction}')\n",
    "            print(f'score is {score}')\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "#             print(f'Exception is {e}')\n",
    "#             print(f'trg is {trg}')\n",
    "#             print(f'prediction is {prediction}')\n",
    "            pass\n",
    "\n",
    "    return (all_scores, sum(all_scores)/len(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-radical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bleu(mt_test, model, hindi, english, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "owned-peter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prime',\n",
       " 'minister',\n",
       " 'said',\n",
       " 'the',\n",
       " 'union',\n",
       " 'government',\n",
       " 'is',\n",
       " 'working',\n",
       " 'focusing',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'infrastructure',\n",
       " 'augmentation',\n",
       " 'and',\n",
       " 'it',\n",
       " 'requires',\n",
       " 'is',\n",
       " 'focus',\n",
       " 'infrastructure',\n",
       " 'development',\n",
       " 'deficit',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = ['prime', 'minister', 'said', 'the', 'union', 'government', 'is', 'working', 'focusing', 'focusing', 'on', 'infrastructure', 'augmentation', 'and', 'it', 'requires', 'is', 'focus', 'infrastructure', 'development', 'deficit', '<unk>']\n",
    "# sent1 =  ' '.join(sent1)\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "diagnostic-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = ['the', 'union', 'government', 'of', 'india', 'infrastructure', 'is', 'focusing', 'focused', 'on', 'focusing', 'on', 'infrastructure', 'technology', 'and', 'real', 'structure', 'with', 'speed', 'targets', 'being', 'infrastructure', 'is', 'focusing', 'on', '<unk>']\n",
    "# sent2 =  ' '.join(sent2)\n",
    "# sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "trying-intake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.384292958842266e-231"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(['my','name','is','mohit' ], ['i', 'am','mohit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "conditional-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2882297539194154e-231\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this', 'is' 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "requested-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964276313782"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]\n",
    "bleu_score(candidate_corpus, references_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fresh-bible",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁प्रधानमंत्री',\n",
       " '▁ने',\n",
       " '▁कहा',\n",
       " '▁कि',\n",
       " '▁भारत',\n",
       " '▁में',\n",
       " '▁केंद्र',\n",
       " '▁सरकार',\n",
       " '▁बुनियादी',\n",
       " '▁ढांचे',\n",
       " '▁पर',\n",
       " '▁ध्यान',\n",
       " '▁केंद्रित',\n",
       " '▁कर',\n",
       " '▁रही',\n",
       " '▁है']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_hi('प्रधानमंत्री ने कहा कि भारत में केंद्र सरकार बुनियादी ढांचे पर ध्यान केंद्रित कर रही है।')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "forward-deposit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/1000 [00:00<01:46,  9.41it/s]\u001b[A\n",
      "  0%|          | 4/1000 [00:00<01:29, 11.13it/s]\u001b[A\n",
      "  0%|          | 5/1000 [00:00<02:09,  7.67it/s]\u001b[A\n",
      "  1%|          | 6/1000 [00:00<02:11,  7.59it/s]\u001b[A\n",
      "  1%|          | 8/1000 [00:00<02:07,  7.77it/s]\u001b[A\n",
      "  1%|          | 10/1000 [00:01<01:45,  9.38it/s]\u001b[A\n",
      "  1%|▏         | 14/1000 [00:01<01:22, 11.96it/s]\u001b[A\n",
      "  2%|▏         | 16/1000 [00:01<01:39,  9.92it/s]\u001b[A\n",
      "  2%|▏         | 18/1000 [00:01<01:29, 11.01it/s]\u001b[A\n",
      "  2%|▏         | 20/1000 [00:01<01:26, 11.31it/s]\u001b[A\n",
      "  2%|▏         | 22/1000 [00:01<01:21, 11.96it/s]\u001b[A\n",
      "  2%|▏         | 24/1000 [00:02<01:38,  9.90it/s]\u001b[A\n",
      "  3%|▎         | 26/1000 [00:02<01:48,  8.98it/s]\u001b[A\n",
      "  3%|▎         | 28/1000 [00:02<01:57,  8.25it/s]\u001b[A\n",
      "  3%|▎         | 30/1000 [00:02<01:38,  9.88it/s]\u001b[A\n",
      "  3%|▎         | 32/1000 [00:02<01:23, 11.57it/s]\u001b[A\n",
      "  4%|▎         | 35/1000 [00:03<01:11, 13.45it/s]\u001b[A\n",
      "  4%|▎         | 37/1000 [00:03<01:17, 12.39it/s]\u001b[A\n",
      "  4%|▍         | 39/1000 [00:03<01:08, 13.95it/s]\u001b[A\n",
      "  4%|▍         | 42/1000 [00:03<01:00, 15.96it/s]\u001b[A\n",
      "  4%|▍         | 44/1000 [00:03<01:01, 15.62it/s]\u001b[A\n",
      "  5%|▍         | 47/1000 [00:03<01:11, 13.42it/s]\u001b[A\n",
      "  5%|▍         | 49/1000 [00:04<01:23, 11.42it/s]\u001b[A\n",
      "  5%|▌         | 51/1000 [00:04<01:40,  9.41it/s]\u001b[A\n",
      "  5%|▌         | 53/1000 [00:04<01:49,  8.64it/s]\u001b[A\n",
      "  6%|▌         | 55/1000 [00:04<01:53,  8.29it/s]\u001b[A\n",
      "  6%|▌         | 56/1000 [00:05<02:27,  6.41it/s]\u001b[A\n",
      "  6%|▌         | 58/1000 [00:05<02:24,  6.51it/s]\u001b[A\n",
      "  6%|▌         | 61/1000 [00:05<02:01,  7.73it/s]\u001b[A\n",
      "  6%|▌         | 62/1000 [00:05<02:08,  7.31it/s]\u001b[A\n",
      "  6%|▋         | 65/1000 [00:06<01:52,  8.29it/s]\u001b[A\n",
      "  7%|▋         | 66/1000 [00:06<01:54,  8.19it/s]\u001b[A\n",
      "  7%|▋         | 67/1000 [00:06<02:22,  6.54it/s]\u001b[A\n",
      "  7%|▋         | 70/1000 [00:06<01:49,  8.49it/s]\u001b[A\n",
      "  7%|▋         | 72/1000 [00:06<01:56,  7.96it/s]\u001b[A\n",
      "  7%|▋         | 74/1000 [00:07<02:01,  7.64it/s]\u001b[A\n",
      "  8%|▊         | 76/1000 [00:07<02:05,  7.37it/s]\u001b[A\n",
      "  8%|▊         | 77/1000 [00:07<02:13,  6.89it/s]\u001b[A\n",
      "  8%|▊         | 80/1000 [00:07<01:46,  8.67it/s]\u001b[A\n",
      "  8%|▊         | 82/1000 [00:08<01:46,  8.60it/s]\u001b[A\n",
      "  8%|▊         | 84/1000 [00:08<01:42,  8.96it/s]\u001b[A\n",
      "  9%|▊         | 86/1000 [00:08<02:00,  7.56it/s]\u001b[A\n",
      "  9%|▊         | 87/1000 [00:08<02:08,  7.13it/s]\u001b[A\n",
      "  9%|▉         | 90/1000 [00:08<01:42,  8.88it/s]\u001b[A\n",
      "  9%|▉         | 92/1000 [00:09<01:29, 10.10it/s]\u001b[A\n",
      "  9%|▉         | 94/1000 [00:09<01:27, 10.34it/s]\u001b[A\n",
      " 10%|▉         | 98/1000 [00:09<01:07, 13.29it/s]\u001b[A\n",
      " 10%|█         | 101/1000 [00:09<00:59, 15.22it/s]\u001b[A\n",
      " 10%|█         | 105/1000 [00:09<00:54, 16.31it/s]\u001b[A\n",
      " 11%|█         | 108/1000 [00:09<00:58, 15.35it/s]\u001b[A\n",
      " 11%|█         | 111/1000 [00:10<00:58, 15.25it/s]\u001b[A\n",
      " 12%|█▏        | 115/1000 [00:10<00:49, 17.74it/s]\u001b[A\n",
      " 12%|█▏        | 118/1000 [00:10<01:01, 14.28it/s]\u001b[A\n",
      " 12%|█▏        | 120/1000 [00:10<01:19, 11.11it/s]\u001b[A\n",
      " 12%|█▏        | 122/1000 [00:11<01:29,  9.82it/s]\u001b[A\n",
      " 12%|█▏        | 124/1000 [00:11<01:30,  9.70it/s]\u001b[A\n",
      " 13%|█▎        | 128/1000 [00:11<01:23, 10.49it/s]\u001b[A\n",
      " 13%|█▎        | 130/1000 [00:11<01:19, 10.94it/s]\u001b[A\n",
      " 13%|█▎        | 133/1000 [00:12<01:20, 10.81it/s]\u001b[A\n",
      " 14%|█▎        | 135/1000 [00:12<01:09, 12.43it/s]\u001b[A\n",
      " 14%|█▎        | 137/1000 [00:12<01:02, 13.76it/s]\u001b[A\n",
      " 14%|█▍        | 139/1000 [00:12<01:21, 10.51it/s]\u001b[A\n",
      " 14%|█▍        | 141/1000 [00:12<01:15, 11.40it/s]\u001b[A\n",
      " 14%|█▍        | 143/1000 [00:12<01:32,  9.23it/s]\u001b[A\n",
      " 14%|█▍        | 145/1000 [00:13<01:26,  9.91it/s]\u001b[A\n",
      " 15%|█▍        | 149/1000 [00:13<01:09, 12.22it/s]\u001b[A\n",
      " 15%|█▌        | 151/1000 [00:13<01:41,  8.33it/s]\u001b[A\n",
      " 15%|█▌        | 153/1000 [00:13<01:32,  9.12it/s]\u001b[A\n",
      " 16%|█▌        | 155/1000 [00:14<01:35,  8.83it/s]\u001b[A\n",
      " 16%|█▌        | 157/1000 [00:14<01:30,  9.30it/s]\u001b[A\n",
      " 16%|█▌        | 160/1000 [00:14<01:11, 11.70it/s]\u001b[A\n",
      " 16%|█▌        | 162/1000 [00:14<01:09, 12.02it/s]\u001b[A\n",
      " 16%|█▋        | 164/1000 [00:14<01:16, 10.93it/s]\u001b[A\n",
      " 17%|█▋        | 167/1000 [00:15<01:11, 11.69it/s]\u001b[A\n",
      " 17%|█▋        | 170/1000 [00:15<00:59, 13.91it/s]\u001b[A\n",
      " 17%|█▋        | 174/1000 [00:15<01:00, 13.62it/s]\u001b[A\n",
      " 18%|█▊        | 178/1000 [00:15<00:59, 13.74it/s]\u001b[A\n",
      " 18%|█▊        | 180/1000 [00:15<01:01, 13.24it/s]\u001b[A\n",
      " 18%|█▊        | 182/1000 [00:16<01:35,  8.56it/s]\u001b[A\n",
      " 18%|█▊        | 185/1000 [00:16<01:21,  9.96it/s]\u001b[A\n",
      " 19%|█▉        | 188/1000 [00:16<01:07, 11.99it/s]\u001b[A\n",
      " 19%|█▉        | 191/1000 [00:16<01:13, 10.99it/s]\u001b[A\n",
      " 19%|█▉        | 194/1000 [00:17<01:01, 13.04it/s]\u001b[A\n",
      " 20%|█▉        | 196/1000 [00:17<01:37,  8.29it/s]\u001b[A\n",
      " 20%|█▉        | 198/1000 [00:17<01:24,  9.53it/s]\u001b[A\n",
      " 20%|██        | 202/1000 [00:17<01:05, 12.23it/s]\u001b[A\n",
      " 20%|██        | 205/1000 [00:18<01:29,  8.87it/s]\u001b[A\n",
      " 21%|██        | 207/1000 [00:18<01:17, 10.30it/s]\u001b[A\n",
      " 21%|██        | 209/1000 [00:18<01:28,  8.89it/s]\u001b[A\n",
      " 21%|██        | 212/1000 [00:18<01:13, 10.70it/s]\u001b[A\n",
      " 21%|██▏       | 214/1000 [00:19<01:05, 11.97it/s]\u001b[A\n",
      " 22%|██▏       | 216/1000 [00:19<01:32,  8.52it/s]\u001b[A\n",
      " 22%|██▏       | 218/1000 [00:19<01:54,  6.81it/s]\u001b[A\n",
      " 22%|██▏       | 220/1000 [00:19<01:38,  7.93it/s]\u001b[A\n",
      " 22%|██▏       | 222/1000 [00:20<01:58,  6.56it/s]\u001b[A\n",
      " 22%|██▏       | 224/1000 [00:20<01:42,  7.58it/s]\u001b[A\n",
      " 23%|██▎       | 226/1000 [00:20<01:49,  7.05it/s]\u001b[A\n",
      " 23%|██▎       | 227/1000 [00:21<01:47,  7.22it/s]\u001b[A\n",
      " 23%|██▎       | 229/1000 [00:21<01:36,  8.01it/s]\u001b[A\n",
      " 23%|██▎       | 233/1000 [00:21<01:25,  8.98it/s]\u001b[A\n",
      " 24%|██▎       | 235/1000 [00:21<01:26,  8.88it/s]\u001b[A\n",
      " 24%|██▎       | 237/1000 [00:22<01:35,  7.99it/s]\u001b[A\n",
      " 24%|██▍       | 239/1000 [00:22<01:38,  7.72it/s]\u001b[A\n",
      " 24%|██▍       | 241/1000 [00:22<01:25,  8.89it/s]\u001b[A\n",
      " 24%|██▍       | 242/1000 [00:22<01:52,  6.75it/s]\u001b[A\n",
      " 24%|██▍       | 245/1000 [00:23<01:40,  7.49it/s]\u001b[A\n",
      " 25%|██▍       | 246/1000 [00:23<02:13,  5.65it/s]\u001b[A\n",
      " 25%|██▍       | 247/1000 [00:23<02:04,  6.07it/s]\u001b[A\n",
      " 25%|██▍       | 248/1000 [00:23<01:59,  6.30it/s]\u001b[A\n",
      " 25%|██▍       | 249/1000 [00:23<02:12,  5.66it/s]\u001b[A\n",
      " 25%|██▌       | 250/1000 [00:23<02:04,  6.05it/s]\u001b[A\n",
      " 25%|██▌       | 251/1000 [00:24<02:11,  5.70it/s]\u001b[A\n",
      " 25%|██▌       | 253/1000 [00:24<02:07,  5.88it/s]\u001b[A\n",
      " 25%|██▌       | 254/1000 [00:24<02:23,  5.21it/s]\u001b[A\n",
      " 26%|██▌       | 256/1000 [00:24<02:00,  6.19it/s]\u001b[A\n",
      " 26%|██▌       | 257/1000 [00:25<02:17,  5.41it/s]\u001b[A\n",
      " 26%|██▌       | 258/1000 [00:25<01:58,  6.24it/s]\u001b[A\n",
      " 26%|██▌       | 259/1000 [00:25<02:11,  5.62it/s]\u001b[A\n",
      " 26%|██▌       | 260/1000 [00:25<02:31,  4.89it/s]\u001b[A\n",
      " 26%|██▌       | 262/1000 [00:26<02:19,  5.30it/s]\u001b[A\n",
      " 26%|██▋       | 263/1000 [00:26<02:05,  5.86it/s]\u001b[A\n",
      " 26%|██▋       | 265/1000 [00:26<01:41,  7.27it/s]\u001b[A\n",
      " 27%|██▋       | 268/1000 [00:26<01:19,  9.25it/s]\u001b[A\n",
      " 27%|██▋       | 270/1000 [00:26<01:34,  7.76it/s]\u001b[A\n",
      " 27%|██▋       | 274/1000 [00:27<01:22,  8.75it/s]\u001b[A\n",
      " 28%|██▊       | 276/1000 [00:27<01:25,  8.45it/s]\u001b[A\n",
      " 28%|██▊       | 282/1000 [00:27<01:04, 11.17it/s]\u001b[A\n",
      " 28%|██▊       | 285/1000 [00:27<00:53, 13.48it/s]\u001b[A\n",
      " 29%|██▉       | 288/1000 [00:27<00:46, 15.25it/s]\u001b[A\n",
      " 29%|██▉       | 292/1000 [00:27<00:43, 16.09it/s]\u001b[A\n",
      " 30%|██▉       | 295/1000 [00:28<00:42, 16.65it/s]\u001b[A\n",
      " 30%|██▉       | 298/1000 [00:28<00:38, 18.31it/s]\u001b[A\n",
      " 30%|███       | 301/1000 [00:28<00:46, 15.13it/s]\u001b[A\n",
      " 30%|███       | 303/1000 [00:28<00:48, 14.43it/s]\u001b[A\n",
      " 31%|███       | 306/1000 [00:28<00:50, 13.80it/s]\u001b[A\n",
      " 31%|███       | 309/1000 [00:29<00:57, 12.01it/s]\u001b[A\n",
      " 31%|███       | 311/1000 [00:29<01:10,  9.80it/s]\u001b[A\n",
      " 31%|███▏      | 313/1000 [00:29<01:19,  8.63it/s]\u001b[A\n",
      " 32%|███▏      | 315/1000 [00:29<01:13,  9.31it/s]\u001b[A\n",
      " 32%|███▏      | 317/1000 [00:30<01:42,  6.66it/s]\u001b[A\n",
      " 32%|███▏      | 320/1000 [00:30<01:18,  8.63it/s]\u001b[A\n",
      " 32%|███▏      | 322/1000 [00:30<01:12,  9.35it/s]\u001b[A\n",
      " 32%|███▏      | 324/1000 [00:30<01:04, 10.51it/s]\u001b[A\n",
      " 33%|███▎      | 326/1000 [00:31<01:14,  9.10it/s]\u001b[A\n",
      " 33%|███▎      | 328/1000 [00:31<01:17,  8.69it/s]\u001b[A\n",
      " 33%|███▎      | 330/1000 [00:31<01:15,  8.92it/s]\u001b[A\n",
      " 33%|███▎      | 332/1000 [00:32<01:37,  6.86it/s]\u001b[A\n",
      " 33%|███▎      | 334/1000 [00:32<01:37,  6.82it/s]\u001b[A\n",
      " 34%|███▎      | 335/1000 [00:32<01:52,  5.89it/s]\u001b[A\n",
      " 34%|███▎      | 337/1000 [00:32<01:30,  7.30it/s]\u001b[A\n",
      " 34%|███▍      | 338/1000 [00:32<01:46,  6.22it/s]\u001b[A\n",
      " 34%|███▍      | 339/1000 [00:33<01:58,  5.56it/s]\u001b[A\n",
      " 34%|███▍      | 341/1000 [00:33<01:48,  6.05it/s]\u001b[A\n",
      " 34%|███▍      | 342/1000 [00:33<02:05,  5.25it/s]\u001b[A\n",
      " 34%|███▍      | 343/1000 [00:33<02:14,  4.88it/s]\u001b[A\n",
      " 34%|███▍      | 345/1000 [00:34<01:43,  6.31it/s]\u001b[A\n",
      " 35%|███▍      | 346/1000 [00:34<02:00,  5.43it/s]\u001b[A\n",
      " 35%|███▍      | 347/1000 [00:34<01:47,  6.09it/s]\u001b[A\n",
      " 35%|███▍      | 349/1000 [00:34<01:41,  6.41it/s]\u001b[A\n",
      " 35%|███▌      | 351/1000 [00:34<01:27,  7.43it/s]\u001b[A\n",
      " 35%|███▌      | 352/1000 [00:34<01:28,  7.35it/s]\u001b[A\n",
      " 35%|███▌      | 353/1000 [00:35<01:46,  6.09it/s]\u001b[A\n",
      " 35%|███▌      | 354/1000 [00:35<01:54,  5.64it/s]\u001b[A\n",
      " 36%|███▌      | 355/1000 [00:35<02:05,  5.14it/s]\u001b[A\n",
      " 36%|███▌      | 358/1000 [00:35<01:45,  6.09it/s]\u001b[A\n",
      " 36%|███▌      | 359/1000 [00:36<01:34,  6.77it/s]\u001b[A\n",
      " 36%|███▌      | 361/1000 [00:36<01:26,  7.36it/s]\u001b[A\n",
      " 36%|███▌      | 362/1000 [00:36<01:46,  6.01it/s]\u001b[A\n",
      " 36%|███▋      | 363/1000 [00:36<01:58,  5.35it/s]\u001b[A\n",
      " 36%|███▋      | 364/1000 [00:36<01:57,  5.41it/s]\u001b[A\n",
      " 36%|███▋      | 365/1000 [00:37<01:45,  6.03it/s]\u001b[A\n",
      " 37%|███▋      | 368/1000 [00:37<01:30,  6.98it/s]\u001b[A\n",
      " 37%|███▋      | 372/1000 [00:37<01:17,  8.07it/s]\u001b[A\n",
      " 37%|███▋      | 374/1000 [00:37<01:05,  9.55it/s]\u001b[A\n",
      " 38%|███▊      | 376/1000 [00:38<01:15,  8.30it/s]\u001b[A\n",
      " 38%|███▊      | 378/1000 [00:38<01:03,  9.75it/s]\u001b[A\n",
      " 38%|███▊      | 381/1000 [00:38<00:52, 11.78it/s]\u001b[A\n",
      " 38%|███▊      | 383/1000 [00:38<01:00, 10.17it/s]\u001b[A\n",
      " 38%|███▊      | 385/1000 [00:38<01:11,  8.58it/s]\u001b[A\n",
      " 39%|███▊      | 387/1000 [00:39<01:06,  9.23it/s]\u001b[A\n",
      " 39%|███▉      | 389/1000 [00:39<01:11,  8.49it/s]\u001b[A\n",
      " 39%|███▉      | 391/1000 [00:39<01:04,  9.44it/s]\u001b[A\n",
      " 39%|███▉      | 393/1000 [00:39<01:09,  8.74it/s]\u001b[A\n",
      " 40%|███▉      | 395/1000 [00:39<01:00,  9.97it/s]\u001b[A\n",
      " 40%|███▉      | 398/1000 [00:40<00:53, 11.31it/s]\u001b[A\n",
      " 40%|████      | 400/1000 [00:40<00:50, 11.96it/s]\u001b[A\n",
      " 40%|████      | 402/1000 [00:40<01:05,  9.06it/s]\u001b[A\n",
      " 40%|████      | 404/1000 [00:41<01:26,  6.86it/s]\u001b[A\n",
      " 41%|████      | 406/1000 [00:41<01:23,  7.08it/s]\u001b[A\n",
      " 41%|████      | 407/1000 [00:41<01:30,  6.57it/s]\u001b[A\n",
      " 41%|████      | 410/1000 [00:41<01:22,  7.18it/s]\u001b[A\n",
      " 41%|████      | 411/1000 [00:42<01:38,  5.95it/s]\u001b[A\n",
      " 41%|████▏     | 414/1000 [00:42<01:17,  7.58it/s]\u001b[A\n",
      " 42%|████▏     | 417/1000 [00:42<01:12,  8.02it/s]\u001b[A\n",
      " 42%|████▏     | 419/1000 [00:42<01:25,  6.77it/s]\u001b[A\n",
      " 42%|████▏     | 420/1000 [00:43<01:18,  7.38it/s]\u001b[A\n",
      " 42%|████▏     | 423/1000 [00:43<01:14,  7.74it/s]\u001b[A\n",
      " 42%|████▎     | 425/1000 [00:43<01:02,  9.27it/s]\u001b[A\n",
      " 43%|████▎     | 428/1000 [00:43<00:49, 11.66it/s]\u001b[A\n",
      " 43%|████▎     | 430/1000 [00:43<00:59,  9.51it/s]\u001b[A\n",
      " 43%|████▎     | 432/1000 [00:44<00:53, 10.69it/s]\u001b[A\n",
      " 43%|████▎     | 434/1000 [00:44<01:17,  7.29it/s]\u001b[A\n",
      " 44%|████▎     | 437/1000 [00:44<01:00,  9.30it/s]\u001b[A\n",
      " 44%|████▍     | 439/1000 [00:44<01:03,  8.84it/s]\u001b[A\n",
      " 44%|████▍     | 441/1000 [00:45<00:57,  9.68it/s]\u001b[A\n",
      " 44%|████▍     | 443/1000 [00:45<01:15,  7.39it/s]\u001b[A\n",
      " 44%|████▍     | 445/1000 [00:45<01:09,  8.04it/s]\u001b[A\n",
      " 45%|████▍     | 449/1000 [00:45<00:53, 10.25it/s]\u001b[A\n",
      " 45%|████▌     | 452/1000 [00:46<00:53, 10.30it/s]\u001b[A\n",
      " 45%|████▌     | 454/1000 [00:46<01:05,  8.32it/s]\u001b[A\n",
      " 46%|████▌     | 458/1000 [00:46<00:50, 10.70it/s]\u001b[A\n",
      " 46%|████▌     | 460/1000 [00:46<00:58,  9.27it/s]\u001b[A\n",
      " 46%|████▋     | 463/1000 [00:46<00:49, 10.85it/s]\u001b[A\n",
      " 46%|████▋     | 465/1000 [00:47<00:54,  9.86it/s]\u001b[A\n",
      " 47%|████▋     | 467/1000 [00:47<00:58,  9.15it/s]\u001b[A\n",
      " 47%|████▋     | 469/1000 [00:47<01:04,  8.29it/s]\u001b[A\n",
      " 47%|████▋     | 471/1000 [00:48<01:18,  6.73it/s]\u001b[A\n",
      " 47%|████▋     | 472/1000 [00:48<01:32,  5.71it/s]\u001b[A\n",
      " 47%|████▋     | 474/1000 [00:48<01:13,  7.17it/s]\u001b[A\n",
      " 48%|████▊     | 476/1000 [00:48<01:05,  8.03it/s]\u001b[A\n",
      " 48%|████▊     | 478/1000 [00:49<01:12,  7.20it/s]\u001b[A\n",
      " 48%|████▊     | 480/1000 [00:49<01:11,  7.24it/s]\u001b[A\n",
      " 48%|████▊     | 481/1000 [00:49<01:28,  5.88it/s]\u001b[A\n",
      " 48%|████▊     | 483/1000 [00:49<01:24,  6.13it/s]\u001b[A\n",
      " 48%|████▊     | 485/1000 [00:50<01:18,  6.53it/s]\u001b[A\n",
      " 49%|████▊     | 486/1000 [00:50<01:16,  6.72it/s]\u001b[A\n",
      " 49%|████▊     | 487/1000 [00:50<01:29,  5.76it/s]\u001b[A\n",
      " 49%|████▉     | 488/1000 [00:50<01:38,  5.19it/s]\u001b[A\n",
      " 49%|████▉     | 491/1000 [00:51<01:24,  6.03it/s]\u001b[A\n",
      " 49%|████▉     | 492/1000 [00:51<01:15,  6.72it/s]\u001b[A\n",
      " 49%|████▉     | 493/1000 [00:51<01:30,  5.60it/s]\u001b[A\n",
      " 49%|████▉     | 494/1000 [00:51<01:36,  5.24it/s]\u001b[A\n",
      " 50%|████▉     | 495/1000 [00:51<01:38,  5.12it/s]\u001b[A\n",
      " 50%|████▉     | 496/1000 [00:52<01:45,  4.78it/s]\u001b[A\n",
      " 50%|████▉     | 497/1000 [00:52<01:51,  4.51it/s]\u001b[A\n",
      " 50%|████▉     | 498/1000 [00:52<01:54,  4.37it/s]\u001b[A\n",
      " 50%|████▉     | 499/1000 [00:52<01:54,  4.39it/s]\u001b[A\n",
      " 50%|█████     | 500/1000 [00:53<01:55,  4.34it/s]\u001b[A\n",
      " 50%|█████     | 501/1000 [00:53<01:58,  4.20it/s]\u001b[A\n",
      " 50%|█████     | 502/1000 [00:53<01:57,  4.25it/s]\u001b[A\n",
      " 50%|█████     | 504/1000 [00:53<01:40,  4.93it/s]\u001b[A\n",
      " 50%|█████     | 505/1000 [00:54<01:43,  4.76it/s]\u001b[A\n",
      " 51%|█████     | 506/1000 [00:54<01:47,  4.61it/s]\u001b[A\n",
      " 51%|█████     | 507/1000 [00:54<01:32,  5.32it/s]\u001b[A\n",
      " 51%|█████     | 509/1000 [00:54<01:24,  5.80it/s]\u001b[A\n",
      " 51%|█████     | 511/1000 [00:54<01:09,  6.99it/s]\u001b[A\n",
      " 52%|█████▏    | 515/1000 [00:55<00:57,  8.48it/s]\u001b[A\n",
      " 52%|█████▏    | 517/1000 [00:55<00:55,  8.63it/s]\u001b[A\n",
      " 52%|█████▏    | 519/1000 [00:55<01:03,  7.54it/s]\u001b[A\n",
      " 52%|█████▏    | 520/1000 [00:55<01:18,  6.14it/s]\u001b[A\n",
      " 52%|█████▏    | 521/1000 [00:56<01:27,  5.48it/s]\u001b[A\n",
      " 52%|█████▏    | 523/1000 [00:56<01:22,  5.77it/s]\u001b[A\n",
      " 52%|█████▏    | 524/1000 [00:56<01:15,  6.27it/s]\u001b[A\n",
      " 52%|█████▎    | 525/1000 [00:56<01:21,  5.84it/s]\u001b[A\n",
      " 53%|█████▎    | 526/1000 [00:56<01:31,  5.16it/s]\u001b[A\n",
      " 53%|█████▎    | 528/1000 [00:57<01:22,  5.70it/s]\u001b[A\n",
      " 53%|█████▎    | 529/1000 [00:57<01:12,  6.50it/s]\u001b[A\n",
      " 53%|█████▎    | 530/1000 [00:57<01:25,  5.52it/s]\u001b[A\n",
      " 53%|█████▎    | 532/1000 [00:57<01:06,  6.99it/s]\u001b[A\n",
      " 54%|█████▎    | 535/1000 [00:57<01:00,  7.72it/s]\u001b[A\n",
      " 54%|█████▍    | 538/1000 [00:58<00:47,  9.78it/s]\u001b[A\n",
      " 54%|█████▍    | 540/1000 [00:58<00:40, 11.42it/s]\u001b[A\n",
      " 54%|█████▍    | 542/1000 [00:58<00:41, 10.95it/s]\u001b[A\n",
      " 54%|█████▍    | 544/1000 [00:58<00:47,  9.65it/s]\u001b[A\n",
      " 55%|█████▍    | 546/1000 [00:58<00:41, 10.97it/s]\u001b[A\n",
      " 55%|█████▍    | 549/1000 [00:59<00:41, 10.77it/s]\u001b[A\n",
      " 55%|█████▌    | 551/1000 [00:59<00:57,  7.76it/s]\u001b[A\n",
      " 55%|█████▌    | 553/1000 [00:59<00:47,  9.47it/s]\u001b[A\n",
      " 56%|█████▌    | 556/1000 [00:59<00:38, 11.68it/s]\u001b[A\n",
      " 56%|█████▌    | 558/1000 [00:59<00:38, 11.39it/s]\u001b[A\n",
      " 56%|█████▌    | 560/1000 [01:00<00:38, 11.41it/s]\u001b[A\n",
      " 56%|█████▌    | 562/1000 [01:00<00:42, 10.27it/s]\u001b[A\n",
      " 56%|█████▋    | 564/1000 [01:00<00:36, 12.02it/s]\u001b[A\n",
      " 57%|█████▋    | 567/1000 [01:00<00:31, 13.67it/s]\u001b[A\n",
      " 57%|█████▋    | 569/1000 [01:00<00:34, 12.64it/s]\u001b[A\n",
      " 57%|█████▋    | 573/1000 [01:01<00:33, 12.80it/s]\u001b[A\n",
      " 58%|█████▊    | 578/1000 [01:01<00:26, 16.15it/s]\u001b[A\n",
      " 58%|█████▊    | 581/1000 [01:01<00:25, 16.62it/s]\u001b[A\n",
      " 58%|█████▊    | 584/1000 [01:01<00:24, 17.12it/s]\u001b[A\n",
      " 59%|█████▊    | 587/1000 [01:01<00:23, 17.66it/s]\u001b[A\n",
      " 59%|█████▉    | 589/1000 [01:01<00:24, 16.71it/s]\u001b[A\n",
      " 59%|█████▉    | 592/1000 [01:01<00:26, 15.54it/s]\u001b[A\n",
      " 59%|█████▉    | 594/1000 [01:02<00:26, 15.19it/s]\u001b[A\n",
      " 60%|█████▉    | 597/1000 [01:02<00:22, 17.74it/s]\u001b[A\n",
      " 60%|██████    | 600/1000 [01:02<00:30, 13.20it/s]\u001b[A\n",
      " 60%|██████    | 602/1000 [01:02<00:31, 12.71it/s]\u001b[A\n",
      " 60%|██████    | 604/1000 [01:03<00:39, 10.15it/s]\u001b[A\n",
      " 61%|██████    | 607/1000 [01:03<00:31, 12.37it/s]\u001b[A\n",
      " 61%|██████    | 609/1000 [01:03<00:31, 12.38it/s]\u001b[A\n",
      " 61%|██████    | 611/1000 [01:03<00:37, 10.36it/s]\u001b[A\n",
      " 61%|██████▏   | 613/1000 [01:03<00:48,  7.98it/s]\u001b[A\n",
      " 62%|██████▏   | 615/1000 [01:04<00:45,  8.40it/s]\u001b[A\n",
      " 62%|██████▏   | 617/1000 [01:04<00:40,  9.47it/s]\u001b[A\n",
      " 62%|██████▏   | 619/1000 [01:04<00:41,  9.09it/s]\u001b[A\n",
      " 62%|██████▏   | 621/1000 [01:05<00:52,  7.16it/s]\u001b[A\n",
      " 62%|██████▏   | 623/1000 [01:05<00:45,  8.36it/s]\u001b[A\n",
      " 62%|██████▎   | 625/1000 [01:05<00:37,  9.92it/s]\u001b[A\n",
      " 63%|██████▎   | 627/1000 [01:05<00:43,  8.57it/s]\u001b[A\n",
      " 63%|██████▎   | 630/1000 [01:05<00:34, 10.69it/s]\u001b[A\n",
      " 63%|██████▎   | 632/1000 [01:06<00:49,  7.42it/s]\u001b[A\n",
      " 63%|██████▎   | 634/1000 [01:06<01:00,  6.05it/s]\u001b[A\n",
      " 64%|██████▎   | 635/1000 [01:06<01:08,  5.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 636/1000 [01:06<01:01,  5.97it/s]\u001b[A\n",
      " 64%|██████▎   | 637/1000 [01:07<01:05,  5.53it/s]\u001b[A\n",
      " 64%|██████▍   | 638/1000 [01:07<01:01,  5.93it/s]\u001b[A\n",
      " 64%|██████▍   | 640/1000 [01:07<00:52,  6.88it/s]\u001b[A\n",
      " 64%|██████▍   | 641/1000 [01:07<01:03,  5.64it/s]\u001b[A\n",
      " 65%|██████▍   | 647/1000 [01:07<00:45,  7.72it/s]\u001b[A\n",
      " 65%|██████▌   | 651/1000 [01:08<00:39,  8.78it/s]\u001b[A\n",
      " 65%|██████▌   | 653/1000 [01:08<00:40,  8.61it/s]\u001b[A\n",
      " 66%|██████▌   | 655/1000 [01:08<00:42,  8.18it/s]\u001b[A\n",
      " 66%|██████▌   | 657/1000 [01:09<00:44,  7.64it/s]\u001b[A\n",
      " 66%|██████▌   | 660/1000 [01:09<00:34,  9.75it/s]\u001b[A\n",
      " 66%|██████▌   | 662/1000 [01:09<00:29, 11.45it/s]\u001b[A\n",
      " 67%|██████▋   | 667/1000 [01:09<00:23, 14.38it/s]\u001b[A\n",
      " 67%|██████▋   | 670/1000 [01:09<00:27, 11.97it/s]\u001b[A\n",
      " 67%|██████▋   | 673/1000 [01:09<00:22, 14.40it/s]\u001b[A\n",
      " 68%|██████▊   | 676/1000 [01:10<00:27, 11.77it/s]\u001b[A\n",
      " 68%|██████▊   | 678/1000 [01:10<00:26, 11.95it/s]\u001b[A\n",
      " 68%|██████▊   | 680/1000 [01:10<00:25, 12.36it/s]\u001b[A\n",
      " 68%|██████▊   | 682/1000 [01:10<00:40,  7.91it/s]\u001b[A\n",
      " 68%|██████▊   | 684/1000 [01:11<00:50,  6.23it/s]\u001b[A\n",
      " 69%|██████▊   | 687/1000 [01:11<00:39,  8.02it/s]\u001b[A\n",
      " 69%|██████▉   | 690/1000 [01:11<00:31,  9.78it/s]\u001b[A\n",
      " 69%|██████▉   | 694/1000 [01:11<00:24, 12.27it/s]\u001b[A\n",
      " 70%|██████▉   | 697/1000 [01:11<00:20, 14.72it/s]\u001b[A\n",
      " 70%|███████   | 700/1000 [01:12<00:17, 17.14it/s]\u001b[A\n",
      " 70%|███████   | 703/1000 [01:12<00:18, 16.21it/s]\u001b[A\n",
      " 71%|███████   | 706/1000 [01:12<00:22, 13.03it/s]\u001b[A\n",
      " 71%|███████   | 708/1000 [01:12<00:20, 14.43it/s]\u001b[A\n",
      " 71%|███████   | 710/1000 [01:12<00:22, 13.13it/s]\u001b[A\n",
      " 71%|███████   | 712/1000 [01:13<00:23, 12.18it/s]\u001b[A\n",
      " 71%|███████▏  | 714/1000 [01:13<00:29,  9.76it/s]\u001b[A\n",
      " 72%|███████▏  | 716/1000 [01:13<00:25, 11.09it/s]\u001b[A\n",
      " 72%|███████▏  | 719/1000 [01:13<00:26, 10.45it/s]\u001b[A\n",
      " 72%|███████▏  | 721/1000 [01:13<00:22, 12.14it/s]\u001b[A\n",
      " 72%|███████▏  | 723/1000 [01:14<00:31,  8.87it/s]\u001b[A\n",
      " 72%|███████▎  | 725/1000 [01:14<00:37,  7.36it/s]\u001b[A\n",
      " 73%|███████▎  | 726/1000 [01:14<00:45,  6.00it/s]\u001b[A\n",
      " 73%|███████▎  | 730/1000 [01:15<00:37,  7.12it/s]\u001b[A\n",
      " 73%|███████▎  | 732/1000 [01:15<00:38,  6.94it/s]\u001b[A\n",
      " 74%|███████▎  | 735/1000 [01:15<00:32,  8.17it/s]\u001b[A\n",
      " 74%|███████▎  | 737/1000 [01:16<00:40,  6.46it/s]\u001b[A\n",
      " 74%|███████▍  | 739/1000 [01:16<00:40,  6.46it/s]\u001b[A\n",
      " 74%|███████▍  | 742/1000 [01:16<00:30,  8.42it/s]\u001b[A\n",
      " 74%|███████▍  | 744/1000 [01:16<00:26,  9.67it/s]\u001b[A\n",
      " 75%|███████▍  | 747/1000 [01:16<00:22, 11.21it/s]\u001b[A\n",
      " 75%|███████▌  | 750/1000 [01:17<00:18, 13.49it/s]\u001b[A\n",
      " 75%|███████▌  | 752/1000 [01:17<00:17, 14.45it/s]\u001b[A\n",
      " 75%|███████▌  | 754/1000 [01:17<00:23, 10.41it/s]\u001b[A\n",
      " 76%|███████▌  | 756/1000 [01:17<00:21, 11.17it/s]\u001b[A\n",
      " 76%|███████▌  | 758/1000 [01:17<00:26,  8.99it/s]\u001b[A\n",
      " 76%|███████▌  | 760/1000 [01:18<00:30,  7.85it/s]\u001b[A\n",
      " 76%|███████▌  | 762/1000 [01:18<00:31,  7.57it/s]\u001b[A\n",
      " 76%|███████▋  | 763/1000 [01:18<00:39,  5.95it/s]\u001b[A\n",
      " 76%|███████▋  | 764/1000 [01:18<00:38,  6.06it/s]\u001b[A\n",
      " 76%|███████▋  | 765/1000 [01:19<00:44,  5.28it/s]\u001b[A\n",
      " 77%|███████▋  | 766/1000 [01:19<00:48,  4.78it/s]\u001b[A\n",
      " 77%|███████▋  | 767/1000 [01:19<00:49,  4.71it/s]\u001b[A\n",
      " 77%|███████▋  | 770/1000 [01:19<00:39,  5.75it/s]\u001b[A\n",
      " 77%|███████▋  | 771/1000 [01:20<00:46,  4.93it/s]\u001b[A\n",
      " 77%|███████▋  | 772/1000 [01:20<00:49,  4.60it/s]\u001b[A\n",
      " 77%|███████▋  | 773/1000 [01:20<00:49,  4.56it/s]\u001b[A\n",
      " 78%|███████▊  | 776/1000 [01:20<00:40,  5.47it/s]\u001b[A\n",
      " 78%|███████▊  | 778/1000 [01:21<00:32,  6.89it/s]\u001b[A\n",
      " 78%|███████▊  | 783/1000 [01:21<00:23,  9.24it/s]\u001b[A\n",
      " 79%|███████▊  | 786/1000 [01:21<00:21,  9.88it/s]\u001b[A\n",
      " 79%|███████▉  | 788/1000 [01:21<00:18, 11.38it/s]\u001b[A\n",
      " 79%|███████▉  | 791/1000 [01:21<00:15, 13.29it/s]\u001b[A\n",
      " 79%|███████▉  | 793/1000 [01:21<00:14, 14.11it/s]\u001b[A\n",
      " 80%|███████▉  | 798/1000 [01:21<00:11, 17.75it/s]\u001b[A\n",
      " 80%|████████  | 801/1000 [01:22<00:12, 16.17it/s]\u001b[A\n",
      " 80%|████████  | 804/1000 [01:22<00:11, 17.73it/s]\u001b[A\n",
      " 81%|████████  | 809/1000 [01:22<00:08, 21.57it/s]\u001b[A\n",
      " 81%|████████▏ | 813/1000 [01:22<00:07, 24.89it/s]\u001b[A\n",
      " 82%|████████▏ | 817/1000 [01:22<00:07, 24.99it/s]\u001b[A\n",
      " 82%|████████▏ | 820/1000 [01:22<00:08, 20.24it/s]\u001b[A\n",
      " 82%|████████▏ | 823/1000 [01:23<00:08, 20.50it/s]\u001b[A\n",
      " 83%|████████▎ | 826/1000 [01:23<00:07, 22.27it/s]\u001b[A\n",
      " 83%|████████▎ | 829/1000 [01:23<00:07, 22.97it/s]\u001b[A\n",
      " 83%|████████▎ | 832/1000 [01:23<00:13, 12.76it/s]\u001b[A\n",
      " 84%|████████▎ | 835/1000 [01:24<00:13, 11.99it/s]\u001b[A\n",
      " 84%|████████▍ | 842/1000 [01:24<00:09, 15.82it/s]\u001b[A\n",
      " 85%|████████▍ | 846/1000 [01:24<00:15, 10.23it/s]\u001b[A\n",
      " 85%|████████▍ | 849/1000 [01:25<00:13, 11.58it/s]\u001b[A\n",
      " 85%|████████▌ | 852/1000 [01:25<00:11, 13.26it/s]\u001b[A\n",
      " 86%|████████▌ | 855/1000 [01:25<00:12, 11.76it/s]\u001b[A\n",
      " 86%|████████▌ | 857/1000 [01:25<00:11, 12.87it/s]\u001b[A\n",
      " 86%|████████▌ | 859/1000 [01:26<00:18,  7.80it/s]\u001b[A\n",
      " 86%|████████▌ | 861/1000 [01:26<00:20,  6.91it/s]\u001b[A\n",
      " 86%|████████▋ | 863/1000 [01:26<00:23,  5.81it/s]\u001b[A\n",
      " 86%|████████▋ | 864/1000 [01:27<00:26,  5.22it/s]\u001b[A\n",
      " 86%|████████▋ | 865/1000 [01:27<00:28,  4.72it/s]\u001b[A\n",
      " 87%|████████▋ | 866/1000 [01:27<00:29,  4.51it/s]\u001b[A\n",
      " 87%|████████▋ | 867/1000 [01:27<00:25,  5.27it/s]\u001b[A\n",
      " 87%|████████▋ | 868/1000 [01:28<00:28,  4.70it/s]\u001b[A\n",
      " 87%|████████▋ | 869/1000 [01:28<00:29,  4.45it/s]\u001b[A\n",
      " 87%|████████▋ | 870/1000 [01:28<00:28,  4.64it/s]\u001b[A\n",
      " 87%|████████▋ | 871/1000 [01:28<00:29,  4.40it/s]\u001b[A\n",
      " 87%|████████▋ | 873/1000 [01:29<00:25,  4.89it/s]\u001b[A\n",
      " 88%|████████▊ | 875/1000 [01:29<00:22,  5.59it/s]\u001b[A\n",
      " 88%|████████▊ | 876/1000 [01:29<00:24,  5.02it/s]\u001b[A\n",
      " 88%|████████▊ | 877/1000 [01:29<00:22,  5.45it/s]\u001b[A\n",
      " 88%|████████▊ | 879/1000 [01:29<00:18,  6.49it/s]\u001b[A\n",
      " 88%|████████▊ | 882/1000 [01:30<00:14,  8.41it/s]\u001b[A\n",
      " 88%|████████▊ | 884/1000 [01:30<00:14,  7.93it/s]\u001b[A\n",
      " 89%|████████▊ | 886/1000 [01:30<00:12,  9.19it/s]\u001b[A\n",
      " 89%|████████▉ | 888/1000 [01:30<00:11,  9.39it/s]\u001b[A\n",
      " 89%|████████▉ | 890/1000 [01:30<00:11,  9.84it/s]\u001b[A\n",
      " 89%|████████▉ | 892/1000 [01:31<00:11,  9.03it/s]\u001b[A\n",
      " 89%|████████▉ | 894/1000 [01:31<00:11,  9.39it/s]\u001b[A\n",
      " 90%|████████▉ | 896/1000 [01:31<00:12,  8.65it/s]\u001b[A\n",
      " 90%|████████▉ | 897/1000 [01:31<00:15,  6.44it/s]\u001b[A\n",
      " 90%|████████▉ | 899/1000 [01:32<00:15,  6.36it/s]\u001b[A\n",
      " 90%|█████████ | 900/1000 [01:32<00:17,  5.56it/s]\u001b[A\n",
      " 90%|█████████ | 901/1000 [01:32<00:19,  5.13it/s]\u001b[A\n",
      " 90%|█████████ | 902/1000 [01:32<00:20,  4.78it/s]\u001b[A\n",
      " 90%|█████████ | 903/1000 [01:32<00:17,  5.48it/s]\u001b[A\n",
      " 90%|█████████ | 904/1000 [01:33<00:19,  5.00it/s]\u001b[A\n",
      " 90%|█████████ | 905/1000 [01:33<00:20,  4.68it/s]\u001b[A\n",
      " 91%|█████████ | 907/1000 [01:33<00:18,  5.05it/s]\u001b[A\n",
      " 91%|█████████ | 908/1000 [01:33<00:19,  4.79it/s]\u001b[A\n",
      " 91%|█████████ | 909/1000 [01:34<00:19,  4.55it/s]\u001b[A\n",
      " 91%|█████████ | 910/1000 [01:34<00:21,  4.27it/s]\u001b[A\n",
      " 91%|█████████ | 911/1000 [01:34<00:21,  4.18it/s]\u001b[A\n",
      " 91%|█████████▏| 913/1000 [01:34<00:17,  4.95it/s]\u001b[A\n",
      " 91%|█████████▏| 914/1000 [01:35<00:18,  4.70it/s]\u001b[A\n",
      " 92%|█████████▏| 915/1000 [01:35<00:18,  4.55it/s]\u001b[A\n",
      " 92%|█████████▏| 916/1000 [01:35<00:18,  4.58it/s]\u001b[A\n",
      " 92%|█████████▏| 918/1000 [01:35<00:14,  5.82it/s]\u001b[A\n",
      " 92%|█████████▏| 919/1000 [01:36<00:15,  5.36it/s]\u001b[A\n",
      " 92%|█████████▏| 920/1000 [01:36<00:15,  5.03it/s]\u001b[A\n",
      " 92%|█████████▏| 921/1000 [01:36<00:15,  5.09it/s]\u001b[A\n",
      " 92%|█████████▏| 923/1000 [01:36<00:13,  5.65it/s]\u001b[A\n",
      " 92%|█████████▏| 924/1000 [01:36<00:15,  4.92it/s]\u001b[A\n",
      " 93%|█████████▎| 927/1000 [01:37<00:11,  6.25it/s]\u001b[A\n",
      " 93%|█████████▎| 928/1000 [01:37<00:13,  5.46it/s]\u001b[A\n",
      " 93%|█████████▎| 929/1000 [01:37<00:14,  5.07it/s]\u001b[A\n",
      " 93%|█████████▎| 931/1000 [01:37<00:11,  6.18it/s]\u001b[A\n",
      " 93%|█████████▎| 933/1000 [01:37<00:09,  6.88it/s]\u001b[A\n",
      " 93%|█████████▎| 934/1000 [01:38<00:11,  5.85it/s]\u001b[A\n",
      " 94%|█████████▎| 935/1000 [01:38<00:12,  5.06it/s]\u001b[A\n",
      " 94%|█████████▍| 938/1000 [01:38<00:09,  6.48it/s]\u001b[A\n",
      " 94%|█████████▍| 940/1000 [01:38<00:08,  6.68it/s]\u001b[A\n",
      " 94%|█████████▍| 942/1000 [01:39<00:08,  6.64it/s]\u001b[A\n",
      " 94%|█████████▍| 943/1000 [01:39<00:07,  7.22it/s]\u001b[A\n",
      " 94%|█████████▍| 944/1000 [01:39<00:08,  6.46it/s]\u001b[A\n",
      " 94%|█████████▍| 945/1000 [01:39<00:09,  5.66it/s]\u001b[A\n",
      " 95%|█████████▍| 947/1000 [01:39<00:07,  6.82it/s]\u001b[A\n",
      " 95%|█████████▌| 950/1000 [01:40<00:05,  8.84it/s]\u001b[A\n",
      " 95%|█████████▌| 953/1000 [01:40<00:04, 10.16it/s]\u001b[A\n",
      " 96%|█████████▌| 955/1000 [01:40<00:06,  7.27it/s]\u001b[A\n",
      " 96%|█████████▌| 957/1000 [01:41<00:06,  6.17it/s]\u001b[A\n",
      " 96%|█████████▌| 958/1000 [01:41<00:07,  5.34it/s]\u001b[A\n",
      " 96%|█████████▌| 960/1000 [01:41<00:06,  5.83it/s]\u001b[A\n",
      " 96%|█████████▋| 963/1000 [01:41<00:04,  7.51it/s]\u001b[A\n",
      " 96%|█████████▋| 965/1000 [01:41<00:04,  8.14it/s]\u001b[A\n",
      " 97%|█████████▋| 967/1000 [01:42<00:04,  8.00it/s]\u001b[A\n",
      " 97%|█████████▋| 969/1000 [01:42<00:03,  8.66it/s]\u001b[A\n",
      " 97%|█████████▋| 971/1000 [01:42<00:03,  7.54it/s]\u001b[A\n",
      " 97%|█████████▋| 973/1000 [01:42<00:03,  7.62it/s]\u001b[A\n",
      " 97%|█████████▋| 974/1000 [01:43<00:04,  6.16it/s]\u001b[A\n",
      " 98%|█████████▊| 976/1000 [01:43<00:03,  7.05it/s]\u001b[A\n",
      " 98%|█████████▊| 977/1000 [01:43<00:03,  7.48it/s]\u001b[A\n",
      " 98%|█████████▊| 978/1000 [01:43<00:03,  6.22it/s]\u001b[A\n",
      " 98%|█████████▊| 980/1000 [01:43<00:02,  6.72it/s]\u001b[A\n",
      " 98%|█████████▊| 982/1000 [01:44<00:02,  7.66it/s]\u001b[A\n",
      " 98%|█████████▊| 983/1000 [01:44<00:02,  7.02it/s]\u001b[A\n",
      " 98%|█████████▊| 985/1000 [01:44<00:01,  8.09it/s]\u001b[A\n",
      " 99%|█████████▊| 986/1000 [01:44<00:02,  6.34it/s]\u001b[A\n",
      " 99%|█████████▉| 988/1000 [01:44<00:01,  7.66it/s]\u001b[A\n",
      " 99%|█████████▉| 993/1000 [01:44<00:00, 10.18it/s]\u001b[A\n",
      "100%|█████████▉| 997/1000 [01:45<00:00, 12.04it/s]\u001b[A\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.49it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 0.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores, score = bleu(mt_test, model, hindi, english, device)\n",
    "all_scores, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adverse-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "suburban-astronomy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f522003ab793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhindi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bleu score {score * 100:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2a886ada98b7>\u001b[0m in \u001b[0;36mbleu\u001b[0;34m(data, model, german, english, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "overhead-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "hypothesis2 = 'It is to insure the troops forever hearing the activity guidebook that party direct'\n",
    "\n",
    "reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "reference2 = 'It is the guiding principle which guarantees the military forces always being under the command of the Party'\n",
    "reference3 = 'It is the practical guide for the army always to heed the directions of the party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate.meteor_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southeast-mathematics",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ddc0fcfad492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeteor_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "round(translate.meteor_score([reference1, reference2, reference3], hypothesis1),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-opposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-orientation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-appraisal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
