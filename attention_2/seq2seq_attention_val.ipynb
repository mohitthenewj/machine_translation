{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unexpected-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from inltk.inltk import tokenize\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import sys\n",
    "import time\n",
    "from inltk.inltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trained-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return [tok for tok in spacy_eng.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latest-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = data.Field(tokenize=tokenize_hi)\n",
    "english = data.Field(tokenize=tokenize_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "orange-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for hindi.build_vocab was 2.9937100410461426\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))\n",
    "hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "english.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "\n",
    "print(f'Total time taken for hindi.build_vocab was {time.time() - st}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-monkey",
   "metadata": {},
   "source": [
    "### Total time taken for hindi.build_vocab was 2783.8125097751617\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fifth-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('hindi_vocab_1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(hindi, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('english_vocab_1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(english, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('hindi_vocab.pickle', 'rb') as handle:\n",
    "#     hindi = pickle.load(handle)\n",
    "\n",
    "# with open('english_vocab.pickle', 'rb') as handle:\n",
    "#     english = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "necessary-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "enabling-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input_size_encoder is 120\n",
      "length of input_size_decoder is 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "# num_epochs = 100\n",
    "learning_rate = 3e-4\n",
    "# batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0\n",
    "\n",
    "print(f'length of input_size_encoder is {input_size_encoder}')\n",
    "\n",
    "print(f'length of input_size_decoder is {input_size_decoder}')\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "model_file_name = \"checkpoint_attn_v2.pth.tar\"\n",
    "\n",
    "# train_iterator = data.BucketIterator(\n",
    "#      dataset=mt_train, batch_size=batch_size,\n",
    "#      sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesbian-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk_ext/nlp/seq2seq_attention\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "removed-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([12689, 300]) from checkpoint, the shape in current model is torch.Size([12668, 300]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([13005, 300]) from checkpoint, the shape in current model is torch.Size([15002, 300]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([13005, 1024]) from checkpoint, the shape in current model is torch.Size([15002, 1024]).\n\tsize mismatch for decoder.fc.bias: copying a param with shape torch.Size([13005]) from checkpoint, the shape in current model is torch.Size([15002]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-709e44950e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msave_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_checkpoint.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-5e990c3fd6f7>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint, model, optimizer)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Loading checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([12689, 300]) from checkpoint, the shape in current model is torch.Size([12668, 300]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([13005, 300]) from checkpoint, the shape in current model is torch.Size([15002, 300]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([13005, 1024]) from checkpoint, the shape in current model is torch.Size([15002, 1024]).\n\tsize mismatch for decoder.fc.bias: copying a param with shape torch.Size([13005]) from checkpoint, the shape in current model is torch.Size([15002])."
     ]
    }
   ],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "# if load_model:\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "load_checkpoint(torch.load(model_file_name), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-blues",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "#     spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "#         tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "        tokens = [i.lower() for i in tokenize(sentence, \"hi\")]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in tqdm(data):\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=model_file_name):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atmospheric-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electoral-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_torch/pmindia.v1.hi-en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['english_sentence', 'hindi_sentence'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "devoted-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХреЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА, рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗред \n",
      " and translated_sent is \n",
      "resources is spreading to <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][0]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "earlier-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдЗрд╕ рддрд░рд╣ рдЖрд░рдПрдПрди рдХрд╛ рдХрд╛рдордХрд╛рдЬ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдПрд╡рдВ рдкрд░рд┐рд╡рд╛рд░ рдХрд▓реНрдпрд╛рдг рд╡рд┐рднрд╛рдЧ рдХреЗ рдЕрдзреАрди рд▓рд╛рдпрд╛ рдЬрд╛рдПрдЧрд╛ред \n",
      " and translated_sent is \n",
      "to provide the up of this health and family welfare with <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][2]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "modern-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдПрдХ рд╕реНрд╡рд╛рдпрд╢рд╛рд╕реА рдирд┐рдХрд╛рдп рдХреЗ рд░реВрдк рдореЗрдВ рдЬреЗрдПрд╕рдХреЗ рдХреЛ рдмрдВрдж рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдирд┐рдзрд┐ рдХреЗ рддреМрд░ рдкрд░ рдЙрд╕рдХрд╛ рдХрд╛рдордХрд╛рдЬ рд╡рд┐рднрд╛рдЧ рджреНрд╡рд╛рд░рд╛ рд╕рдВрднрд╡ рд╣реИред \n",
      " and translated_sent is \n",
      "as a result is to be utilized as it can be administered by the department as a fund possible can be <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][10]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "expensive-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдорд╣рд╛рд░рд╛рдиреА рдореИрдХреНрд╕рд┐рдорд╛ рдиреЗ рдЗрди рдХрджрдореЛрдВ рдХреЗ рдЬрд░рд┐рдП рд╣реБрдИ рдкреНрд░рдЧрддрд┐ рдХреА рд╕рд░рд╛рд╣рдирд╛ рдХреАред \n",
      " and translated_sent is \n",
      "ceos appreciated the progress made by these initiatives through these progress achieved made in these initiatives these initiatives made by these initiatives from тАШ <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][16]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intelligent-delicious",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдкреНрд░рдзрд╛рди рдордВрддреНрд░реА рдиреЗ рдХрд╣рд╛ рдХрд┐ 16рд╡реАрдВ рд▓реЛрдХрд╕рднрд╛ рдореЗрдВ рдХрд░реАрдм 315 рдкрд╣рд▓реА рдмрд╛рд░ рд╕рд╛рдВрд╕рдж рдЪреБрдирдХрд░ рдЖрдП рд╣реИрдВ, рдЬреЛ рдкрд╣рд▓реА рд▓реЛрдХрд╕рднрд╛ рдХреЗ рд╕рдорд╛рди рд╣реИ ред \n",
      " and translated_sent is \n",
      "on the same the prime minister said that the sixteenth lok sabha was comparable to the <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][20]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "respective-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдЙрдиреНрд╣реЛрдВрдиреЗ рдХрд╣рд╛ рдХрд┐ рдЗрд╕ рдХрд╛рд░реНрдп рдХреЛ 2022 рддрдХ рдкреВрд░рд╛ рдХрд░ рд▓реЗрдиреЗ рдХрд╛ рд▓рдХреНрд╖реНрдп рд╣реИред \n",
      " and translated_sent is \n",
      "that the aim is to achieving this task by 2022 out this target to by 2022 out this target is by 2022 out this target is by 2022 out this target is by 2022 objectives of this purpose by 2022 this is by 2022 objectives of this purpose by 2022\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][40]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "simple-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рд╕реЗрдирд╛ рдиреЗ рд╣рдореЗрд╢рд╛ рджреЗрд╢ рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреА рд╣реИред \n",
      " and translated_sent is \n",
      "nations the nation the country given the country to accorded to the nation and the nation is affordable youth country country has accorded the nation тАЩs priority тАЭ the nation nation priority тАЭ the country тАЩs priority on priority тАЭ the nation nation its priority on priority тАЭ the nation\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][80]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "searching-limit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рднрд╛рд░рдд рдХреА рдЙрддреНрд╕рд╡ рдкрд░рдореНрдкрд░рд╛, рдкреНрд░рдХреГрддрд┐-рдкреНрд░реЗрдо рдХреЛ рдмрд▓рд╡рд╛рди рдмрдирд╛рдиреЗ рд╡рд╛рд▓реА, рдмрд╛рд▓рдХ рд╕реЗ рд▓реЗрдХрд░ рдХреЗ рд╣рд░ рд╡реНрдпрдХреНрддрд┐ рдХреЛ рд╕рдВрд╕реНрдХрд╛рд░рд┐рдд рдХрд░рдиреЗ рд╡рд╛рд▓реА рд░рд╣реА рд╣реИред \n",
      " and translated_sent is \n",
      "if india тАЩs land is a <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][1100]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "metallic-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдкрд░рд╕реНрдкрд░ рд╕рд╣рдпреЛрдЧ рдХреЗ рд▓рд┐рдП рджрд┐рдорд╛рдЧ рдореЗрдВ рдХреБрдЫ рд╡рд┐рдЪрд╛рд░ рдЖрдП рд╣реИрдВ, рдЬрд┐рд╕реЗ рдореИрдВ рдпрд╣рд╛рдВ рд╕рд╛рдЭрд╛ рдХрд░ рд░рд╣рд╛ рд╣реВрдВред \n",
      " and translated_sent is \n",
      "possible here with a <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][10000]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "emotional-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org sentenece is \n",
      " рдФрд░ рдЕрдЧрд░ рд╡реЛ рдирд╣реАрдВ рд╣реБрдЖ рддреЛ рдХрд╣рддреЗ рд╣реИрдВ рдХрд┐ рд░рд┐рдлреЙрд░реНрдо рдирд╣реАрдВ рд╣реБрдЖред \n",
      " and translated_sent is \n",
      "if you nтАЩt nтАЩt have enough then do nтАЩt have <unk>\n"
     ]
    }
   ],
   "source": [
    "sent = df['hindi_sentence'][3000]\n",
    "translated_sent = ' '.join(translate_sentence(model, sent, hindi, english, device))\n",
    "print(f'org sentenece is \\n {sent} \\n and translated_sent is \\n{translated_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "honey-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_val', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(data, model, german, english, device):\n",
    "#     targets = []\n",
    "#     outputs = []\n",
    "    all_scores = []\n",
    "    for example in tqdm(data):\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        \n",
    "#         targets.append([trg])\n",
    "#         outputs.append(prediction)\n",
    "        \n",
    "        try:\n",
    "#             score = bleu_score([prediction], [trg], max_n=2)\n",
    "#             score = sentence_bleu(prediction, trg)\n",
    "#             all_scores.append(score)\n",
    "#             if score>0:\n",
    "            print(f'trg is {trg}')\n",
    "            print(f'prediction is {prediction}')\n",
    "            print(f'score is {score}')\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "#             print(f'Exception is {e}')\n",
    "#             print(f'trg is {trg}')\n",
    "#             print(f'prediction is {prediction}')\n",
    "            pass\n",
    "\n",
    "    return (all_scores, sum(all_scores)/len(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-radical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bleu(mt_test, model, hindi, english, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "owned-peter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prime',\n",
       " 'minister',\n",
       " 'said',\n",
       " 'the',\n",
       " 'union',\n",
       " 'government',\n",
       " 'is',\n",
       " 'working',\n",
       " 'focusing',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'infrastructure',\n",
       " 'augmentation',\n",
       " 'and',\n",
       " 'it',\n",
       " 'requires',\n",
       " 'is',\n",
       " 'focus',\n",
       " 'infrastructure',\n",
       " 'development',\n",
       " 'deficit',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = ['prime', 'minister', 'said', 'the', 'union', 'government', 'is', 'working', 'focusing', 'focusing', 'on', 'infrastructure', 'augmentation', 'and', 'it', 'requires', 'is', 'focus', 'infrastructure', 'development', 'deficit', '<unk>']\n",
    "# sent1 =  ' '.join(sent1)\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "diagnostic-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = ['the', 'union', 'government', 'of', 'india', 'infrastructure', 'is', 'focusing', 'focused', 'on', 'focusing', 'on', 'infrastructure', 'technology', 'and', 'real', 'structure', 'with', 'speed', 'targets', 'being', 'infrastructure', 'is', 'focusing', 'on', '<unk>']\n",
    "# sent2 =  ' '.join(sent2)\n",
    "# sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "trying-intake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.384292958842266e-231"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(['my','name','is','mohit' ], ['i', 'am','mohit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "conditional-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2882297539194154e-231\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this', 'is' 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "requested-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964276313782"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]\n",
    "bleu_score(candidate_corpus, references_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fresh-bible",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['тЦБрдкреНрд░рдзрд╛рдирдордВрддреНрд░реА',\n",
       " 'тЦБрдиреЗ',\n",
       " 'тЦБрдХрд╣рд╛',\n",
       " 'тЦБрдХрд┐',\n",
       " 'тЦБрднрд╛рд░рдд',\n",
       " 'тЦБрдореЗрдВ',\n",
       " 'тЦБрдХреЗрдВрджреНрд░',\n",
       " 'тЦБрд╕рд░рдХрд╛рд░',\n",
       " 'тЦБрдмреБрдирд┐рдпрд╛рджреА',\n",
       " 'тЦБрдврд╛рдВрдЪреЗ',\n",
       " 'тЦБрдкрд░',\n",
       " 'тЦБрдзреНрдпрд╛рди',\n",
       " 'тЦБрдХреЗрдВрджреНрд░рд┐рдд',\n",
       " 'тЦБрдХрд░',\n",
       " 'тЦБрд░рд╣реА',\n",
       " 'тЦБрд╣реИ']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_hi('рдкреНрд░рдзрд╛рдирдордВрддреНрд░реА рдиреЗ рдХрд╣рд╛ рдХрд┐ рднрд╛рд░рдд рдореЗрдВ рдХреЗрдВрджреНрд░ рд╕рд░рдХрд╛рд░ рдмреБрдирд┐рдпрд╛рджреА рдврд╛рдВрдЪреЗ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░ рд░рд╣реА рд╣реИред')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "forward-deposit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/1000 [00:00<01:46,  9.41it/s]\u001b[A\n",
      "  0%|          | 4/1000 [00:00<01:29, 11.13it/s]\u001b[A\n",
      "  0%|          | 5/1000 [00:00<02:09,  7.67it/s]\u001b[A\n",
      "  1%|          | 6/1000 [00:00<02:11,  7.59it/s]\u001b[A\n",
      "  1%|          | 8/1000 [00:00<02:07,  7.77it/s]\u001b[A\n",
      "  1%|          | 10/1000 [00:01<01:45,  9.38it/s]\u001b[A\n",
      "  1%|тЦП         | 14/1000 [00:01<01:22, 11.96it/s]\u001b[A\n",
      "  2%|тЦП         | 16/1000 [00:01<01:39,  9.92it/s]\u001b[A\n",
      "  2%|тЦП         | 18/1000 [00:01<01:29, 11.01it/s]\u001b[A\n",
      "  2%|тЦП         | 20/1000 [00:01<01:26, 11.31it/s]\u001b[A\n",
      "  2%|тЦП         | 22/1000 [00:01<01:21, 11.96it/s]\u001b[A\n",
      "  2%|тЦП         | 24/1000 [00:02<01:38,  9.90it/s]\u001b[A\n",
      "  3%|тЦО         | 26/1000 [00:02<01:48,  8.98it/s]\u001b[A\n",
      "  3%|тЦО         | 28/1000 [00:02<01:57,  8.25it/s]\u001b[A\n",
      "  3%|тЦО         | 30/1000 [00:02<01:38,  9.88it/s]\u001b[A\n",
      "  3%|тЦО         | 32/1000 [00:02<01:23, 11.57it/s]\u001b[A\n",
      "  4%|тЦО         | 35/1000 [00:03<01:11, 13.45it/s]\u001b[A\n",
      "  4%|тЦО         | 37/1000 [00:03<01:17, 12.39it/s]\u001b[A\n",
      "  4%|тЦН         | 39/1000 [00:03<01:08, 13.95it/s]\u001b[A\n",
      "  4%|тЦН         | 42/1000 [00:03<01:00, 15.96it/s]\u001b[A\n",
      "  4%|тЦН         | 44/1000 [00:03<01:01, 15.62it/s]\u001b[A\n",
      "  5%|тЦН         | 47/1000 [00:03<01:11, 13.42it/s]\u001b[A\n",
      "  5%|тЦН         | 49/1000 [00:04<01:23, 11.42it/s]\u001b[A\n",
      "  5%|тЦМ         | 51/1000 [00:04<01:40,  9.41it/s]\u001b[A\n",
      "  5%|тЦМ         | 53/1000 [00:04<01:49,  8.64it/s]\u001b[A\n",
      "  6%|тЦМ         | 55/1000 [00:04<01:53,  8.29it/s]\u001b[A\n",
      "  6%|тЦМ         | 56/1000 [00:05<02:27,  6.41it/s]\u001b[A\n",
      "  6%|тЦМ         | 58/1000 [00:05<02:24,  6.51it/s]\u001b[A\n",
      "  6%|тЦМ         | 61/1000 [00:05<02:01,  7.73it/s]\u001b[A\n",
      "  6%|тЦМ         | 62/1000 [00:05<02:08,  7.31it/s]\u001b[A\n",
      "  6%|тЦЛ         | 65/1000 [00:06<01:52,  8.29it/s]\u001b[A\n",
      "  7%|тЦЛ         | 66/1000 [00:06<01:54,  8.19it/s]\u001b[A\n",
      "  7%|тЦЛ         | 67/1000 [00:06<02:22,  6.54it/s]\u001b[A\n",
      "  7%|тЦЛ         | 70/1000 [00:06<01:49,  8.49it/s]\u001b[A\n",
      "  7%|тЦЛ         | 72/1000 [00:06<01:56,  7.96it/s]\u001b[A\n",
      "  7%|тЦЛ         | 74/1000 [00:07<02:01,  7.64it/s]\u001b[A\n",
      "  8%|тЦК         | 76/1000 [00:07<02:05,  7.37it/s]\u001b[A\n",
      "  8%|тЦК         | 77/1000 [00:07<02:13,  6.89it/s]\u001b[A\n",
      "  8%|тЦК         | 80/1000 [00:07<01:46,  8.67it/s]\u001b[A\n",
      "  8%|тЦК         | 82/1000 [00:08<01:46,  8.60it/s]\u001b[A\n",
      "  8%|тЦК         | 84/1000 [00:08<01:42,  8.96it/s]\u001b[A\n",
      "  9%|тЦК         | 86/1000 [00:08<02:00,  7.56it/s]\u001b[A\n",
      "  9%|тЦК         | 87/1000 [00:08<02:08,  7.13it/s]\u001b[A\n",
      "  9%|тЦЙ         | 90/1000 [00:08<01:42,  8.88it/s]\u001b[A\n",
      "  9%|тЦЙ         | 92/1000 [00:09<01:29, 10.10it/s]\u001b[A\n",
      "  9%|тЦЙ         | 94/1000 [00:09<01:27, 10.34it/s]\u001b[A\n",
      " 10%|тЦЙ         | 98/1000 [00:09<01:07, 13.29it/s]\u001b[A\n",
      " 10%|тЦИ         | 101/1000 [00:09<00:59, 15.22it/s]\u001b[A\n",
      " 10%|тЦИ         | 105/1000 [00:09<00:54, 16.31it/s]\u001b[A\n",
      " 11%|тЦИ         | 108/1000 [00:09<00:58, 15.35it/s]\u001b[A\n",
      " 11%|тЦИ         | 111/1000 [00:10<00:58, 15.25it/s]\u001b[A\n",
      " 12%|тЦИтЦП        | 115/1000 [00:10<00:49, 17.74it/s]\u001b[A\n",
      " 12%|тЦИтЦП        | 118/1000 [00:10<01:01, 14.28it/s]\u001b[A\n",
      " 12%|тЦИтЦП        | 120/1000 [00:10<01:19, 11.11it/s]\u001b[A\n",
      " 12%|тЦИтЦП        | 122/1000 [00:11<01:29,  9.82it/s]\u001b[A\n",
      " 12%|тЦИтЦП        | 124/1000 [00:11<01:30,  9.70it/s]\u001b[A\n",
      " 13%|тЦИтЦО        | 128/1000 [00:11<01:23, 10.49it/s]\u001b[A\n",
      " 13%|тЦИтЦО        | 130/1000 [00:11<01:19, 10.94it/s]\u001b[A\n",
      " 13%|тЦИтЦО        | 133/1000 [00:12<01:20, 10.81it/s]\u001b[A\n",
      " 14%|тЦИтЦО        | 135/1000 [00:12<01:09, 12.43it/s]\u001b[A\n",
      " 14%|тЦИтЦО        | 137/1000 [00:12<01:02, 13.76it/s]\u001b[A\n",
      " 14%|тЦИтЦН        | 139/1000 [00:12<01:21, 10.51it/s]\u001b[A\n",
      " 14%|тЦИтЦН        | 141/1000 [00:12<01:15, 11.40it/s]\u001b[A\n",
      " 14%|тЦИтЦН        | 143/1000 [00:12<01:32,  9.23it/s]\u001b[A\n",
      " 14%|тЦИтЦН        | 145/1000 [00:13<01:26,  9.91it/s]\u001b[A\n",
      " 15%|тЦИтЦН        | 149/1000 [00:13<01:09, 12.22it/s]\u001b[A\n",
      " 15%|тЦИтЦМ        | 151/1000 [00:13<01:41,  8.33it/s]\u001b[A\n",
      " 15%|тЦИтЦМ        | 153/1000 [00:13<01:32,  9.12it/s]\u001b[A\n",
      " 16%|тЦИтЦМ        | 155/1000 [00:14<01:35,  8.83it/s]\u001b[A\n",
      " 16%|тЦИтЦМ        | 157/1000 [00:14<01:30,  9.30it/s]\u001b[A\n",
      " 16%|тЦИтЦМ        | 160/1000 [00:14<01:11, 11.70it/s]\u001b[A\n",
      " 16%|тЦИтЦМ        | 162/1000 [00:14<01:09, 12.02it/s]\u001b[A\n",
      " 16%|тЦИтЦЛ        | 164/1000 [00:14<01:16, 10.93it/s]\u001b[A\n",
      " 17%|тЦИтЦЛ        | 167/1000 [00:15<01:11, 11.69it/s]\u001b[A\n",
      " 17%|тЦИтЦЛ        | 170/1000 [00:15<00:59, 13.91it/s]\u001b[A\n",
      " 17%|тЦИтЦЛ        | 174/1000 [00:15<01:00, 13.62it/s]\u001b[A\n",
      " 18%|тЦИтЦК        | 178/1000 [00:15<00:59, 13.74it/s]\u001b[A\n",
      " 18%|тЦИтЦК        | 180/1000 [00:15<01:01, 13.24it/s]\u001b[A\n",
      " 18%|тЦИтЦК        | 182/1000 [00:16<01:35,  8.56it/s]\u001b[A\n",
      " 18%|тЦИтЦК        | 185/1000 [00:16<01:21,  9.96it/s]\u001b[A\n",
      " 19%|тЦИтЦЙ        | 188/1000 [00:16<01:07, 11.99it/s]\u001b[A\n",
      " 19%|тЦИтЦЙ        | 191/1000 [00:16<01:13, 10.99it/s]\u001b[A\n",
      " 19%|тЦИтЦЙ        | 194/1000 [00:17<01:01, 13.04it/s]\u001b[A\n",
      " 20%|тЦИтЦЙ        | 196/1000 [00:17<01:37,  8.29it/s]\u001b[A\n",
      " 20%|тЦИтЦЙ        | 198/1000 [00:17<01:24,  9.53it/s]\u001b[A\n",
      " 20%|тЦИтЦИ        | 202/1000 [00:17<01:05, 12.23it/s]\u001b[A\n",
      " 20%|тЦИтЦИ        | 205/1000 [00:18<01:29,  8.87it/s]\u001b[A\n",
      " 21%|тЦИтЦИ        | 207/1000 [00:18<01:17, 10.30it/s]\u001b[A\n",
      " 21%|тЦИтЦИ        | 209/1000 [00:18<01:28,  8.89it/s]\u001b[A\n",
      " 21%|тЦИтЦИ        | 212/1000 [00:18<01:13, 10.70it/s]\u001b[A\n",
      " 21%|тЦИтЦИтЦП       | 214/1000 [00:19<01:05, 11.97it/s]\u001b[A\n",
      " 22%|тЦИтЦИтЦП       | 216/1000 [00:19<01:32,  8.52it/s]\u001b[A\n",
      " 22%|тЦИтЦИтЦП       | 218/1000 [00:19<01:54,  6.81it/s]\u001b[A\n",
      " 22%|тЦИтЦИтЦП       | 220/1000 [00:19<01:38,  7.93it/s]\u001b[A\n",
      " 22%|тЦИтЦИтЦП       | 222/1000 [00:20<01:58,  6.56it/s]\u001b[A\n",
      " 22%|тЦИтЦИтЦП       | 224/1000 [00:20<01:42,  7.58it/s]\u001b[A\n",
      " 23%|тЦИтЦИтЦО       | 226/1000 [00:20<01:49,  7.05it/s]\u001b[A\n",
      " 23%|тЦИтЦИтЦО       | 227/1000 [00:21<01:47,  7.22it/s]\u001b[A\n",
      " 23%|тЦИтЦИтЦО       | 229/1000 [00:21<01:36,  8.01it/s]\u001b[A\n",
      " 23%|тЦИтЦИтЦО       | 233/1000 [00:21<01:25,  8.98it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦО       | 235/1000 [00:21<01:26,  8.88it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦО       | 237/1000 [00:22<01:35,  7.99it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦН       | 239/1000 [00:22<01:38,  7.72it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦН       | 241/1000 [00:22<01:25,  8.89it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦН       | 242/1000 [00:22<01:52,  6.75it/s]\u001b[A\n",
      " 24%|тЦИтЦИтЦН       | 245/1000 [00:23<01:40,  7.49it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦН       | 246/1000 [00:23<02:13,  5.65it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦН       | 247/1000 [00:23<02:04,  6.07it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦН       | 248/1000 [00:23<01:59,  6.30it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦН       | 249/1000 [00:23<02:12,  5.66it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦМ       | 250/1000 [00:23<02:04,  6.05it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦМ       | 251/1000 [00:24<02:11,  5.70it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦМ       | 253/1000 [00:24<02:07,  5.88it/s]\u001b[A\n",
      " 25%|тЦИтЦИтЦМ       | 254/1000 [00:24<02:23,  5.21it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 256/1000 [00:24<02:00,  6.19it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 257/1000 [00:25<02:17,  5.41it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 258/1000 [00:25<01:58,  6.24it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 259/1000 [00:25<02:11,  5.62it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 260/1000 [00:25<02:31,  4.89it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦМ       | 262/1000 [00:26<02:19,  5.30it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦЛ       | 263/1000 [00:26<02:05,  5.86it/s]\u001b[A\n",
      " 26%|тЦИтЦИтЦЛ       | 265/1000 [00:26<01:41,  7.27it/s]\u001b[A\n",
      " 27%|тЦИтЦИтЦЛ       | 268/1000 [00:26<01:19,  9.25it/s]\u001b[A\n",
      " 27%|тЦИтЦИтЦЛ       | 270/1000 [00:26<01:34,  7.76it/s]\u001b[A\n",
      " 27%|тЦИтЦИтЦЛ       | 274/1000 [00:27<01:22,  8.75it/s]\u001b[A\n",
      " 28%|тЦИтЦИтЦК       | 276/1000 [00:27<01:25,  8.45it/s]\u001b[A\n",
      " 28%|тЦИтЦИтЦК       | 282/1000 [00:27<01:04, 11.17it/s]\u001b[A\n",
      " 28%|тЦИтЦИтЦК       | 285/1000 [00:27<00:53, 13.48it/s]\u001b[A\n",
      " 29%|тЦИтЦИтЦЙ       | 288/1000 [00:27<00:46, 15.25it/s]\u001b[A\n",
      " 29%|тЦИтЦИтЦЙ       | 292/1000 [00:27<00:43, 16.09it/s]\u001b[A\n",
      " 30%|тЦИтЦИтЦЙ       | 295/1000 [00:28<00:42, 16.65it/s]\u001b[A\n",
      " 30%|тЦИтЦИтЦЙ       | 298/1000 [00:28<00:38, 18.31it/s]\u001b[A\n",
      " 30%|тЦИтЦИтЦИ       | 301/1000 [00:28<00:46, 15.13it/s]\u001b[A\n",
      " 30%|тЦИтЦИтЦИ       | 303/1000 [00:28<00:48, 14.43it/s]\u001b[A\n",
      " 31%|тЦИтЦИтЦИ       | 306/1000 [00:28<00:50, 13.80it/s]\u001b[A\n",
      " 31%|тЦИтЦИтЦИ       | 309/1000 [00:29<00:57, 12.01it/s]\u001b[A\n",
      " 31%|тЦИтЦИтЦИ       | 311/1000 [00:29<01:10,  9.80it/s]\u001b[A\n",
      " 31%|тЦИтЦИтЦИтЦП      | 313/1000 [00:29<01:19,  8.63it/s]\u001b[A\n",
      " 32%|тЦИтЦИтЦИтЦП      | 315/1000 [00:29<01:13,  9.31it/s]\u001b[A\n",
      " 32%|тЦИтЦИтЦИтЦП      | 317/1000 [00:30<01:42,  6.66it/s]\u001b[A\n",
      " 32%|тЦИтЦИтЦИтЦП      | 320/1000 [00:30<01:18,  8.63it/s]\u001b[A\n",
      " 32%|тЦИтЦИтЦИтЦП      | 322/1000 [00:30<01:12,  9.35it/s]\u001b[A\n",
      " 32%|тЦИтЦИтЦИтЦП      | 324/1000 [00:30<01:04, 10.51it/s]\u001b[A\n",
      " 33%|тЦИтЦИтЦИтЦО      | 326/1000 [00:31<01:14,  9.10it/s]\u001b[A\n",
      " 33%|тЦИтЦИтЦИтЦО      | 328/1000 [00:31<01:17,  8.69it/s]\u001b[A\n",
      " 33%|тЦИтЦИтЦИтЦО      | 330/1000 [00:31<01:15,  8.92it/s]\u001b[A\n",
      " 33%|тЦИтЦИтЦИтЦО      | 332/1000 [00:32<01:37,  6.86it/s]\u001b[A\n",
      " 33%|тЦИтЦИтЦИтЦО      | 334/1000 [00:32<01:37,  6.82it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦО      | 335/1000 [00:32<01:52,  5.89it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦО      | 337/1000 [00:32<01:30,  7.30it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 338/1000 [00:32<01:46,  6.22it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 339/1000 [00:33<01:58,  5.56it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 341/1000 [00:33<01:48,  6.05it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 342/1000 [00:33<02:05,  5.25it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 343/1000 [00:33<02:14,  4.88it/s]\u001b[A\n",
      " 34%|тЦИтЦИтЦИтЦН      | 345/1000 [00:34<01:43,  6.31it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦН      | 346/1000 [00:34<02:00,  5.43it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦН      | 347/1000 [00:34<01:47,  6.09it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦН      | 349/1000 [00:34<01:41,  6.41it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦМ      | 351/1000 [00:34<01:27,  7.43it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦМ      | 352/1000 [00:34<01:28,  7.35it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦМ      | 353/1000 [00:35<01:46,  6.09it/s]\u001b[A\n",
      " 35%|тЦИтЦИтЦИтЦМ      | 354/1000 [00:35<01:54,  5.64it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦМ      | 355/1000 [00:35<02:05,  5.14it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦМ      | 358/1000 [00:35<01:45,  6.09it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦМ      | 359/1000 [00:36<01:34,  6.77it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦМ      | 361/1000 [00:36<01:26,  7.36it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦМ      | 362/1000 [00:36<01:46,  6.01it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦЛ      | 363/1000 [00:36<01:58,  5.35it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦЛ      | 364/1000 [00:36<01:57,  5.41it/s]\u001b[A\n",
      " 36%|тЦИтЦИтЦИтЦЛ      | 365/1000 [00:37<01:45,  6.03it/s]\u001b[A\n",
      " 37%|тЦИтЦИтЦИтЦЛ      | 368/1000 [00:37<01:30,  6.98it/s]\u001b[A\n",
      " 37%|тЦИтЦИтЦИтЦЛ      | 372/1000 [00:37<01:17,  8.07it/s]\u001b[A\n",
      " 37%|тЦИтЦИтЦИтЦЛ      | 374/1000 [00:37<01:05,  9.55it/s]\u001b[A\n",
      " 38%|тЦИтЦИтЦИтЦК      | 376/1000 [00:38<01:15,  8.30it/s]\u001b[A\n",
      " 38%|тЦИтЦИтЦИтЦК      | 378/1000 [00:38<01:03,  9.75it/s]\u001b[A\n",
      " 38%|тЦИтЦИтЦИтЦК      | 381/1000 [00:38<00:52, 11.78it/s]\u001b[A\n",
      " 38%|тЦИтЦИтЦИтЦК      | 383/1000 [00:38<01:00, 10.17it/s]\u001b[A\n",
      " 38%|тЦИтЦИтЦИтЦК      | 385/1000 [00:38<01:11,  8.58it/s]\u001b[A\n",
      " 39%|тЦИтЦИтЦИтЦК      | 387/1000 [00:39<01:06,  9.23it/s]\u001b[A\n",
      " 39%|тЦИтЦИтЦИтЦЙ      | 389/1000 [00:39<01:11,  8.49it/s]\u001b[A\n",
      " 39%|тЦИтЦИтЦИтЦЙ      | 391/1000 [00:39<01:04,  9.44it/s]\u001b[A\n",
      " 39%|тЦИтЦИтЦИтЦЙ      | 393/1000 [00:39<01:09,  8.74it/s]\u001b[A\n",
      " 40%|тЦИтЦИтЦИтЦЙ      | 395/1000 [00:39<01:00,  9.97it/s]\u001b[A\n",
      " 40%|тЦИтЦИтЦИтЦЙ      | 398/1000 [00:40<00:53, 11.31it/s]\u001b[A\n",
      " 40%|тЦИтЦИтЦИтЦИ      | 400/1000 [00:40<00:50, 11.96it/s]\u001b[A\n",
      " 40%|тЦИтЦИтЦИтЦИ      | 402/1000 [00:40<01:05,  9.06it/s]\u001b[A\n",
      " 40%|тЦИтЦИтЦИтЦИ      | 404/1000 [00:41<01:26,  6.86it/s]\u001b[A\n",
      " 41%|тЦИтЦИтЦИтЦИ      | 406/1000 [00:41<01:23,  7.08it/s]\u001b[A\n",
      " 41%|тЦИтЦИтЦИтЦИ      | 407/1000 [00:41<01:30,  6.57it/s]\u001b[A\n",
      " 41%|тЦИтЦИтЦИтЦИ      | 410/1000 [00:41<01:22,  7.18it/s]\u001b[A\n",
      " 41%|тЦИтЦИтЦИтЦИ      | 411/1000 [00:42<01:38,  5.95it/s]\u001b[A\n",
      " 41%|тЦИтЦИтЦИтЦИтЦП     | 414/1000 [00:42<01:17,  7.58it/s]\u001b[A\n",
      " 42%|тЦИтЦИтЦИтЦИтЦП     | 417/1000 [00:42<01:12,  8.02it/s]\u001b[A\n",
      " 42%|тЦИтЦИтЦИтЦИтЦП     | 419/1000 [00:42<01:25,  6.77it/s]\u001b[A\n",
      " 42%|тЦИтЦИтЦИтЦИтЦП     | 420/1000 [00:43<01:18,  7.38it/s]\u001b[A\n",
      " 42%|тЦИтЦИтЦИтЦИтЦП     | 423/1000 [00:43<01:14,  7.74it/s]\u001b[A\n",
      " 42%|тЦИтЦИтЦИтЦИтЦО     | 425/1000 [00:43<01:02,  9.27it/s]\u001b[A\n",
      " 43%|тЦИтЦИтЦИтЦИтЦО     | 428/1000 [00:43<00:49, 11.66it/s]\u001b[A\n",
      " 43%|тЦИтЦИтЦИтЦИтЦО     | 430/1000 [00:43<00:59,  9.51it/s]\u001b[A\n",
      " 43%|тЦИтЦИтЦИтЦИтЦО     | 432/1000 [00:44<00:53, 10.69it/s]\u001b[A\n",
      " 43%|тЦИтЦИтЦИтЦИтЦО     | 434/1000 [00:44<01:17,  7.29it/s]\u001b[A\n",
      " 44%|тЦИтЦИтЦИтЦИтЦО     | 437/1000 [00:44<01:00,  9.30it/s]\u001b[A\n",
      " 44%|тЦИтЦИтЦИтЦИтЦН     | 439/1000 [00:44<01:03,  8.84it/s]\u001b[A\n",
      " 44%|тЦИтЦИтЦИтЦИтЦН     | 441/1000 [00:45<00:57,  9.68it/s]\u001b[A\n",
      " 44%|тЦИтЦИтЦИтЦИтЦН     | 443/1000 [00:45<01:15,  7.39it/s]\u001b[A\n",
      " 44%|тЦИтЦИтЦИтЦИтЦН     | 445/1000 [00:45<01:09,  8.04it/s]\u001b[A\n",
      " 45%|тЦИтЦИтЦИтЦИтЦН     | 449/1000 [00:45<00:53, 10.25it/s]\u001b[A\n",
      " 45%|тЦИтЦИтЦИтЦИтЦМ     | 452/1000 [00:46<00:53, 10.30it/s]\u001b[A\n",
      " 45%|тЦИтЦИтЦИтЦИтЦМ     | 454/1000 [00:46<01:05,  8.32it/s]\u001b[A\n",
      " 46%|тЦИтЦИтЦИтЦИтЦМ     | 458/1000 [00:46<00:50, 10.70it/s]\u001b[A\n",
      " 46%|тЦИтЦИтЦИтЦИтЦМ     | 460/1000 [00:46<00:58,  9.27it/s]\u001b[A\n",
      " 46%|тЦИтЦИтЦИтЦИтЦЛ     | 463/1000 [00:46<00:49, 10.85it/s]\u001b[A\n",
      " 46%|тЦИтЦИтЦИтЦИтЦЛ     | 465/1000 [00:47<00:54,  9.86it/s]\u001b[A\n",
      " 47%|тЦИтЦИтЦИтЦИтЦЛ     | 467/1000 [00:47<00:58,  9.15it/s]\u001b[A\n",
      " 47%|тЦИтЦИтЦИтЦИтЦЛ     | 469/1000 [00:47<01:04,  8.29it/s]\u001b[A\n",
      " 47%|тЦИтЦИтЦИтЦИтЦЛ     | 471/1000 [00:48<01:18,  6.73it/s]\u001b[A\n",
      " 47%|тЦИтЦИтЦИтЦИтЦЛ     | 472/1000 [00:48<01:32,  5.71it/s]\u001b[A\n",
      " 47%|тЦИтЦИтЦИтЦИтЦЛ     | 474/1000 [00:48<01:13,  7.17it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 476/1000 [00:48<01:05,  8.03it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 478/1000 [00:49<01:12,  7.20it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 480/1000 [00:49<01:11,  7.24it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 481/1000 [00:49<01:28,  5.88it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 483/1000 [00:49<01:24,  6.13it/s]\u001b[A\n",
      " 48%|тЦИтЦИтЦИтЦИтЦК     | 485/1000 [00:50<01:18,  6.53it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦК     | 486/1000 [00:50<01:16,  6.72it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦК     | 487/1000 [00:50<01:29,  5.76it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦЙ     | 488/1000 [00:50<01:38,  5.19it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦЙ     | 491/1000 [00:51<01:24,  6.03it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦЙ     | 492/1000 [00:51<01:15,  6.72it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦЙ     | 493/1000 [00:51<01:30,  5.60it/s]\u001b[A\n",
      " 49%|тЦИтЦИтЦИтЦИтЦЙ     | 494/1000 [00:51<01:36,  5.24it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦЙ     | 495/1000 [00:51<01:38,  5.12it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦЙ     | 496/1000 [00:52<01:45,  4.78it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦЙ     | 497/1000 [00:52<01:51,  4.51it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦЙ     | 498/1000 [00:52<01:54,  4.37it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦЙ     | 499/1000 [00:52<01:54,  4.39it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦИ     | 500/1000 [00:53<01:55,  4.34it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦИ     | 501/1000 [00:53<01:58,  4.20it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦИ     | 502/1000 [00:53<01:57,  4.25it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦИ     | 504/1000 [00:53<01:40,  4.93it/s]\u001b[A\n",
      " 50%|тЦИтЦИтЦИтЦИтЦИ     | 505/1000 [00:54<01:43,  4.76it/s]\u001b[A\n",
      " 51%|тЦИтЦИтЦИтЦИтЦИ     | 506/1000 [00:54<01:47,  4.61it/s]\u001b[A\n",
      " 51%|тЦИтЦИтЦИтЦИтЦИ     | 507/1000 [00:54<01:32,  5.32it/s]\u001b[A\n",
      " 51%|тЦИтЦИтЦИтЦИтЦИ     | 509/1000 [00:54<01:24,  5.80it/s]\u001b[A\n",
      " 51%|тЦИтЦИтЦИтЦИтЦИ     | 511/1000 [00:54<01:09,  6.99it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 515/1000 [00:55<00:57,  8.48it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 517/1000 [00:55<00:55,  8.63it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 519/1000 [00:55<01:03,  7.54it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 520/1000 [00:55<01:18,  6.14it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 521/1000 [00:56<01:27,  5.48it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 523/1000 [00:56<01:22,  5.77it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦП    | 524/1000 [00:56<01:15,  6.27it/s]\u001b[A\n",
      " 52%|тЦИтЦИтЦИтЦИтЦИтЦО    | 525/1000 [00:56<01:21,  5.84it/s]\u001b[A\n",
      " 53%|тЦИтЦИтЦИтЦИтЦИтЦО    | 526/1000 [00:56<01:31,  5.16it/s]\u001b[A\n",
      " 53%|тЦИтЦИтЦИтЦИтЦИтЦО    | 528/1000 [00:57<01:22,  5.70it/s]\u001b[A\n",
      " 53%|тЦИтЦИтЦИтЦИтЦИтЦО    | 529/1000 [00:57<01:12,  6.50it/s]\u001b[A\n",
      " 53%|тЦИтЦИтЦИтЦИтЦИтЦО    | 530/1000 [00:57<01:25,  5.52it/s]\u001b[A\n",
      " 53%|тЦИтЦИтЦИтЦИтЦИтЦО    | 532/1000 [00:57<01:06,  6.99it/s]\u001b[A\n",
      " 54%|тЦИтЦИтЦИтЦИтЦИтЦО    | 535/1000 [00:57<01:00,  7.72it/s]\u001b[A\n",
      " 54%|тЦИтЦИтЦИтЦИтЦИтЦН    | 538/1000 [00:58<00:47,  9.78it/s]\u001b[A\n",
      " 54%|тЦИтЦИтЦИтЦИтЦИтЦН    | 540/1000 [00:58<00:40, 11.42it/s]\u001b[A\n",
      " 54%|тЦИтЦИтЦИтЦИтЦИтЦН    | 542/1000 [00:58<00:41, 10.95it/s]\u001b[A\n",
      " 54%|тЦИтЦИтЦИтЦИтЦИтЦН    | 544/1000 [00:58<00:47,  9.65it/s]\u001b[A\n",
      " 55%|тЦИтЦИтЦИтЦИтЦИтЦН    | 546/1000 [00:58<00:41, 10.97it/s]\u001b[A\n",
      " 55%|тЦИтЦИтЦИтЦИтЦИтЦН    | 549/1000 [00:59<00:41, 10.77it/s]\u001b[A\n",
      " 55%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 551/1000 [00:59<00:57,  7.76it/s]\u001b[A\n",
      " 55%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 553/1000 [00:59<00:47,  9.47it/s]\u001b[A\n",
      " 56%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 556/1000 [00:59<00:38, 11.68it/s]\u001b[A\n",
      " 56%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 558/1000 [00:59<00:38, 11.39it/s]\u001b[A\n",
      " 56%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 560/1000 [01:00<00:38, 11.41it/s]\u001b[A\n",
      " 56%|тЦИтЦИтЦИтЦИтЦИтЦМ    | 562/1000 [01:00<00:42, 10.27it/s]\u001b[A\n",
      " 56%|тЦИтЦИтЦИтЦИтЦИтЦЛ    | 564/1000 [01:00<00:36, 12.02it/s]\u001b[A\n",
      " 57%|тЦИтЦИтЦИтЦИтЦИтЦЛ    | 567/1000 [01:00<00:31, 13.67it/s]\u001b[A\n",
      " 57%|тЦИтЦИтЦИтЦИтЦИтЦЛ    | 569/1000 [01:00<00:34, 12.64it/s]\u001b[A\n",
      " 57%|тЦИтЦИтЦИтЦИтЦИтЦЛ    | 573/1000 [01:01<00:33, 12.80it/s]\u001b[A\n",
      " 58%|тЦИтЦИтЦИтЦИтЦИтЦК    | 578/1000 [01:01<00:26, 16.15it/s]\u001b[A\n",
      " 58%|тЦИтЦИтЦИтЦИтЦИтЦК    | 581/1000 [01:01<00:25, 16.62it/s]\u001b[A\n",
      " 58%|тЦИтЦИтЦИтЦИтЦИтЦК    | 584/1000 [01:01<00:24, 17.12it/s]\u001b[A\n",
      " 59%|тЦИтЦИтЦИтЦИтЦИтЦК    | 587/1000 [01:01<00:23, 17.66it/s]\u001b[A\n",
      " 59%|тЦИтЦИтЦИтЦИтЦИтЦЙ    | 589/1000 [01:01<00:24, 16.71it/s]\u001b[A\n",
      " 59%|тЦИтЦИтЦИтЦИтЦИтЦЙ    | 592/1000 [01:01<00:26, 15.54it/s]\u001b[A\n",
      " 59%|тЦИтЦИтЦИтЦИтЦИтЦЙ    | 594/1000 [01:02<00:26, 15.19it/s]\u001b[A\n",
      " 60%|тЦИтЦИтЦИтЦИтЦИтЦЙ    | 597/1000 [01:02<00:22, 17.74it/s]\u001b[A\n",
      " 60%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 600/1000 [01:02<00:30, 13.20it/s]\u001b[A\n",
      " 60%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 602/1000 [01:02<00:31, 12.71it/s]\u001b[A\n",
      " 60%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 604/1000 [01:03<00:39, 10.15it/s]\u001b[A\n",
      " 61%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 607/1000 [01:03<00:31, 12.37it/s]\u001b[A\n",
      " 61%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 609/1000 [01:03<00:31, 12.38it/s]\u001b[A\n",
      " 61%|тЦИтЦИтЦИтЦИтЦИтЦИ    | 611/1000 [01:03<00:37, 10.36it/s]\u001b[A\n",
      " 61%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 613/1000 [01:03<00:48,  7.98it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 615/1000 [01:04<00:45,  8.40it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 617/1000 [01:04<00:40,  9.47it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 619/1000 [01:04<00:41,  9.09it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 621/1000 [01:05<00:52,  7.16it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦП   | 623/1000 [01:05<00:45,  8.36it/s]\u001b[A\n",
      " 62%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 625/1000 [01:05<00:37,  9.92it/s]\u001b[A\n",
      " 63%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 627/1000 [01:05<00:43,  8.57it/s]\u001b[A\n",
      " 63%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 630/1000 [01:05<00:34, 10.69it/s]\u001b[A\n",
      " 63%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 632/1000 [01:06<00:49,  7.42it/s]\u001b[A\n",
      " 63%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 634/1000 [01:06<01:00,  6.05it/s]\u001b[A\n",
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 635/1000 [01:06<01:08,  5.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 636/1000 [01:06<01:01,  5.97it/s]\u001b[A\n",
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦО   | 637/1000 [01:07<01:05,  5.53it/s]\u001b[A\n",
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦН   | 638/1000 [01:07<01:01,  5.93it/s]\u001b[A\n",
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦН   | 640/1000 [01:07<00:52,  6.88it/s]\u001b[A\n",
      " 64%|тЦИтЦИтЦИтЦИтЦИтЦИтЦН   | 641/1000 [01:07<01:03,  5.64it/s]\u001b[A\n",
      " 65%|тЦИтЦИтЦИтЦИтЦИтЦИтЦН   | 647/1000 [01:07<00:45,  7.72it/s]\u001b[A\n",
      " 65%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 651/1000 [01:08<00:39,  8.78it/s]\u001b[A\n",
      " 65%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 653/1000 [01:08<00:40,  8.61it/s]\u001b[A\n",
      " 66%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 655/1000 [01:08<00:42,  8.18it/s]\u001b[A\n",
      " 66%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 657/1000 [01:09<00:44,  7.64it/s]\u001b[A\n",
      " 66%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 660/1000 [01:09<00:34,  9.75it/s]\u001b[A\n",
      " 66%|тЦИтЦИтЦИтЦИтЦИтЦИтЦМ   | 662/1000 [01:09<00:29, 11.45it/s]\u001b[A\n",
      " 67%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЛ   | 667/1000 [01:09<00:23, 14.38it/s]\u001b[A\n",
      " 67%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЛ   | 670/1000 [01:09<00:27, 11.97it/s]\u001b[A\n",
      " 67%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЛ   | 673/1000 [01:09<00:22, 14.40it/s]\u001b[A\n",
      " 68%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 676/1000 [01:10<00:27, 11.77it/s]\u001b[A\n",
      " 68%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 678/1000 [01:10<00:26, 11.95it/s]\u001b[A\n",
      " 68%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 680/1000 [01:10<00:25, 12.36it/s]\u001b[A\n",
      " 68%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 682/1000 [01:10<00:40,  7.91it/s]\u001b[A\n",
      " 68%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 684/1000 [01:11<00:50,  6.23it/s]\u001b[A\n",
      " 69%|тЦИтЦИтЦИтЦИтЦИтЦИтЦК   | 687/1000 [01:11<00:39,  8.02it/s]\u001b[A\n",
      " 69%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЙ   | 690/1000 [01:11<00:31,  9.78it/s]\u001b[A\n",
      " 69%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЙ   | 694/1000 [01:11<00:24, 12.27it/s]\u001b[A\n",
      " 70%|тЦИтЦИтЦИтЦИтЦИтЦИтЦЙ   | 697/1000 [01:11<00:20, 14.72it/s]\u001b[A\n",
      " 70%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 700/1000 [01:12<00:17, 17.14it/s]\u001b[A\n",
      " 70%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 703/1000 [01:12<00:18, 16.21it/s]\u001b[A\n",
      " 71%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 706/1000 [01:12<00:22, 13.03it/s]\u001b[A\n",
      " 71%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 708/1000 [01:12<00:20, 14.43it/s]\u001b[A\n",
      " 71%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 710/1000 [01:12<00:22, 13.13it/s]\u001b[A\n",
      " 71%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИ   | 712/1000 [01:13<00:23, 12.18it/s]\u001b[A\n",
      " 71%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП  | 714/1000 [01:13<00:29,  9.76it/s]\u001b[A\n",
      " 72%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП  | 716/1000 [01:13<00:25, 11.09it/s]\u001b[A\n",
      " 72%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП  | 719/1000 [01:13<00:26, 10.45it/s]\u001b[A\n",
      " 72%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП  | 721/1000 [01:13<00:22, 12.14it/s]\u001b[A\n",
      " 72%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП  | 723/1000 [01:14<00:31,  8.87it/s]\u001b[A\n",
      " 72%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 725/1000 [01:14<00:37,  7.36it/s]\u001b[A\n",
      " 73%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 726/1000 [01:14<00:45,  6.00it/s]\u001b[A\n",
      " 73%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 730/1000 [01:15<00:37,  7.12it/s]\u001b[A\n",
      " 73%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 732/1000 [01:15<00:38,  6.94it/s]\u001b[A\n",
      " 74%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 735/1000 [01:15<00:32,  8.17it/s]\u001b[A\n",
      " 74%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО  | 737/1000 [01:16<00:40,  6.46it/s]\u001b[A\n",
      " 74%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН  | 739/1000 [01:16<00:40,  6.46it/s]\u001b[A\n",
      " 74%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН  | 742/1000 [01:16<00:30,  8.42it/s]\u001b[A\n",
      " 74%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН  | 744/1000 [01:16<00:26,  9.67it/s]\u001b[A\n",
      " 75%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН  | 747/1000 [01:16<00:22, 11.21it/s]\u001b[A\n",
      " 75%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 750/1000 [01:17<00:18, 13.49it/s]\u001b[A\n",
      " 75%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 752/1000 [01:17<00:17, 14.45it/s]\u001b[A\n",
      " 75%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 754/1000 [01:17<00:23, 10.41it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 756/1000 [01:17<00:21, 11.17it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 758/1000 [01:17<00:26,  8.99it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 760/1000 [01:18<00:30,  7.85it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ  | 762/1000 [01:18<00:31,  7.57it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 763/1000 [01:18<00:39,  5.95it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 764/1000 [01:18<00:38,  6.06it/s]\u001b[A\n",
      " 76%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 765/1000 [01:19<00:44,  5.28it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 766/1000 [01:19<00:48,  4.78it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 767/1000 [01:19<00:49,  4.71it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 770/1000 [01:19<00:39,  5.75it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 771/1000 [01:20<00:46,  4.93it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 772/1000 [01:20<00:49,  4.60it/s]\u001b[A\n",
      " 77%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ  | 773/1000 [01:20<00:49,  4.56it/s]\u001b[A\n",
      " 78%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК  | 776/1000 [01:20<00:40,  5.47it/s]\u001b[A\n",
      " 78%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК  | 778/1000 [01:21<00:32,  6.89it/s]\u001b[A\n",
      " 78%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК  | 783/1000 [01:21<00:23,  9.24it/s]\u001b[A\n",
      " 79%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК  | 786/1000 [01:21<00:21,  9.88it/s]\u001b[A\n",
      " 79%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ  | 788/1000 [01:21<00:18, 11.38it/s]\u001b[A\n",
      " 79%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ  | 791/1000 [01:21<00:15, 13.29it/s]\u001b[A\n",
      " 79%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ  | 793/1000 [01:21<00:14, 14.11it/s]\u001b[A\n",
      " 80%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ  | 798/1000 [01:21<00:11, 17.75it/s]\u001b[A\n",
      " 80%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ  | 801/1000 [01:22<00:12, 16.17it/s]\u001b[A\n",
      " 80%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ  | 804/1000 [01:22<00:11, 17.73it/s]\u001b[A\n",
      " 81%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ  | 809/1000 [01:22<00:08, 21.57it/s]\u001b[A\n",
      " 81%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП | 813/1000 [01:22<00:07, 24.89it/s]\u001b[A\n",
      " 82%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП | 817/1000 [01:22<00:07, 24.99it/s]\u001b[A\n",
      " 82%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП | 820/1000 [01:22<00:08, 20.24it/s]\u001b[A\n",
      " 82%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП | 823/1000 [01:23<00:08, 20.50it/s]\u001b[A\n",
      " 83%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО | 826/1000 [01:23<00:07, 22.27it/s]\u001b[A\n",
      " 83%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО | 829/1000 [01:23<00:07, 22.97it/s]\u001b[A\n",
      " 83%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО | 832/1000 [01:23<00:13, 12.76it/s]\u001b[A\n",
      " 84%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО | 835/1000 [01:24<00:13, 11.99it/s]\u001b[A\n",
      " 84%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН | 842/1000 [01:24<00:09, 15.82it/s]\u001b[A\n",
      " 85%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН | 846/1000 [01:24<00:15, 10.23it/s]\u001b[A\n",
      " 85%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН | 849/1000 [01:25<00:13, 11.58it/s]\u001b[A\n",
      " 85%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ | 852/1000 [01:25<00:11, 13.26it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ | 855/1000 [01:25<00:12, 11.76it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ | 857/1000 [01:25<00:11, 12.87it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ | 859/1000 [01:26<00:18,  7.80it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ | 861/1000 [01:26<00:20,  6.91it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 863/1000 [01:26<00:23,  5.81it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 864/1000 [01:27<00:26,  5.22it/s]\u001b[A\n",
      " 86%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 865/1000 [01:27<00:28,  4.72it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 866/1000 [01:27<00:29,  4.51it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 867/1000 [01:27<00:25,  5.27it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 868/1000 [01:28<00:28,  4.70it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 869/1000 [01:28<00:29,  4.45it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 870/1000 [01:28<00:28,  4.64it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 871/1000 [01:28<00:29,  4.40it/s]\u001b[A\n",
      " 87%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ | 873/1000 [01:29<00:25,  4.89it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 875/1000 [01:29<00:22,  5.59it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 876/1000 [01:29<00:24,  5.02it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 877/1000 [01:29<00:22,  5.45it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 879/1000 [01:29<00:18,  6.49it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 882/1000 [01:30<00:14,  8.41it/s]\u001b[A\n",
      " 88%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 884/1000 [01:30<00:14,  7.93it/s]\u001b[A\n",
      " 89%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК | 886/1000 [01:30<00:12,  9.19it/s]\u001b[A\n",
      " 89%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 888/1000 [01:30<00:11,  9.39it/s]\u001b[A\n",
      " 89%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 890/1000 [01:30<00:11,  9.84it/s]\u001b[A\n",
      " 89%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 892/1000 [01:31<00:11,  9.03it/s]\u001b[A\n",
      " 89%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 894/1000 [01:31<00:11,  9.39it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 896/1000 [01:31<00:12,  8.65it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 897/1000 [01:31<00:15,  6.44it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ | 899/1000 [01:32<00:15,  6.36it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 900/1000 [01:32<00:17,  5.56it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 901/1000 [01:32<00:19,  5.13it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 902/1000 [01:32<00:20,  4.78it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 903/1000 [01:32<00:17,  5.48it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 904/1000 [01:33<00:19,  5.00it/s]\u001b[A\n",
      " 90%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 905/1000 [01:33<00:20,  4.68it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 907/1000 [01:33<00:18,  5.05it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 908/1000 [01:33<00:19,  4.79it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 909/1000 [01:34<00:19,  4.55it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 910/1000 [01:34<00:21,  4.27it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ | 911/1000 [01:34<00:21,  4.18it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 913/1000 [01:34<00:17,  4.95it/s]\u001b[A\n",
      " 91%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 914/1000 [01:35<00:18,  4.70it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 915/1000 [01:35<00:18,  4.55it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 916/1000 [01:35<00:18,  4.58it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 918/1000 [01:35<00:14,  5.82it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 919/1000 [01:36<00:15,  5.36it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 920/1000 [01:36<00:15,  5.03it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 921/1000 [01:36<00:15,  5.09it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 923/1000 [01:36<00:13,  5.65it/s]\u001b[A\n",
      " 92%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦП| 924/1000 [01:36<00:15,  4.92it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 927/1000 [01:37<00:11,  6.25it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 928/1000 [01:37<00:13,  5.46it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 929/1000 [01:37<00:14,  5.07it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 931/1000 [01:37<00:11,  6.18it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 933/1000 [01:37<00:09,  6.88it/s]\u001b[A\n",
      " 93%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 934/1000 [01:38<00:11,  5.85it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦО| 935/1000 [01:38<00:12,  5.06it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 938/1000 [01:38<00:09,  6.48it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 940/1000 [01:38<00:08,  6.68it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 942/1000 [01:39<00:08,  6.64it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 943/1000 [01:39<00:07,  7.22it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 944/1000 [01:39<00:08,  6.46it/s]\u001b[A\n",
      " 94%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 945/1000 [01:39<00:09,  5.66it/s]\u001b[A\n",
      " 95%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦН| 947/1000 [01:39<00:07,  6.82it/s]\u001b[A\n",
      " 95%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 950/1000 [01:40<00:05,  8.84it/s]\u001b[A\n",
      " 95%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 953/1000 [01:40<00:04, 10.16it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 955/1000 [01:40<00:06,  7.27it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 957/1000 [01:41<00:06,  6.17it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 958/1000 [01:41<00:07,  5.34it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦМ| 960/1000 [01:41<00:06,  5.83it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 963/1000 [01:41<00:04,  7.51it/s]\u001b[A\n",
      " 96%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 965/1000 [01:41<00:04,  8.14it/s]\u001b[A\n",
      " 97%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 967/1000 [01:42<00:04,  8.00it/s]\u001b[A\n",
      " 97%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 969/1000 [01:42<00:03,  8.66it/s]\u001b[A\n",
      " 97%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 971/1000 [01:42<00:03,  7.54it/s]\u001b[A\n",
      " 97%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 973/1000 [01:42<00:03,  7.62it/s]\u001b[A\n",
      " 97%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЛ| 974/1000 [01:43<00:04,  6.16it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 976/1000 [01:43<00:03,  7.05it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 977/1000 [01:43<00:03,  7.48it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 978/1000 [01:43<00:03,  6.22it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 980/1000 [01:43<00:02,  6.72it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 982/1000 [01:44<00:02,  7.66it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 983/1000 [01:44<00:02,  7.02it/s]\u001b[A\n",
      " 98%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 985/1000 [01:44<00:01,  8.09it/s]\u001b[A\n",
      " 99%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦК| 986/1000 [01:44<00:02,  6.34it/s]\u001b[A\n",
      " 99%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ| 988/1000 [01:44<00:01,  7.66it/s]\u001b[A\n",
      " 99%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ| 993/1000 [01:44<00:00, 10.18it/s]\u001b[A\n",
      "100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦЙ| 997/1000 [01:45<00:00, 12.04it/s]\u001b[A\n",
      "100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 1000/1000 [01:45<00:00,  9.49it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 0.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores, score = bleu(mt_test, model, hindi, english, device)\n",
    "all_scores, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adverse-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "suburban-astronomy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f522003ab793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhindi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bleu score {score * 100:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2a886ada98b7>\u001b[0m in \u001b[0;36mbleu\u001b[0;34m(data, model, german, english, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "overhead-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "hypothesis2 = 'It is to insure the troops forever hearing the activity guidebook that party direct'\n",
    "\n",
    "reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "reference2 = 'It is the guiding principle which guarantees the military forces always being under the command of the Party'\n",
    "reference3 = 'It is the practical guide for the army always to heed the directions of the party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate.meteor_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southeast-mathematics",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ddc0fcfad492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeteor_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "round(translate.meteor_score([reference1, reference2, reference3], hypothesis1),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-opposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-orientation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-appraisal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
