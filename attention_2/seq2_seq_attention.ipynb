{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "generous-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from inltk.inltk import tokenize\n",
    "from time import time\n",
    "\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quarterly-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~।]'''\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    text = re.sub(str_punct,'',text).lower()\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "criminal-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n",
    "\n",
    "\n",
    "hindi = data.Field(tokenize=tokenize_hi)\n",
    "english = data.Field(tokenize=tokenize_eng)\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strong-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load fastext simple embedding with 300d\n",
    "# english.build_vocab(\n",
    "#     mt_train, \n",
    "#     vectors='fasttext.simple.300d'\n",
    "# )\n",
    "# # get the vocab instance\n",
    "# vocab = mt_train.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "massive-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "english.build_vocab(mt_train, vectors='glove.6B.300d')\n",
    "vocab = english.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fiscal-chaos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "supreme-convergence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors[304].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "monthly-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f25b0200c90>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'the': 2,\n",
       "             'of': 3,\n",
       "             'to': 4,\n",
       "             'and': 5,\n",
       "             'in': 6,\n",
       "             'a': 7,\n",
       "             'as': 8,\n",
       "             'be': 9,\n",
       "             'is': 10,\n",
       "             'minister': 11,\n",
       "             'by': 12,\n",
       "             'he': 13,\n",
       "             'jsk': 14,\n",
       "             'prime': 15,\n",
       "             'with': 16,\n",
       "             '’s': 17,\n",
       "             'an': 18,\n",
       "             'development': 19,\n",
       "             'for': 20,\n",
       "             'india': 21,\n",
       "             'on': 22,\n",
       "             'said': 23,\n",
       "             'can': 24,\n",
       "             'has': 25,\n",
       "             'health': 26,\n",
       "             'house': 27,\n",
       "             'maxima': 28,\n",
       "             'modi': 29,\n",
       "             'queen': 30,\n",
       "             'that': 31,\n",
       "             'will': 32,\n",
       "             'yojana': 33,\n",
       "             'act': 34,\n",
       "             'also': 35,\n",
       "             'amendments': 36,\n",
       "             'at': 37,\n",
       "             'autonomous': 38,\n",
       "             'body': 39,\n",
       "             'centre': 40,\n",
       "             'department': 41,\n",
       "             'from': 42,\n",
       "             'initiatives': 43,\n",
       "             'its': 44,\n",
       "             'lokayuktas': 45,\n",
       "             'lokpal': 46,\n",
       "             'narendra': 47,\n",
       "             'was': 48,\n",
       "             '–': 49,\n",
       "             '2013': 50,\n",
       "             '44': 51,\n",
       "             'being': 52,\n",
       "             'bima': 53,\n",
       "             'case': 54,\n",
       "             'committee': 55,\n",
       "             'democracy': 56,\n",
       "             'discussed': 57,\n",
       "             'finance': 58,\n",
       "             'fund': 59,\n",
       "             'funding': 60,\n",
       "             'given': 61,\n",
       "             'government': 62,\n",
       "             'had': 63,\n",
       "             'her': 64,\n",
       "             'hospitals': 65,\n",
       "             'hub': 66,\n",
       "             'inaugurated': 67,\n",
       "             'interacted': 68,\n",
       "             'it': 69,\n",
       "             'lok': 70,\n",
       "             'mahajan': 71,\n",
       "             'mantri': 72,\n",
       "             'ministry': 73,\n",
       "             'new': 74,\n",
       "             'one': 75,\n",
       "             'opportunity': 76,\n",
       "             'parliament': 77,\n",
       "             'people': 78,\n",
       "             'population': 79,\n",
       "             'pradhan': 80,\n",
       "             'public': 81,\n",
       "             'ran': 82,\n",
       "             'sabha': 83,\n",
       "             'section': 84,\n",
       "             'she': 85,\n",
       "             'speaker': 86,\n",
       "             'stabilization': 87,\n",
       "             'strategies': 88,\n",
       "             'such': 89,\n",
       "             'this': 90,\n",
       "             'today': 91,\n",
       "             'union': 92,\n",
       "             'various': 93,\n",
       "             'walk': 94,\n",
       "             'wellness': 95,\n",
       "             'which': 96,\n",
       "             'would': 97,\n",
       "             '1860': 98,\n",
       "             '2016': 99,\n",
       "             '315': 100,\n",
       "             'ab': 101,\n",
       "             'accessed': 102,\n",
       "             'achieved': 103,\n",
       "             'activities': 104,\n",
       "             'addition': 105,\n",
       "             'address': 106,\n",
       "             'addresses': 107,\n",
       "             'administered': 108,\n",
       "             'advance': 109,\n",
       "             'advocate': 110,\n",
       "             'all': 111,\n",
       "             'although': 112,\n",
       "             'ambedkar': 113,\n",
       "             'ambitious': 114,\n",
       "             'amendment': 115,\n",
       "             'ancient': 116,\n",
       "             'appreciated': 117,\n",
       "             'apprehensions': 118,\n",
       "             'approval': 119,\n",
       "             'approved': 120,\n",
       "             'approximately': 121,\n",
       "             'asha': 122,\n",
       "             'aspirational': 123,\n",
       "             'assistance': 124,\n",
       "             'assurance': 125,\n",
       "             'assured': 126,\n",
       "             'atal': 127,\n",
       "             'ayushman': 128,\n",
       "             'basis': 129,\n",
       "             'been': 130,\n",
       "             'behalf': 131,\n",
       "             'behind': 132,\n",
       "             'beneficial': 133,\n",
       "             'benefit': 134,\n",
       "             'bharat': 135,\n",
       "             'bijapur': 136,\n",
       "             'bill': 137,\n",
       "             'briefed': 138,\n",
       "             'cabinet': 139,\n",
       "             'cancer': 140,\n",
       "             'capacity': 141,\n",
       "             'categories': 142,\n",
       "             'chaired': 143,\n",
       "             'chhattisgarh': 144,\n",
       "             'closed': 145,\n",
       "             'closure': 146,\n",
       "             'comparable': 147,\n",
       "             'concerns': 148,\n",
       "             'conducting': 149,\n",
       "             'consequential': 150,\n",
       "             'continue': 151,\n",
       "             'continuous': 152,\n",
       "             'cooperation': 153,\n",
       "             'corporate': 154,\n",
       "             'corporation': 155,\n",
       "             'corporator': 156,\n",
       "             'course': 157,\n",
       "             'dhan': 158,\n",
       "             'different': 159,\n",
       "             'difficulties': 160,\n",
       "             'directly': 161,\n",
       "             'dissolve': 162,\n",
       "             'district': 163,\n",
       "             'dohfw': 164,\n",
       "             'eightterm': 165,\n",
       "             'endeavoured': 166,\n",
       "             'energy': 167,\n",
       "             'enhancing': 168,\n",
       "             'entire': 169,\n",
       "             'establish': 170,\n",
       "             'everyone': 171,\n",
       "             'existence': 172,\n",
       "             'experience': 173,\n",
       "             'expost': 174,\n",
       "             'expressed': 175,\n",
       "             'faced': 176,\n",
       "             'facto': 177,\n",
       "             'feel': 178,\n",
       "             'few': 179,\n",
       "             'financial': 180,\n",
       "             'first': 181,\n",
       "             'firsttime': 182,\n",
       "             'friend': 183,\n",
       "             'full': 184,\n",
       "             'functions': 185,\n",
       "             'funds': 186,\n",
       "             'gatah': 187,\n",
       "             'global': 188,\n",
       "             'grants': 189,\n",
       "             'guidance': 190,\n",
       "             'hence': 191,\n",
       "             'hmcpf': 192,\n",
       "             'hospital': 193,\n",
       "             'hour': 194,\n",
       "             'immense': 195,\n",
       "             'implementing': 196,\n",
       "             'inauguration': 197,\n",
       "             'inclusion': 198,\n",
       "             'inclusive': 199,\n",
       "             'indian': 200,\n",
       "             'indore': 201,\n",
       "             'introducing': 202,\n",
       "             'itself': 203,\n",
       "             'jan': 204,\n",
       "             'jangla': 205,\n",
       "             'jayanti': 206,\n",
       "             'jeevan': 207,\n",
       "             'jyoti': 208,\n",
       "             'kingdom': 209,\n",
       "             'last': 210,\n",
       "             'launch': 211,\n",
       "             'leaders': 212,\n",
       "             'leave': 213,\n",
       "             'life': 214,\n",
       "             'mahajaney': 215,\n",
       "             'mahajans': 216,\n",
       "             'majesty': 217,\n",
       "             'managing': 218,\n",
       "             'mandate': 219,\n",
       "             'many': 220,\n",
       "             'mark': 221,\n",
       "             'medical': 222,\n",
       "             'meet': 223,\n",
       "             'members': 224,\n",
       "             'met': 225,\n",
       "             'mp': 226,\n",
       "             'mps': 227,\n",
       "             'municipal': 228,\n",
       "             'name': 229,\n",
       "             'necessary': 230,\n",
       "             'netherlands': 231,\n",
       "             'no': 232,\n",
       "             'not': 233,\n",
       "             'number': 234,\n",
       "             'occasion': 235,\n",
       "             'old': 236,\n",
       "             'ones': 237,\n",
       "             'organizes': 238,\n",
       "             'our': 239,\n",
       "             'over': 240,\n",
       "             'panthaya': 241,\n",
       "             'part': 242,\n",
       "             'path': 243,\n",
       "             'patient': 244,\n",
       "             'pension': 245,\n",
       "             'per': 246,\n",
       "             'placed': 247,\n",
       "             'play': 248,\n",
       "             'populations': 249,\n",
       "             'powerful': 250,\n",
       "             'present': 251,\n",
       "             'private': 252,\n",
       "             'proceedings': 253,\n",
       "             'programme': 254,\n",
       "             'progress': 255,\n",
       "             'provide': 256,\n",
       "             'provides': 257,\n",
       "             'provision': 258,\n",
       "             'provisions': 259,\n",
       "             'receive': 260,\n",
       "             'recommended': 261,\n",
       "             'registration': 262,\n",
       "             'require': 263,\n",
       "             'required': 264,\n",
       "             'role': 265,\n",
       "             'say': 266,\n",
       "             'secretarygeneral': 267,\n",
       "             'servants': 268,\n",
       "             'serve': 269,\n",
       "             'several': 270,\n",
       "             'shall': 271,\n",
       "             'shri': 272,\n",
       "             'significant': 273,\n",
       "             'since': 274,\n",
       "             'sixteenth': 275,\n",
       "             'smt': 276,\n",
       "             'societies': 277,\n",
       "             'society': 278,\n",
       "             'special': 279,\n",
       "             'sra': 280,\n",
       "             'successfully': 281,\n",
       "             'suggests': 282,\n",
       "             'sumitra': 283,\n",
       "             'superintendents': 284,\n",
       "             'suraksha': 285,\n",
       "             'taken': 286,\n",
       "             'target': 287,\n",
       "             'temple': 288,\n",
       "             'texts': 289,\n",
       "             'their': 290,\n",
       "             'then': 291,\n",
       "             'there': 292,\n",
       "             'these': 293,\n",
       "             'through': 294,\n",
       "             'timeline': 295,\n",
       "             'traditions': 296,\n",
       "             'transferred': 297,\n",
       "             'two': 298,\n",
       "             'un': 299,\n",
       "             'vast': 300,\n",
       "             'vested': 301,\n",
       "             'visiting': 302,\n",
       "             'who': 303,\n",
       "             'workers': 304,\n",
       "             'world': 305,\n",
       "             'year': 306,\n",
       "             'years': 307,\n",
       "             'yen': 308,\n",
       "             '“': 309,\n",
       "             '”': 310})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "circular-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "metropolitan-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "instrumental-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vocab['are'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "included-latest",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-844120929c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'vectors'"
     ]
    }
   ],
   "source": [
    "vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "english.build_vocab(mt_train, max_size=15000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 2\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0\n",
    "\n",
    "print(f'length of input_size_encoder is {input_size_encoder}')\n",
    "\n",
    "print(f'length of input_size_decoder is {input_size_decoder}')\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs_attn_smp/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "     dataset=mt_train, batch_size=batch_size,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)), device=device)\n",
    "\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "model_file_name = \"checkpoint_attn_v2_smp.pth.tar\"\n",
    "\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(model_file_name), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thick-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input_size_encoder is 120\n",
      "length of input_size_decoder is 2\n",
      "[Epoch 0 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Total time taken for the epoch number 0 was 1.8525021076202393\n",
      "[Epoch 1 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "Total time taken for the epoch number 1 was 4.1723010540008545\n",
      "[Epoch 2 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "Total time taken for the epoch number 2 was 4.865523338317871\n",
      "[Epoch 3 / 100]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "Total time taken for the epoch number 3 was 5.644169092178345\n",
      "[Epoch 4 / 100]\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3485ebf241f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         }\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c3485ebf241f>\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, filename)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Saving checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "#     spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "#         tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "        sentence = re.sub(str_punct,'',sentence).lower()\n",
    "        tokens = tokenize(sentence, \"hi\")\n",
    "        # tokens = [i.lower() for i in tokenize(sentence, \"hi\")]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=model_file_name):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "\n",
    "sentence = \"प्रधानमंत्री ने कहा कि भारत में केंद्र सरकार बुनियादी ढांचे पर ध्यान केंद्रित कर रही है।\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    st = time()\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, hindi, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1  \n",
    "    \n",
    "    print(f'Total time taken for the epoch number {epoch} was {time() - st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-holmes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-cleaners",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-mystery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
