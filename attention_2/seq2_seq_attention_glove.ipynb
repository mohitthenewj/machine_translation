{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "divided-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchtext.data import Field\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abroad-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_torch/pmindia.v1.hi-en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hydraulic-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['english_sentence', 'hindi_sentence'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "processed-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "def tokenize_hi(text):\n",
    "    return [re.sub(str_punct,'',tok).lower() for tok in tokenize(text, \"hi\")]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [re.sub(str_punct,'',tok.text).lower() for tok in spacy_eng.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "involved-evolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "other-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_field = Field(\n",
    "#     tokenize='basic_english', \n",
    "#     lower=True\n",
    "# )\n",
    "\n",
    "text_field = Field(\n",
    "    tokenize=tokenize_eng, \n",
    "    lower=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "complicated-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_field = Field(sequential=False, use_vocab=False)\n",
    "# sadly have to apply preprocess manually\n",
    "preprocessed_text = df['english_sentence'].apply(lambda x: text_field.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "marine-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56831"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "nutritional-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fastext simple embedding with 300d\n",
    "text_field.build_vocab(\n",
    "    preprocessed_text, \n",
    "    vectors='glove.6B.300d',max_size=17000, min_freq=2\n",
    ")\n",
    "# get the vocab instance\n",
    "vocab = text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "settled-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_glove = vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "practical-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in dict_glove if type(i) is not float  and type(int(i)) == int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "laughing-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_default_unk_index',\n",
       " 'extend',\n",
       " 'freqs',\n",
       " 'itos',\n",
       " 'load_vectors',\n",
       " 'lookup_indices',\n",
       " 'set_vectors',\n",
       " 'stoi',\n",
       " 'unk_index',\n",
       " 'vectors']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "psychological-rubber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17002, 300])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "classified-climate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors[-10001].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "written-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intended-notion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# known token, in my case print 12\n",
    "print(vocab['are'])\n",
    "# unknown token, will print 0\n",
    "print(vocab['crazy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "foster-coupon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field\n",
    "text_field = Field(\n",
    "    sequential=True,\n",
    "    tokenize='basic_english', \n",
    "    fix_length=5,\n",
    "    lower=True\n",
    ")\n",
    "label_field = Field(sequential=False, use_vocab=False)\n",
    "# sadly have to apply preprocess manually\n",
    "preprocessed_text = df['text'].apply(\n",
    "    lambda x: text_field.preprocess(x)\n",
    ")\n",
    "# load fastext simple embedding with 300d\n",
    "text_field.build_vocab(\n",
    "    preprocessed_text, \n",
    "    vectors='glove.6B.300d'\n",
    ")\n",
    "# get the vocab instance\n",
    "vocab = text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civilian-imagination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "descending-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'The news-test2011 set has three additional Czech translations that you may want to use. You can download them from Charles University.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "practical-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "basic-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "# def tokenize_hi(text):\n",
    "#     return [re.sub(str_punct,'',tok).lower() for tok in tokenize(text, \"hi\")]\n",
    "\n",
    "\n",
    "# def tokenize_eng(text):\n",
    "#     return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "# hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "# english = Field(\n",
    "#     tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    "# )\n",
    "\n",
    "# train_data = TranslationDataset('./data_torch/data_sm',\n",
    "#     exts=(\".hi\", \".en\"), fields=(hindi, english)\n",
    "# )\n",
    "\n",
    "# hindi.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "# english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "homeless-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "def tokenize_hi(text):\n",
    "    return [re.sub(str_punct,'',tok).lower() for tok in tokenize(text, \"hi\")]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [re.sub(str_punct,'',tok.text).lower() for tok in spacy_eng.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "drawn-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "experienced-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = data.Field(tokenize=tokenize_hi)\n",
    "english = data.Field(tokenize=tokenize_eng)\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))\n",
    "hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "english.build_vocab(mt_train, max_size=15000, min_freq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blond-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('mt_train.pickle', 'wb') as handle:\n",
    "#     pickle.dump(mt_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guilty-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('src.pickle', 'rb') as handle:\n",
    "#     src_loaded = pickle.load(handle)\n",
    "\n",
    "# with open('trg.pickle', 'rb') as handle:\n",
    "#     trg_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "million-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naked-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 200\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "asian-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corporate-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "first-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator = BucketIterator.splits(\n",
    "#     (mt_train),\n",
    "#     batch_size=batch_size,\n",
    "#     sort_within_batch=True,\n",
    "#     sort_key=lambda x: len(x.src),\n",
    "#     device=device)\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "     dataset=mt_train, batch_size=batch_size,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perceived-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tribal-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "analyzed-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sorted-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "civic-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "#     spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "#         tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "        tokens = [i.lower() for i in tokenize(sentence, \"hi\")]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recent-screw",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = \"рдкреНрд░рдзрд╛рдирдордВрддреНрд░реА рдиреЗ рдХрд╣рд╛ рдХрд┐ рднрд╛рд░рдд рдореЗрдВ рдХреЗрдВрджреНрд░ рд╕рд░рдХрд╛рд░ рдмреБрдирд┐рдпрд╛рджреА рдврд╛рдВрдЪреЗ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░ рд░рд╣реА рд╣реИред\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "detailed-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('./data_torch/train.csv')\n",
    "\n",
    "# df.columns\n",
    "\n",
    "# # df['hi_len'] = \n",
    "# sum(df['english_sentence'].apply(lambda x : len(x)) <=40)\n",
    "\n",
    "# df = pd.read_excel('./data_torch/autocat_data.xlsx')\n",
    "\n",
    "# df.shape\n",
    "\n",
    "# sum(df['title'].apply(lambda x : len(x)) <=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "opposed-postage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['democracy', '44', 'prime', 'its', 'department', 'india', 'has', 'india', 'yojana', 'with', 'being', 'funding', 'queen', 'committee', 'ministry', 'india', 'yojana', 'with', 'being', 'funding', 'queen', 'committee', 'ministry', 'india', 'yojana', 'with', 'being', 'funding', 'queen', 'committee', 'ministry', 'india', 'yojana', 'with', 'being', 'funding', 'queen', 'committee', 'ministry', 'india', 'yojana', 'with', 'being', 'funding', 'queen', 'committee', 'ministry', 'india', 'yojana', 'with']\n",
      "[Epoch 1 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "[Epoch 2 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "[Epoch 3 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "[Epoch 4 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "[Epoch 5 / 200]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['<unk>']\n",
      "[Epoch 6 / 200]\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0a1d26573a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         }\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2a886ada98b7>\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, filename)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"my_checkpoint.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Saving checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# Copy to a buffer, then serialize that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, hindi, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "korean-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "plain-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_torch/pmindia.v1.hi-en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "crude-arthritis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['тЦБрдкреНрд░рдзрд╛рдирдордВрддреНрд░реА',\n",
       " 'тЦБрдиреЗ',\n",
       " 'тЦБрдХрд╣рд╛',\n",
       " 'тЦБрдХрд┐',\n",
       " 'тЦБрднрд╛рд░рдд',\n",
       " 'тЦБрдореЗрдВ',\n",
       " 'тЦБрдХреЗрдВрджреНрд░',\n",
       " 'тЦБрд╕рд░рдХрд╛рд░',\n",
       " 'тЦБрдмреБрдирд┐рдпрд╛рджреА',\n",
       " 'тЦБрдврд╛рдВрдЪреЗ',\n",
       " 'тЦБрдкрд░',\n",
       " 'тЦБрдзреНрдпрд╛рди',\n",
       " 'тЦБрдХреЗрдВрджреНрд░рд┐рдд',\n",
       " 'тЦБрдХрд░',\n",
       " 'тЦБрд░рд╣реА',\n",
       " 'тЦБрд╣реИ',\n",
       " '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_hi(df['hindi_sentence'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "overhead-officer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
