{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improving-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "from inltk.inltk import tokenize\n",
    "from time import time\n",
    "\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  \n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "raising-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchtext.data.metrics import bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "champion-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"checkpoint_attn_v2.pth.tar\"\n",
    "# tf_board_path = f\"runs_attn_v2/loss_plot\"\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "# pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "\n",
    "# text = [re.sub(str_punct,'',txt).lower() for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "transparent-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hi(text):\n",
    "    text = tokenize(text, \"hi\")\n",
    "    text = [tok for tok in text if not re.search(str_punct,tok)]\n",
    "    return text\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    text = [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "    text = [tok.lower() for tok in text if not re.search(str_punct,tok)]\n",
    "    return text\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "innovative-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "#     spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "#         tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "        sentence = re.sub(str_punct,'',sentence).lower()\n",
    "        tokens = tokenize(sentence, \"hi\")\n",
    "        # tokens = [i.lower() for i in tokenize(sentence, \"hi\")]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in tqdm(data):\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return (targets, outputs)\n",
    "#     return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=model_file_name):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mighty-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n",
    "\n",
    "hindi = data.Field(tokenize=tokenize_hi)\n",
    "english = data.Field(tokenize=tokenize_eng)\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))\n",
    "hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "english.build_vocab(mt_train, max_size=15000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "foreign-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hindi_v2.pickle', 'wb') as handle:\n",
    "    pickle.dump(hindi, handle)\n",
    "    \n",
    "with open('english_v2.pickle', 'wb') as handle:\n",
    "    pickle.dump(english, handle)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bronze-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input_size_encoder is 12796\n",
      "length of input_size_decoder is 13005\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model = True\n",
    "save_model = False\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(hindi.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0\n",
    "\n",
    "print(f'length of input_size_encoder is {input_size_encoder}')\n",
    "\n",
    "print(f'length of input_size_decoder is {input_size_decoder}')\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "# writer = SummaryWriter(tf_board_path)\n",
    "step = 0\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "     dataset=mt_train, batch_size=batch_size,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)), device=device)\n",
    "\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "advised-construction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(model_file_name), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fewer-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"рдкреНрд░рдзрд╛рдирдордВрддреНрд░реА рдиреЗ рдХрд╣рд╛ рдХрд┐ рднрд╛рд░рдд рдореЗрдВ рдХреЗрдВрджреНрд░ рд╕рд░рдХрд╛рд░ рдмреБрдирд┐рдпрд╛рджреА рдврд╛рдВрдЪреЗ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░ рд░рд╣реА рд╣реИред\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "final-millennium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that',\n",
       " 'on',\n",
       " 'the',\n",
       " 'infrastructure',\n",
       " 'the',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'said',\n",
       " 'that',\n",
       " 'the',\n",
       " 'union',\n",
       " 'government',\n",
       " 'in',\n",
       " 'india',\n",
       " 'is',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'infrastructure',\n",
       " 'creation',\n",
       " 'in',\n",
       " 'india',\n",
       " 'infrastructure',\n",
       " 'creation',\n",
       " 'in',\n",
       " 'india',\n",
       " 'the',\n",
       " 'union',\n",
       " 'government',\n",
       " 'of',\n",
       " 'india',\n",
       " 'is',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'infrastructure',\n",
       " 'creation',\n",
       " 'in',\n",
       " 'india',\n",
       " 'and',\n",
       " 'infrastructure',\n",
       " 'creation',\n",
       " 'in',\n",
       " 'india',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'infrastructure',\n",
       " 'creation',\n",
       " 'in',\n",
       " 'india',\n",
       " 'and',\n",
       " 'abroad']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, hindi, english, device, max_length=50\n",
    ")\n",
    "translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "intermediate-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindi = Field(tokenize=tokenize_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "# english = Field(\n",
    "#     tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    "# )\n",
    "\n",
    "# hindi = data.Field(tokenize=tokenize_hi)\n",
    "# english = data.Field(tokenize=tokenize_eng)\n",
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_val', exts=('.hi', '.en'),\n",
    "     fields=(hindi, english))\n",
    "# hindi.build_vocab(mt_train, max_size=15000, min_freq=2)\n",
    "# english.build_vocab(mt_train, max_size=15000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "composed-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 1000/1000 [01:39<00:00, 10.10it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = bleu(mt_test, model, hindi, english, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "certain-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val = pairs[0]\n",
    "outputs_val = pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "expanded-warrant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prime',\n",
       " 'minister',\n",
       " 'modi',\n",
       " 'the',\n",
       " 'top',\n",
       " 'officials',\n",
       " 'of',\n",
       " 'india',\n",
       " 'тАЩs',\n",
       " 'all',\n",
       " 'with',\n",
       " 'the',\n",
       " 'administrative',\n",
       " 'of',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'government',\n",
       " 'for',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'local',\n",
       " 'and',\n",
       " 'and',\n",
       " 'state',\n",
       " 'in',\n",
       " 'strengthening',\n",
       " 'the',\n",
       " 'strength',\n",
       " 'of',\n",
       " 'the',\n",
       " 'government',\n",
       " 'of',\n",
       " 'india',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'for',\n",
       " 'restoration',\n",
       " 'of',\n",
       " 'the',\n",
       " 'government',\n",
       " 'of',\n",
       " 'india',\n",
       " 'the',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'work']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "apart-genealogy",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-e0766fb66965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences_corpus\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclipped_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mclipped_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclipped_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "bleu_score(candidate_corpus = outputs_val[400:900], references_corpus= target_val[400:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "brilliant-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = [[i] for i in target_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sixth-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "patient-helicopter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prime minister modi the top officials of india тАЩs all with the administrative of of the union government for the development of local and and state in strengthening the strength of the government of india as well as for restoration of the government of india the sides of work'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(outputs_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bacterial-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence ='he exhorted the muslim community in india to take maximum advantage of the skill development schemes and programmes being initiated by the union government'\n",
    "sentence_out = 'he exhorted the prime minister modi the muslim community in india to take maximum advantage of the skill development schemes and programmes being initiated by the union government'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "flying-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ambient-shore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964276313782"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(candidate_corpus, references_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "buried-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8182183504104614"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(candidate_corpus = [ sentence_out.split(' ')], references_corpus=[[sentence.split(' ')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "streaming-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(candidate_corpus = [sentence.split(' '), sentence.split(' ')], references_corpus=[[sentence.split(' ')],[sentence.split(' ')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "limiting-conservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(candidate_corpus=sentence.split(' '), references_corpus = sentence.split(' '), max_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "athletic-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(candidate_corpus=[['he',\n",
    "   'exhorted',\n",
    "   'the',\n",
    "   'muslim',\n",
    "   'community',\n",
    "   'in',\n",
    "   'india',\n",
    "   'to',\n",
    "   'take',\n",
    "   'maximum',\n",
    "   'advantage',\n",
    "   'of',\n",
    "   'the',\n",
    "   'skill',\n",
    "   'development',\n",
    "   'schemes',\n",
    "   'and',\n",
    "   'programmes',\n",
    "   'being',\n",
    "   'initiated',\n",
    "   'by',\n",
    "   'the',\n",
    "   'union',\n",
    "   'government'], ['he',\n",
    "   'exhorted',\n",
    "   'the',\n",
    "   'muslim',\n",
    "   'community',\n",
    "   'in',\n",
    "   'india',\n",
    "   'to',\n",
    "   'take',\n",
    "   'maximum',\n",
    "   'advantage',\n",
    "   'of',\n",
    "   'the',\n",
    "   'skill',\n",
    "   'development',\n",
    "   'schemes',\n",
    "   'and',\n",
    "   'programmes',\n",
    "   'being',\n",
    "   'initiated',\n",
    "   'by',\n",
    "   'the',\n",
    "   'union',\n",
    "   'government']], references_corpus=[['he',\n",
    "   'exhorted',\n",
    "   'the',\n",
    "   'muslim',\n",
    "   'community',\n",
    "   'in',\n",
    "   'india',\n",
    "   'to',\n",
    "   'take',\n",
    "   'maximum',\n",
    "   'advantage',\n",
    "   'of',\n",
    "   'the',\n",
    "   'skill',\n",
    "   'development',\n",
    "   'schemes',\n",
    "   'and',\n",
    "   'programmes',\n",
    "   'being',\n",
    "   'initiated',\n",
    "   'by',\n",
    "   'the',\n",
    "   'union',\n",
    "   'government'], ['he',\n",
    "   'exhorted',\n",
    "   'the',\n",
    "   'muslim',\n",
    "   'community',\n",
    "   'in',\n",
    "   'india',\n",
    "   'to',\n",
    "   'take',\n",
    "   'maximum',\n",
    "   'advantage',\n",
    "   'of',\n",
    "   'the',\n",
    "   'skill',\n",
    "   'development',\n",
    "   'schemes',\n",
    "   'and',\n",
    "   'programmes',\n",
    "   'being',\n",
    "   'initiated',\n",
    "   'by',\n",
    "   'the',\n",
    "   'union',\n",
    "   'government']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "operational-scale",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c1e00db5e8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "bleu_score(outputs_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "original-relevance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['he',\n",
       "   'exhorted',\n",
       "   'the',\n",
       "   'muslim',\n",
       "   'community',\n",
       "   'in',\n",
       "   'india',\n",
       "   'to',\n",
       "   'take',\n",
       "   'maximum',\n",
       "   'advantage',\n",
       "   'of',\n",
       "   'the',\n",
       "   'skill',\n",
       "   'development',\n",
       "   'schemes',\n",
       "   'and',\n",
       "   'programmes',\n",
       "   'being',\n",
       "   'initiated',\n",
       "   'by',\n",
       "   'the',\n",
       "   'union',\n",
       "   'government']],\n",
       " ['prime',\n",
       "  'minister',\n",
       "  'modi',\n",
       "  'the',\n",
       "  'top',\n",
       "  'officials',\n",
       "  'of',\n",
       "  'india',\n",
       "  'тАЩs',\n",
       "  'all',\n",
       "  'with',\n",
       "  'the',\n",
       "  'administrative',\n",
       "  'of',\n",
       "  'of',\n",
       "  'the',\n",
       "  'union',\n",
       "  'government',\n",
       "  'for',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'local',\n",
       "  'and',\n",
       "  'and',\n",
       "  'state',\n",
       "  'in',\n",
       "  'strengthening',\n",
       "  'the',\n",
       "  'strength',\n",
       "  'of',\n",
       "  'the',\n",
       "  'government',\n",
       "  'of',\n",
       "  'india',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'for',\n",
       "  'restoration',\n",
       "  'of',\n",
       "  'the',\n",
       "  'government',\n",
       "  'of',\n",
       "  'india',\n",
       "  'the',\n",
       "  'sides',\n",
       "  'of',\n",
       "  'work'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0][0], pairs[1][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     st = time()\n",
    "#     print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "#     if save_model:\n",
    "#         checkpoint = {\n",
    "#             \"state_dict\": model.state_dict(),\n",
    "#             \"optimizer\": optimizer.state_dict(),\n",
    "#         }\n",
    "#         save_checkpoint(checkpoint)\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     translated_sentence = translate_sentence(\n",
    "#         model, sentence, hindi, english, device, max_length=50\n",
    "#     )\n",
    "\n",
    "#     print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "#     model.train()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(train_iterator):\n",
    "#         # Get input and targets and get to cuda\n",
    "#         inp_data = batch.src.to(device)\n",
    "#         target = batch.trg.to(device)\n",
    "\n",
    "#         # Forward prop\n",
    "#         output = model(inp_data, target)\n",
    "\n",
    "#         # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "#         # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "#         # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "#         # way that we have output_words * batch_size that we want to send in into\n",
    "#         # our cost function, so we need to do some reshapin. While we're at it\n",
    "#         # Let's also remove the start token while we're at it\n",
    "#         output = output[1:].reshape(-1, output.shape[2])\n",
    "#         target = target[1:].reshape(-1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # Back prop\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "#         # within a healthy range\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "#         # Gradient descent step\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Plot to tensorboard\n",
    "#         writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "#         step += 1  \n",
    "    \n",
    "#     print(f'Total time taken for the epoch number {epoch} was {time() - st}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
