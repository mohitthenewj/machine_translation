{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# raw_data = './data_torch/pmindia.v1.hi-en.csv'\n",
    "\n",
    "# df = pd.read_csv(raw_data)\n",
    "\n",
    "# str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "# # remove very long sentences and sentences where translations are \n",
    "# # not of roughly equal length\n",
    "# df['eng_len'] = df['english_sentence'].str.count(' ')\n",
    "# df['hi_len'] = df['hindi_sentence'].str.count(' ')\n",
    "\n",
    "# # %matplotlib inline\n",
    "\n",
    "# # df.eng_len.plot()\n",
    "\n",
    "# # df.head()\n",
    "\n",
    "# # df.shape\n",
    "\n",
    "# df.query('hi_len < 50 & eng_len < 50').shape\n",
    "\n",
    "# df = df.query('hi_len < 50 & eng_len < 50')\n",
    "# df = df.query('hi_len < eng_len * 1.5 & hi_len * 1.5 > eng_len')\n",
    "# df['english_sentence'] = df['english_sentence'].apply(lambda x : re.sub(str_punct,'',x))\n",
    "# df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : re.sub(str_punct,'',x))\n",
    "\n",
    "# # np.savetxt(r'./data_torch/data.en', df.english_sentence.head(30000), fmt='%s')\n",
    "# # np.savetxt(r'./data_torch/data.hi', df.hindi_sentence.head(30000), fmt='%s')\n",
    "\n",
    "# np.savetxt(r'./data_torch/data_sm.en', df.english_sentence.head(30), fmt='%s')\n",
    "# np.savetxt(r'./data_torch/data_sm.hi', df.hindi_sentence.head(30), fmt='%s')\n",
    "\n",
    "\n",
    "# # np.savetxt(r'./data_torch/data_val.en', df.english_sentence.tail(1000), fmt='%s')\n",
    "# # np.savetxt(r'./data_torch/data_val.hi', df.hindi_sentence.tail(1000), fmt='%s')\n",
    "\n",
    "# # df.sample(frac=0.1).shape\n",
    "# # df = df.sample(frac=0.01)\n",
    "\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# # # create train and validation set \n",
    "# # train, val = train_test_split(df[['english_sentence', 'hindi_sentence']], test_size=0.2)\n",
    "# # train.shape, val.shape\n",
    "# # train.to_csv(\"./data_torch/train.csv\", index=False)\n",
    "# # val.to_csv(\"./data_torch/val.csv\", index=False)\n",
    "\n",
    "# # train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from inltk.inltk import tokenize\n",
    "# from inltk.inltk import setup\n",
    "# setup('hi')\n",
    "from torchtext import datasets\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = data.Field(tokenize=tokenize_hi)\n",
    "trg = data.Field(tokenize=tokenize_eng)\n",
    "# mt_train = datasets.TranslationDataset(\n",
    "#      fields=(src, trg))\n",
    "\n",
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_val', exts=('.hi', '.en'),\n",
    "     fields=(src, trg))\n",
    "\n",
    "# src.build_vocab(mt_train, max_size=20000, min_freq=2)\n",
    "# trg.build_vocab(mt_train, max_size=20000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('src.pickle', 'rb') as handle:\n",
    "    src_loaded = pickle.load(handle)\n",
    "\n",
    "with open('trg.pickle', 'rb') as handle:\n",
    "    trg_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(trg.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model hyperparameters\n",
    "# load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = 12800\n",
    "input_size_decoder = 15042\n",
    "output_size = 15042\n",
    "\n",
    "# input_size_encoder = len(src.vocab)\n",
    "# input_size_decoder = len(trg.vocab)\n",
    "# output_size = len(trg.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'input_size_encoder is {input_size_encoder}')\n",
    "# print(f'input_size_decoder is {input_size_decoder}')\n",
    "# print(f'output_size is {output_size}')\n",
    "\n",
    "# sys.exit(0)\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# pad_idx = trg.vocab.stoi[\"<pad>\"]\n",
    "pad_idx = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(12800, 300)\n",
       "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(15042, 300)\n",
       "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "    (fc): Linear(in_features=1024, out_features=15042, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = True\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_torch/pmindia.v1.hi-en.csv')\n",
    "str_punct = '''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]'''\n",
    "\n",
    "df['eng_len'] = df['english_sentence'].str.count(' ')\n",
    "df['hi_len'] = df['hindi_sentence'].str.count(' ')\n",
    "# df.query('hi_len < 50 & eng_len < 50').shape\n",
    "\n",
    "df = df.query('hi_len < 50 & eng_len < 50')\n",
    "df = df.query('hi_len < eng_len * 1.5 & hi_len * 1.5 > eng_len')\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x : re.sub(str_punct,'',x))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : re.sub(str_punct,'',x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдПрдХ рд╕реНрд╡рд╛рдпрд╢рд╛рд╕реА рдирд┐рдХрд╛рдп рдХреЗ рд░реВрдк рдореЗрдВ рдЬреЗрдПрд╕рдХреЗ рдХреЛ рдмрдВрдж рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдирд┐рдзрд┐ рдХреЗ рддреМрд░ рдкрд░ рдЙрд╕рдХрд╛ рдХрд╛рдордХрд╛рдЬ рд╡рд┐рднрд╛рдЧ рджреНрд╡рд╛рд░рд╛ рд╕рдВрднрд╡ рд╣реИ'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hindi_sentence'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>eng_len</th>\n",
       "      <th>hi_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An advance is placed with the Medical Superint...</td>\n",
       "      <td>рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреН...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since the DoHFW provides funds to the hospital...</td>\n",
       "      <td>рдЪреВрдВрдХрд┐ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдПрд╡рдВ рдкрд░рд┐рд╡рд╛рд░ рдХрд▓реНрдпрд╛рдг рд╡рд┐рднрд╛рдЧ рдЕрд╕реНрдкрддрд╛...</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Managing Committee of RAN Society will meet to...</td>\n",
       "      <td>рдЖрд░рдПрдПрди рд╕реЛрд╕рд╛рдпрдЯреА рдХреА рдкреНрд░рдмрдВрдз рд╕рдорд┐рддрд┐ рд╕реЛрд╕рд╛рдпрдЯреА рдкрдВрдЬреАрдХрд░рдг ...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In addition to this Health MinisterтАЩs Cancer P...</td>\n",
       "      <td>рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдордВрддреНрд░реА рдХреЗ рдХреИрдВрд╕рд░ рд░реЛрдЧреА рдирд┐рдзрд┐...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The timeline required for this is one year</td>\n",
       "      <td>рдЗрд╕рдХреЗ рд▓рд┐рдП рдПрдХ рд╡рд░реНрд╖ рдХрд╛ рд╕рдордп рд░рдЦрд╛ рдЧрдпрд╛ рд╣реИ</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0  An advance is placed with the Medical Superint...   \n",
       "1  Since the DoHFW provides funds to the hospital...   \n",
       "3  Managing Committee of RAN Society will meet to...   \n",
       "4  In addition to this Health MinisterтАЩs Cancer P...   \n",
       "5         The timeline required for this is one year   \n",
       "\n",
       "                                      hindi_sentence  eng_len  hi_len  \n",
       "0  рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреН...       20      19  \n",
       "1  рдЪреВрдВрдХрд┐ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдПрд╡рдВ рдкрд░рд┐рд╡рд╛рд░ рдХрд▓реНрдпрд╛рдг рд╡рд┐рднрд╛рдЧ рдЕрд╕реНрдкрддрд╛...       19      22  \n",
       "3  рдЖрд░рдПрдПрди рд╕реЛрд╕рд╛рдпрдЯреА рдХреА рдкреНрд░рдмрдВрдз рд╕рдорд┐рддрд┐ рд╕реЛрд╕рд╛рдпрдЯреА рдкрдВрдЬреАрдХрд░рдг ...       21      21  \n",
       "4  рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдордВрддреНрд░реА рдХреЗ рдХреИрдВрд╕рд░ рд░реЛрдЧреА рдирд┐рдзрд┐...       16      15  \n",
       "5                 рдЗрд╕рдХреЗ рд▓рд┐рдП рдПрдХ рд╡рд░реНрд╖ рдХрд╛ рд╕рдордп рд░рдЦрд╛ рдЧрдпрд╛ рд╣реИ        7       8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдПрдХ рд╕реНрд╡рд╛рдпрд╢рд╛рд╕реА рдирд┐рдХрд╛рдп рдХреЗ рд░реВрдк рдореЗрдВ рдЬреЗрдПрд╕рдХреЗ рдХреЛ рдмрдВрдж рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдирд┐рдзрд┐ рдХреЗ рддреМрд░ рдкрд░ рдЙрд╕рдХрд╛ рдХрд╛рдордХрд╛рдЬ рд╡рд┐рднрд╛рдЧ рджреНрд╡рд╛рд░рд╛ рд╕рдВрднрд╡ рд╣реИ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "an area of a Autonomous data can a can be administered as the of the the as a provisions of the the 6th Committee of the 6th of the Vice Committee profession for the profession of the <unk>\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][10]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рдкреНрд░рдзрд╛рдирдордВрддреНрд░реА рдиреЗ рдХрд╣рд╛ рдХрд┐ рднрд╛рд░рдд рдореЗрдВ рдХреЗрдВрджреНрд░ рд╕рд░рдХрд╛рд░ рдмреБрдирд┐рдпрд╛рджреА рдврд╛рдВрдЪреЗ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░ рд░рд╣реА рд╣реИ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "conservation transparency in India Digital India initiative in the Prime Minister added India in India based India procurement infrastructure crop City based etc by the country infrastructure system etc in turn builds in a <unk>\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][100]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рдЖрдкрдХрд╛ рд╕реНрдиреЗрд╣ рдореБрдЭреЗ рдХрдбрд╝реА рдореЗрд╣рдирдд рдХрд░рддреЗ рд░рд╣рдиреЗ рдХреА рдкреНрд░реЗрд░рдгрд╛ рджреЗрддрд╛ рд╣реИтАЭ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "all have been given their words to their dear <unk>\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][1000]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рдЗрд╕реА рдХрд╛рд░реНрдпрдХреНрд░рдо рдореЗрдВ рд╢реНрд░реА рдирд░реЗрдиреНрджреНрд░ рдореЛрджреА рдорд┐рд░реНрдЬрд╛рдкреБрд░ рдореЗрдбрд┐рдХрд▓ рдХреЙрд▓реЗрдЬ рдХреА рдЖрдзрд╛рд░рд╢рд┐рд▓рд╛ рд░рдЦреЗрдВрдЧреЗ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "to <unk>\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][4000]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "6 рдмреНрд░рд┐рдХреНтАНрд╕ рд╢рд┐рдЦрд░ рд╕рдореНтАНрдореЗрд▓рди рдХреЗ рдкрд╣рд▓реЗ рдЪрдХреНрд░ рдореЗрдВ рд╕рд╛рдореВрд╣рд┐рдХ рд░реВрдк рд╕реЗ рд╣рдорд╛рд░реА рдЕрд░реНрдерд╡реНтАНрдпрд╡рд╕реНтАНрдерд╛рдУрдВ рдиреЗ рдЖрд░реНрдерд┐рдХ рд╕рдВрдХрдЯ рд╡реИрд╢реНтАНрд╡рд┐рдХ рд╡рд┐рддреНтАНрддреАрдп рд╕рдВрдХрдЯ рд╕реЗ рдЙрдмрд░рдиреЗ рдХреЗ рдЗрдВрдЬрди рдХреЗ рд░реВрдк рдореЗрдВ рдЕрдкрдиреА рд╕реНрдерд┐рддрд┐ рдордЬрдмреВрдд рдХреА рд╣реИ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "of the launch of BRICS <unk>\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][6000]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рд╣рдо рд╕рд╣рдХрд╛рд░реА рд╕рдВрдШрд╡рд╛рдж рдХреА рдмрд╛рдд рдХрд░рддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди рдкреНрд░рддрд┐рд╕реНтАНрдкрд░реНрдзреА рд╕рдВрдШрд╡рд╛рдж рдХреА рднреА рдЪрд░реНрдЪрд╛ рдХрд░рддреЗ рд╣реИрдВ рдЬрд╣рд╛рдВ рд░рд╛рдЬреНтАНрдпреЛрдВ рдХреЛ рдирд┐рд╡реЗрд╢ рдФрд░ рдиреМрдХрд░рд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП рдПрдХрджреВрд╕рд░реЗ рд╕реЗ рд╕реНтАНрдкрд░реНрдзрд╛ рдХрд░рдХреЗ рд╢реНрд░реЗрд╖реНтАНрдарддрд╛ рд╕рд╛рдмрд┐рдд рдХрд░рдиреА рд╣реЛрдЧреА\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "we are also do do we continue but each other we so that we issues and investments continue to support with differences and support to cooperative and with the common common investments there heritage and other cooperative cooperative heritage there be shared their exports and achieving shared than the top\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][7000]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49846, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>eng_len</th>\n",
       "      <th>hi_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An advance is placed with the Medical Superint...</td>\n",
       "      <td>рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреН...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since the DoHFW provides funds to the hospital...</td>\n",
       "      <td>рдЪреВрдВрдХрд┐ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдПрд╡рдВ рдкрд░рд┐рд╡рд╛рд░ рдХрд▓реНрдпрд╛рдг рд╡рд┐рднрд╛рдЧ рдЕрд╕реНрдкрддрд╛...</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Managing Committee of RAN Society will meet to...</td>\n",
       "      <td>рдЖрд░рдПрдПрди рд╕реЛрд╕рд╛рдпрдЯреА рдХреА рдкреНрд░рдмрдВрдз рд╕рдорд┐рддрд┐ рд╕реЛрд╕рд╛рдпрдЯреА рдкрдВрдЬреАрдХрд░рдг ...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In addition to this Health MinisterтАЩs Cancer P...</td>\n",
       "      <td>рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдордВрддреНрд░реА рдХреЗ рдХреИрдВрд╕рд░ рд░реЛрдЧреА рдирд┐рдзрд┐...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The timeline required for this is one year</td>\n",
       "      <td>рдЗрд╕рдХреЗ рд▓рд┐рдП рдПрдХ рд╡рд░реНрд╖ рдХрд╛ рд╕рдордп рд░рдЦрд╛ рдЧрдпрд╛ рд╣реИ</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11258</th>\n",
       "      <td>They are helping me stay in close touch with p...</td>\n",
       "      <td>рдпреЗ рд▓реЛрдЧреЛрдВ рдХреЗ рдХрд░реАрдм рдмрдиреЗ рд░рд╣рдиреЗ рдореЗрдВ рдореЗрд░реА рдорджрдж рдХрд░ рд░рд╣реЗ рд╣реИрдВ</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11259</th>\n",
       "      <td>I learn a great deal from their suggestions an...</td>\n",
       "      <td>рдореИрдВрдиреЗ рдЙрдирдХреЗ рд╕реБрдЭрд╛рд╡реЛрдВ рдПрд╡рдВ рд╢рд┐рдХрд╛рдпрддреЛрдВ рд╕реЗ рдХрд╛рдлреА рдХреБрдЫ рд╕реА...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>We want to free our citizens from the burden o...</td>\n",
       "      <td>рд╣рдо рдкреНрд░рддреНтАНрдпреЗрдХ рдХрд╛рд░реНрдпрд╛рд▓рдп рдореЗрдВ рдЕрдкрдиреЗ рдирд╛рдЧрд░рд┐рдХреЛрдВ рдХреЛ рдЕрддреН...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11262</th>\n",
       "      <td>We will set up a digital locker for every citi...</td>\n",
       "      <td>рд╣рдо рдирд┐рдЬреА рджрд╕реНтАНрддрд╛рд╡реЗрдЬреЛрдВ рдХреЛ рд╕реНтАНрдЯреЛрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░рдд...</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>We have set up Ebiz portal to make approvals f...</td>\n",
       "      <td>рд╣рдордиреЗ рдХрд╛рд░реЛрдмрд╛рд░рд┐рдпреЛрдВ рдПрд╡рдВ рдирд╛рдЧрд░рд┐рдХреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдореЛрджрдиреЛрдВ...</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows ├Ч 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english_sentence  \\\n",
       "0      An advance is placed with the Medical Superint...   \n",
       "1      Since the DoHFW provides funds to the hospital...   \n",
       "3      Managing Committee of RAN Society will meet to...   \n",
       "4      In addition to this Health MinisterтАЩs Cancer P...   \n",
       "5             The timeline required for this is one year   \n",
       "...                                                  ...   \n",
       "11258  They are helping me stay in close touch with p...   \n",
       "11259  I learn a great deal from their suggestions an...   \n",
       "11260  We want to free our citizens from the burden o...   \n",
       "11262  We will set up a digital locker for every citi...   \n",
       "11263  We have set up Ebiz portal to make approvals f...   \n",
       "\n",
       "                                          hindi_sentence  eng_len  hi_len  \n",
       "0      рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреН...       20      19  \n",
       "1      рдЪреВрдВрдХрд┐ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдПрд╡рдВ рдкрд░рд┐рд╡рд╛рд░ рдХрд▓реНрдпрд╛рдг рд╡рд┐рднрд╛рдЧ рдЕрд╕реНрдкрддрд╛...       19      22  \n",
       "3      рдЖрд░рдПрдПрди рд╕реЛрд╕рд╛рдпрдЯреА рдХреА рдкреНрд░рдмрдВрдз рд╕рдорд┐рддрд┐ рд╕реЛрд╕рд╛рдпрдЯреА рдкрдВрдЬреАрдХрд░рдг ...       21      21  \n",
       "4      рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдордВрддреНрд░реА рдХреЗ рдХреИрдВрд╕рд░ рд░реЛрдЧреА рдирд┐рдзрд┐...       16      15  \n",
       "5                     рдЗрд╕рдХреЗ рд▓рд┐рдП рдПрдХ рд╡рд░реНрд╖ рдХрд╛ рд╕рдордп рд░рдЦрд╛ рдЧрдпрд╛ рд╣реИ        7       8  \n",
       "...                                                  ...      ...     ...  \n",
       "11258  рдпреЗ рд▓реЛрдЧреЛрдВ рдХреЗ рдХрд░реАрдм рдмрдиреЗ рд░рд╣рдиреЗ рдореЗрдВ рдореЗрд░реА рдорджрдж рдХрд░ рд░рд╣реЗ рд╣реИрдВ        9      11  \n",
       "11259  рдореИрдВрдиреЗ рдЙрдирдХреЗ рд╕реБрдЭрд╛рд╡реЛрдВ рдПрд╡рдВ рд╢рд┐рдХрд╛рдпрддреЛрдВ рд╕реЗ рдХрд╛рдлреА рдХреБрдЫ рд╕реА...        9       9  \n",
       "11260  рд╣рдо рдкреНрд░рддреНтАНрдпреЗрдХ рдХрд╛рд░реНрдпрд╛рд▓рдп рдореЗрдВ рдЕрдкрдиреЗ рдирд╛рдЧрд░рд┐рдХреЛрдВ рдХреЛ рдЕрддреН...       15      16  \n",
       "11262  рд╣рдо рдирд┐рдЬреА рджрд╕реНтАНрддрд╛рд╡реЗрдЬреЛрдВ рдХреЛ рд╕реНтАНрдЯреЛрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░рдд...       19      25  \n",
       "11263  рд╣рдордиреЗ рдХрд╛рд░реЛрдмрд╛рд░рд┐рдпреЛрдВ рдПрд╡рдВ рдирд╛рдЧрд░рд┐рдХреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдореЛрджрдиреЛрдВ...       28      32  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is \n",
      " \n",
      "рдпреЗ рд▓реЛрдЧреЛрдВ рдХреЗ рдХрд░реАрдм рдмрдиреЗ рд░рд╣рдиреЗ рдореЗрдВ рдореЗрд░реА рдорджрдж рдХрд░ рд░рд╣реЗ рд╣реИрдВ\n",
      " \n",
      " translated sentence is \n",
      " \n",
      "it of social security in this field of adversity in the society also also be an live in the also in their life as festival as to the festival of life child as child it as child and savings to be it as to the people savings to the women\n"
     ]
    }
   ],
   "source": [
    "org_sentence = df['hindi_sentence'][11258]\n",
    "tr_sentence = ' '.join(translate_sentence(model, org_sentence, src_loaded, trg_loaded, device))\n",
    "print(f'Original sentence is \\n \\n{org_sentence}\\n \\n translated sentence is \\n \\n{tr_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('src.pickle', 'wb') as handle:\n",
    "#     pickle.dump(src, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('trg.pickle', 'wb') as handle:\n",
    "#     pickle.dump(trg, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "with open('src.pickle', 'rb') as handle:\n",
    "    src_loaded = pickle.load(handle)\n",
    "\n",
    "with open('trg.pickle', 'rb') as handle:\n",
    "    trg_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size_encoder is 12800\n",
      "input_size_decoder is 15042\n",
      "output_size is 15042\n",
      "pad_idx is 1\n",
      "Total time taken for data loading was >> 0.0006196498870849609\n"
     ]
    }
   ],
   "source": [
    "# sentence = 'рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХреЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗ'\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "print(f'input_size_encoder is {input_size_encoder}')\n",
    "print(f'input_size_decoder is {input_size_decoder}')\n",
    "print(f'output_size is {output_size}')\n",
    "print(f'pad_idx is {pad_idx}')\n",
    "\n",
    "print(f'Total time taken for data loading was >> {time.time() -st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(src, trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for example in data:\n",
    "        try:\n",
    "            src = vars(example)[\"src\"]\n",
    "            trg = vars(example)[\"trg\"]\n",
    "\n",
    "            prediction = translate_sentence(model, src, german, english, device)\n",
    "            prediction = prediction[:-1] # remove <eos> token\n",
    "\n",
    "            targets.append([trg])\n",
    "            outputs.append(prediction)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e, example)\n",
    "    scores = 0\n",
    "    try:\n",
    "        scores = bleu_score(outputs, targets)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'got the exception from bleu score , >>{e}')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "score_test = bleu(mt_test[1:400], model, src_loaded, trg_loaded, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got the exception from bleu score , >>index 4 is out of bounds for dimension 0 with size 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7858e1a34b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscore_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_loaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_loaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bleu score for test data is {score_test*100:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total time taken for score_test was >> {time.time() -st}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "print(f\"Bleu score for test data is {score_test*100:.2f}\")\n",
    "print(f'Total time taken for score_test was >> {time.time() -st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8b95dcc84854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bleu score for train data is {score_train*100:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total time taken for score_train was >> {time.time() -st}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk_ext/nlp/seq2seq_vanilla/utils.py\u001b[0m in \u001b[0;36mbleu\u001b[0;34m(data, model, german, english, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "score_train = bleu(mt_train[1:100], model, src, trg, device)\n",
    "print(f\"Bleu score for train data is {score_train*100:.2f}\")\n",
    "print(f'Total time taken for score_train was >> {time.time() -st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from inltk.inltk import tokenize\n",
    "# from inltk.inltk import setup\n",
    "# setup('hi')\n",
    "from torchtext import datasets\n",
    "from torchtext import data\n",
    "\n",
    "\n",
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "src = data.Field(tokenize=tokenize_hi)\n",
    "trg = data.Field(tokenize=tokenize_eng)\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_sm', exts=('.hi', '.en'),\n",
    "     fields=(src, trg))\n",
    "\n",
    "src.build_vocab(mt_train, max_size=20000, min_freq=2)\n",
    "trg.build_vocab(mt_train, max_size=20000, min_freq=2)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(trg.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = len(src.vocab)\n",
    "input_size_decoder = len(trg.vocab)\n",
    "output_size = len(trg.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "train_iter = data.BucketIterator(\n",
    "     dataset=mt_train, batch_size=32,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = trg.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "load_model = False\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "\n",
    "sentence = 'рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХреЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch is 0/1000]\n",
      "=> Saving checkpoint\n",
      "Translated sentence is: \n",
      " <unk>\n",
      "[Epoch is 1/1000]\n",
      "=> Saving checkpoint\n",
      "Translated sentence is: \n",
      " <unk>\n",
      "[Epoch is 2/1000]\n",
      "=> Saving checkpoint\n",
      "Translated sentence is: \n",
      " <unk>\n",
      "[Epoch is 3/1000]\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e4c346ae7b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[Epoch is {epoch}/{num_epochs}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/disk_ext/nlp/seq2seq_torch/utils.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, filename)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"my_checkpoint.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Saving checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/inltk/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'[Epoch is {epoch}/{num_epochs}]')\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(\n",
    "        model=model, sentence= sentence, german=src, english=trg, device=device, max_length=50\n",
    "    )\n",
    "    translated_sentence =  ' '.join(translated_sentence)\n",
    "    print(f'Translated sentence is: \\n {translated_sentence}')\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_iter):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        \n",
    "        output = model(inp_data, target)\n",
    "        \n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"training_loss\", loss, global_step=step)\n",
    "        step+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '''An advance is placed with  [ the Medical Superintendents of such hospitals who then provide assistance on a case to case basis.'''\n",
    "\n",
    "\n",
    "re.sub('''[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ред]''','',txt)\n",
    "\n",
    "df.english_sentence[0]\n",
    "\n",
    "\n",
    "df.head(1)['hindi_sentence'][0]\n",
    "\n",
    "# df = df.sample(frac=0.01)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # create train and validation set \n",
    "# train, val = train_test_split(df[['english_sentence', 'hindi_sentence']], test_size=0.2)\n",
    "\n",
    "# train.to_csv(\"./data_torch/train.csv\", index=False)\n",
    "# val.to_csv(\"./data_torch/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from inltk.inltk import tokenize\n",
    "\n",
    "# from inltk.inltk import setup\n",
    "# setup('hi')\n",
    "\n",
    "from torchtext import datasets\n",
    "\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hi(text):\n",
    "    return tokenize(text, \"hi\")\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = data.Field(tokenize=tokenize_hi)\n",
    "trg = data.Field(tokenize=tokenize_eng)\n",
    "mt_train = datasets.TranslationDataset(\n",
    "     path='./data_torch/data', exts=('.hi', '.en'),\n",
    "     fields=(src, trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.build_vocab(mt_train, max_size=10000, min_freq=2)\n",
    "trg.build_vocab(mt_train, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(mt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(trg.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = len(src.vocab)\n",
    "input_size_decoder = len(trg.vocab)\n",
    "output_size = len(trg.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(\n",
    "     dataset=mt_train, batch_size=32,\n",
    "     sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = trg.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.src]:[torch.LongTensor of size 66x32]\n",
       "\t[.trg]:[torch.LongTensor of size 48x32]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usage\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "\n",
    "sentence = 'рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХреЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch is 0/1]\n",
      "=> Saving checkpoint\n",
      "Translated sentence is: \n",
      " ['exchanging', 'Munde', 'Design', 'transferee', 'Said', 'Said', 'Said', 'Said', 'Said', 'before', 'ultimate', 'customer', 'stepping', 'stepping', 'Partnership', 'allows', 'allows', 'repository', 'repository', 'BARC', 'discretion', 'Sinchai', 'food', 'Sinchai', 'amounts', 'Italian', 'benami', 'Colleagues', 'Cyclone', 'Braille', 'Said', 'Said', 'Said', 'Said', 'Said', 'before', 'ultimate', 'customer', 'stepping', 'stepping', 'Partnership', 'allows', 'allows', 'repository', 'repository', 'BARC', 'discretion', 'Sinchai', 'food', 'Sinchai']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'[Epoch is {epoch}/{num_epochs}]')\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(\n",
    "        model=model, sentence= sentence, german=src, english=trg, device=device, max_length=50\n",
    "    )\n",
    "    \n",
    "    print(f'Translated sentence is: \\n {translated_sentence}')\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_iter):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        \n",
    "        output = model(inp_data, target)\n",
    "        \n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"training_loss\", loss, global_step=step)\n",
    "        step+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = 'рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХреЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "translate_sentence(model, test_sent, src, trg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рдЕрдЧреНрд░рд┐рдо рдзрди рд░рд╛рд╢рд┐ рдЗрди рдЕрд╕реНрдкрддрд╛рд▓реЛрдВ рдХреЛ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рд░реАрдХреНрд╖рдХ реЛрдВ рдХреЛ рджреА рдЬрд╛рдПрдЧреА , рдЬреЛ рд╣рд░ рдорд╛рдорд▓реЗ рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░реЗрдВрдЧреЗ ред'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([i.lstrip('тЦБ') for i in list(mt_train[0].__dict__.values())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.lstrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_test = data.Field(tokenize=tokenize_hi)\n",
    "trg_test = data.Field(tokenize=tokenize_eng)\n",
    "mt_test = datasets.TranslationDataset(\n",
    "     path='./data_torch/data_val', exts=('.hi', '.en'),\n",
    "     fields=(src, trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(mt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# raw_data = './data_torch/pmindia.v1.hi-en.csv'\n",
    "\n",
    "# df = pd.read_csv(raw_data)\n",
    "# # remove very long sentences and sentences where translations are \n",
    "# # not of roughly equal length\n",
    "# df['eng_len'] = df['english_sentence'].str.count(' ')\n",
    "# df['hi_len'] = df['hindi_sentence'].str.count(' ')\n",
    "\n",
    "# df = df.query('hi_len < 50 & eng_len < 50')\n",
    "# df = df.query('hi_len < eng_len * 1.5 & hi_len * 1.5 > eng_len')\n",
    "# import numpy as np\n",
    "\n",
    "# np.savetxt(r'./data_torch/data_val.en', df.english_sentence.tail(100), fmt='%s')\n",
    "# np.savetxt(r'./data_torch/data_val.hi', df.hindi_sentence.tail(100), fmt='%s')\n",
    "# # df.sample(frac=0.1).shape\n",
    "\n",
    "# # df = df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['тЦБ31.', 'тЦБрджреЛрдиреЛрдВ', 'тЦБрдиреЗрддрд╛рдУрдВ', 'тЦБрдиреЗ', 'тЦБрдбрдмреНрд▓реНрдпреВ', 'рдЯреА', 'рдУ', 'тЦБрд╕рдВрдмрдВрдзреА', 'тЦБрдореБрджреНрджреЛрдВ', 'тЦБрдкрд░', 'тЦБрдПрдХ', 'тЦБрджреНрд╡рд┐рдкрдХреНрд╖', 'реАрдп', 'тЦБрд╕рд▓рд╛рд╣рдХрд╛рд░', 'тЦБрддрдВрддреНрд░', 'тЦБрд╢реБрд░реВ', 'тЦБрдХрд░рдиреЗ', 'тЦБрдХреЗ', 'тЦБрдлреИрд╕рд▓реЗ', 'тЦБрдХрд╛', 'тЦБрд╕реНрд╡рд╛рдЧрдд', 'тЦБрдХрд░рддреЗ', 'тЦБрд╣реБрдП', 'тЦБрдЗрд╕реЗ', 'тЦБрд╡реИрд╢реНрд╡рд┐рдХ', 'тЦБрд╡реНрдпрд╛рдкрд╛рд░', 'тЦБрдмрд╛рддрдЪреАрдд', 'тЦБрдХреЗ', 'тЦБрд╕рдВрджрд░реНрдн', 'тЦБрдореЗрдВ', 'тЦБрд╕рд╣рдпреЛрдЧ', 'тЦБрдмрдврд╝рд╛рдиреЗ', 'тЦБрдХреЗ', 'тЦБрд▓рд┐рдП', 'тЦБрдПрдХ', 'тЦБрд╕рдХрд╛рд░рд╛рддреНрдордХ', 'тЦБрдХрджрдо', 'тЦБрдмрддрд╛рдпрд╛', 'ред'], ['31', '.', 'The', 'leaders', 'welcomed', 'the', 'decision', 'to', 'launch', 'a', 'bilateral', 'consultative', 'mechanism', 'on', 'WTO', '-', 'related', 'issues', 'as', 'a', 'positive', 'step', 'for', 'enhancing', 'coordination', 'in', 'the', 'context', 'of', 'global', 'trade', 'talks', '.']])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_test[0].__dict__.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 0.00\n"
     ]
    }
   ],
   "source": [
    "score = bleu(mt_test[1:100], model, src, trg, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
