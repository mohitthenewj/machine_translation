{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naval-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crazy-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 11 09:04:15 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00002231:00:00.0 Off |                    0 |\r\n",
      "| N/A   50C    P0    73W / 149W |    876MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      7754      C   ...onda/envs/text/bin/python      484MiB |\r\n",
      "|    0   N/A  N/A     55696      C   ...onda/envs/text/bin/python      386MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "senior-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sixth-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?ред])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./data/%s-%s.tsv' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bound-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "mediterranean-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "def trainIters(encoder=None, decoder= None, n_iters = None, print_every=1000, plot_every=100, learning_rate=0.01, encoder_optimizer = None, decoder_optimizer=None):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "oriented-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "sonic-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "active-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # help(pd.read_csv)\n",
    "\n",
    "# df = pd.read_csv('./data/hi-en.tsv', sep = '\\t', names=['en', 'hi'])\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "blond-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x : len(x.split('ред'))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "opposite-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 56831 sentence pairs\n",
      "Trimmed to 1340 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "hi 3990\n",
      "eng 3850\n",
      "['рдЖрдк рд╣рдорд╛рд░реА рдЬрдирд╕рдЦ\\u200dрдпрд╛ рдФрд░ рд╣рдорд╛рд░реА рдЬрд░рд░рдд рд╕ рднреА рдЕрд╡рдЧрдд рд╣ ред', 'you are also familiar with our demography and our demand .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'hi', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "educated-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 24s (- 7m 38s) (500 5%) 4.7306\n",
      "0m 48s (- 7m 13s) (1000 10%) 4.5652\n",
      "1m 11s (- 6m 45s) (1500 15%) 4.2484\n",
      "1m 34s (- 6m 19s) (2000 20%) 4.1869\n",
      "1m 58s (- 5m 54s) (2500 25%) 3.9928\n",
      "2m 21s (- 5m 30s) (3000 30%) 4.1208\n",
      "2m 45s (- 5m 7s) (3500 35%) 3.9841\n",
      "3m 9s (- 4m 43s) (4000 40%) 3.8031\n",
      "3m 31s (- 4m 18s) (4500 45%) 3.8553\n",
      "3m 55s (- 3m 55s) (5000 50%) 3.7164\n",
      "4m 18s (- 3m 31s) (5500 55%) 3.7141\n",
      "4m 42s (- 3m 8s) (6000 60%) 3.6709\n",
      "5m 4s (- 2m 44s) (6500 65%) 3.4921\n",
      "5m 29s (- 2m 21s) (7000 70%) 3.6004\n",
      "5m 53s (- 1m 57s) (7500 75%) 3.5944\n",
      "6m 17s (- 1m 34s) (8000 80%) 3.4464\n",
      "6m 41s (- 1m 10s) (8500 85%) 3.4925\n",
      "7m 5s (- 0m 47s) (9000 90%) 3.4365\n",
      "7m 30s (- 0m 23s) (9500 95%) 3.3688\n",
      "7m 54s (- 0m 0s) (10000 100%) 3.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/OklEQVR4nO3dd3yb13no8d/BIEGABEmA4p6atIa1ZdlKHXnFI4nTjDpNs+PG6Uia2YxmNL3tvW2aXrdNmtkkdZJmOW4S+zrDjofsxJIlay9ri6RIintvjHP/eN8XBEhwgwPQ8/189DEJvAQPBPnBwXOecx6ltUYIIUTysy32AIQQQiSGBHQhhEgREtCFECJFSEAXQogUIQFdCCFShGOxfnFeXp6urKxcrF8vhBBJ6dChQ21a62Xx7lu0gF5ZWcnBgwcX69cLIURSUkrVTnSfpFyEECJFSEAXQogUIQFdCCFShAR0IYRIEdMK6EqpGqXUCaXUUaXUuJVMpdRblVLHzWv2KqU2Jn6oQgghJjOTKpdbtNZtE9x3GXil1rpTKXU38E3ghjmPTgghxLQlpGxRa7036tsXgdJEPK4QQojpm24OXQNPKqUOKaUemOLa+4Ffx7tDKfWAUuqgUupga2vrTMYZcbapl3954iyd/SOz+nkhhEhV0w3or9BabwHuBv5SKXVzvIuUUrdgBPRPxLtfa/1NrfU2rfW2ZcvibnSa0uW2fv7j2Qs0dA3O6ueFECJVTSuga60bzP+2AD8Hdoy9Ril1PfAt4HVa6/ZEDjKaz5MGQOeAzNCFECLalAFdKeVRSmVZXwOvAk6OuaYc+Bnwdq31ufkYqMXncQLQISkXIYSIMZ1F0QLg50op6/ofaq1/o5T6MwCt9deBzwF+4KvmdUGt9bb5GHCu25yhS0AXQogYUwZ0rfUlYFxduRnIra//FPjTxA4tvuwMJ0pBx0BgIX6dEEIkjaTbKeqw28jOcMoMXQghxki6gA7gc6fRIYuiQggRIykDeq4nTWboQggxRnIGdHeaVLkIIcQYSRnQfR6n1KELIcQYSRnQjZRLAK31Yg9FCCGWjKQM6D53GiOhMP0jocUeihBCLBlJGdBzPbK5SAghxkrKgO5zy3kuQggxVlIGdGuGLpUuQggxKlEt6JRS6ktKqQtmK7otiR/qKDlxUQghxktUC7q7gVXmnxuArzGPLeislEtHv5znIoQQlkSlXF4HfE8bXgRylFJFCXrscbJcDuw2JYuiQggRJVEt6EqAK1Hf15u3xUhECzoAm02R63bKeS5CCBEloS3oppKIFnSWXLec5yKEENES1YKuASiL+r7UvG3e5HrkPBchhIiWkBZ0wGPAO8xql51At9b6asJHG8XnTpMqFyGEiJKoFnS/Au4BLgADwLvnZ7ijcj1pdNRKlYsQQlgS1YJOA3+Z2KFNzjpxUWuN+WYjhBDXtKTcKQrGomgorOkZCi72UIQQYklI2oDukwO6hBAiRtIG9Mh5LrIwKoQQQBIH9MiJizJDF0IIIJkDupy4KIQQMZI2oOfKiYtCCBEjaQO6J81Omt0mJy4KIYQpaQO6Uopcj1Ny6EIIYUragA5GLbpUuQghhCGpA7rPIycuCiGEZdoBXSllV0odUUo9Hue+cqXUs+b9x5VS9yR2mPHlemSGLoQQlpnM0D8IvDzBfZ8BHtZabwb+GPjqXAc2HT45E10IISKm2yS6FHg18K0JLtGA1/w6G2ic+9CmlutJo2swQCisF+LXCSHEkjbdGfq/AR8HwhPc/3ngbUqpeoyjdD8Q76JEtaCz+NxOtIbuQSldFEKI6TS4eA3QorU+NMllbwEe0lqXYpyL/n2l1LjHTmQLOog6z0XSLkIIMa0Z+i7gXqVUDfBj4Fal1H+PueZ+4GEArfU+wAXkJXCcceVlpgNQ294/379KCCGWvCkDutb6U1rrUq11JcaC5zNa67eNuawOuA1AKXUdRkCfe05lClsrcvF70vjh/rr5/lVCCLHkzboOXSn1v5RS95rffhR4r1LqGPAj4F1mF6N55XLaeevOCp4+08LlNpmlCyGubTMK6FrrPVrr15hff05r/Zj59Wmt9S6t9Uat9Sat9ZPzMdh43razHKdd8dALlxfqVwohxJKU1DtFAfKzXLx2YzE/PVQ/p2qXnx68wtMvNydwZEIIsbCSPqADvGdXFQMjIR5+6cqsfl5rzRd+c4Zv/15m+UKI5JUSAX19STY3VPl4aG8NwdBEpfITa+kdpq1vhKaeoXkYnRBCLIyUCOgA795VRUPXIM+fn3lxzanGbgCauodYgLVcIYSYFykT0HevWUaa3ca+i+0z/tlTDT0ADIyE6B0OJnpoQgixIFImoLucdq4vzeZATeeMf/b01Z7I183dknYRQiSnlAnoANurfJxq6GZgZGaz7FONPSzLMnadSh5dCJGsUiqg76j0EQxrjtR1TftneoYC1HUMcFt1PmDk0YUQIhmlVEDfUpGLUnDgcse0f+Z0o5Fu2b3GCOjNY2bo7X3D1HcOJG6QQggxT1IqoGdnOKku9HKwdvoB/ZQZ0LdU5JDjdnJ1zAz98//vNPc/dDCh4xRCiPmQkBZ05v33KaVOK6VOKaV+mLghzsyOylwO13YRmGY9+qnGbpZlpZOf5aLQ6xo3Qz9ztYeLrX2zqm8XQoiFlJAWdEqpVcCngF1a63XAh+Y+tNnZXuVjMBCKzLyncrqxh3XFRrOlwmxXzKJoKKypbR8gGNY0dkluXQixtCWqBd17ga9orTsBtNYtiRnezO2o9AHw0jTy6EOBEBda+kYDutdFU/dw5P7GrkFGzJl5bYec5iiEWNoS1YJuNbBaKfWCUupFpdRd8S5KdAu6ePK9Lir8bg7UTB3Qzzf3EQxr1hVnA1DgddHWN8xI0HiaF1v7ItfWtMvCqBBiaUtUCzoHsArYjdGO7j+VUjljL0p0C7qJbK/0cbCmg/AUzaOtLf/RKReAll4jvWKdsW5TUCddkYQQS1yiWtDVA49prQNa68vAOYwAvyh2VProHAjEzLDjOdXYQ2a6g7JcNzAa0K2F0ctt/WS5HCxflkmtzNCFEEtcolrQ/QJjdo5SKg8jBXMpoSOdge1VRh59/xR59FON3awt8mKzKcDIoQORPPrltn6W53mo9LsloAshlrxEtaB7AmhXSp0GngX+Wms981OyEqTS72ZZVjovTZJHb+wa5Fh9N9urciO3RQK6OUO/1NrP8mWZVPg91Hb0y0mMQoglzTGTi7XWe4A95tefi7pdAx8x/yw6pRQ7qnwcuNyB1hql1LhrvrevFq01b9lRHrktx+0kzWGjqXuQoUCIhq5BqvI85LidDAXCtPQOU2AGfSGEWGpSaqdotB2VPq52D1HfOTjuvsGRED86UMed6wopNfPnYLwRFHpdNPUMU2MuglbleajwewAk7SKEWNJSN6CbefR457r8/EgD3YMB3r2ratx9hV4Xzd1DXG6NCug+I+jXSKWLEGIJS9mAvqYgC6/LMS6PrrXmob2XWVfsZXtl7rifs3aLXmobDegluRnYbYo6maELIZawlA3oNptie6Vv3Az9hQvtnGvu4927quLm1q2AfrG1j0KvC0+6A6fdRklOhszQhRBLWsoGdDDSLpfa+mntHd3O/18vXCYvM43XbiyK+zMFXhcjwTBH6rqoyvNEbq/wu6nrkBm6EGLpSvmADkTSLvsvtfP0mRbevrOSdIc97s9YpYuX2/qpWhYb0GVRVAixlKV0QF9fkk2G086Byx0EQmE+++hJSnIyeODm5RP+TGF2euTr5VEz9Eq/h+7BAF0DI/M6ZiGEmK2UDuhOu40tFTkcuNzBf71wmXPNfXz+3nVkpMWfnQMUZmdEvl4eNUMvNytdZJYuhFiqUjqgA+yo9PNyUw//9tR5br8unzvWFkx6fX5WOtZaaVVeZuR2qxZdFkaFEEtV6gf0Kh9aQ1hr/va166a83mm34fek47ApynJHZ+vWDF1KF4UQS1XCWtCZ17xRKaWVUtsSM7y521yeQ35WOh971RrKfO6pfwAjj17ud+Owj/71ZKTZKfCmy7noQoglayZnuVgt6Lzx7lRKZZnX7E/AuBLG5bSz/29ui1tzPpF33FhJMDT+IK4Kv4c66VwkhFiiEtWCDuDvgS8AS6755kyCOcB928r4kxvKx91e4ZPSRSHE0pWQFnRKqS1Amdb6l5M9yEK0oJtPxTkZtPYNEwhN1IlPCCEWz5xb0CmlbMCDwEeneqyFakE3X4qyXWgNLVE7T4UQYqlIRAu6LGA9sMe8Zifw2FJaGE0Uq0VdU/f4I3mFEGKxzbkFnda6W2udp7WuNK95EbhXa31wvga9WIrMTUeNXUtumUAIIRLWgu6aMDpDl4AuhFh6ZhTQtdZ7tNavMb/+nNb6sTjX7E7F2TmA1+XAnWbn6iQBvb5zgL999CQjQVk4FUIsrJTfKZpISinzvPSJc+gPH6znu/tqOVLXuYAjE0IICegzVpTtmnSGvv9SOwDH6rsWaERCCGGQgD5Dhd6MCXPoQ4EQR650AXDsSvcCjkoIISSgz1hRtouW3mGCcTYXHbvSxUgwTK7byVEzsMejteaxY40MjATncaRCiGuNBPQZKspxEQpr2vrGN7p48VIHSsHbdlbQ0DUY0/ou2smGHv7qR0f45vOX5nu4QohriAT0GSoySxevxtlctP9yO9WFXm5ebeyCPT5BHv2oefvDL10hFB5/CJgQQsyGBPQZKvQam4vG5tFHgmEO13VyQ5WPdcVe7DbFsQnSLsfN2xu7h3j+fPKdaSOEWJokoM/Q6Aw9NqAfr+9iKBBm53If7jQHq/IzOVoff2H0eH03u1b68XvS+PGBunkfsxDi2iABfYZy3E7SHTaaemID+v7LHQDsqPIDsKksh+P1XWgdm1IZGAlyvqWXreW5vGlrKU+/3EJLr+w8FULMnQT0GVJKxa1Ff/FSO2sKsvB50gDYWJZD10CAuo7Y89NPNfYQ1nB9aQ5v3l5GMKx55FD9go1fCJG6EtKCTin1EaXUaaXUcaXU00qpisQOc2kpzHbFnLgYCIU5VNvJDct9kds2luYAjCtftPLq15dls3xZJjuqfPzkpSuEZXFUCDFHM5mhWy3o4jkCbNNaXw88AvzzXAe2lBVlZ8TM0E80dDMwEuIGM90CsLogE5fTNm6D0fH6boqyXeRnGbn4t+woo7Z9gH3mDlMhhJithLSg01o/q7W2cgsvAqWJGd7SVJjtorlnKDKrfuF8GwA7qkZn6A67jQ0l2eOOADhe38X1pdmR7+9eX0ReZjr//tT5cfl2IYSYiYS0oBvjfuDX8e5I9hZ0lqJsF4GQpr3f2Fz0yxNX2VqRy7Ks9JjrNpbmcLKhO9KyrnsgQE37ANeb6Rgwmlh/8PZVHKjp4NmzLQv2HMYaHAnxlWcvMBQILdoYhBBzM+cWdGOufRuwDfhivPuTvQWdpdA7ei76pdY+zjT1cs+GonHXbSzLYTgY5vfmDP54QxdAzAwd4I+3l1Hpd/PPvzk7LxuNrnQM8PXnLk56pO/PjzTwxSfOsmcR31SEEHOTiBZ0ACilbgc+jdGtKKWbblqdi652D/KrE1cBuGdD4bjr7lhbwPJlHj7zi5P0DAU4btalX1+SE3Od027jY3eu4UxTL7840pDw8X75mfP806/P8L7vH5xwBv7EqSYAzjX3Jfz3CyEWxpxb0AEopTYD38AI5ik/xYt0LuoZ4vHjRrrFCvLRXE47//ePNnK1e5B/ePw0x650Uel3k+12jrv2nvVFbCjJ5sHfnkto2iMc1jx7tpUyXwZ7zrXynodeon849lCwnqEAey8anyLONvcm7HcLIRZWolrQfRHIBH6qlDqqlBrXySiV+D1pOO2KvRfaJ0y3WDaX5/Jnr1zBwwfree5ca0z+PJrNpvjEXdU0dA3y2i//no8/cozv7auhvW9uH3ZONfbQ2jvMh25bzYP3beTFS+288zsHYtIvz55pIRDSFHpdnG2afkB/9kwL9Z0DU18ohFgQCWlBp7W+XWtdoLXeZP5J6V6jNpuiwOviydNGmiJeuiXaB29fRXVhFsPB8Lj8ebRXrMrj7+5dR2G2i6debuFzj57iX548O6exPnOmBaVg95plvH5zKQ/et4mDtZ38KOrIgSdONbEsK503bCnhcls/w8GpPyGMBMM88P2DfOM5OTFSiKVCdorOUlG2i7BmwnRLtHSHnQfv28SKZR52r5l8MfidN1Xy/ftv4NBnbuemFX5ONMytUcYzZ1vYWJqDP9OowHndpmJ2Lvfx5WfO0z8cZCgQYs/ZVl61toDriryEwppLrf1TPm5Nez+BkKa2Q2boQiwVEtBnqdAM4pOlW6KtLfby9Ed3szI/a1rXK6VYX5LNuaa+SNnjTLX1DXO8votbq/NjHvcTd1XT1jfCt353md+db2NgJMSd6wpZU2iM7dw08ujnzcXTegnoQiwZjsUeQLIqzjEWRqdKt8zFumIvI6EwF1v7qC70zvjn95xtRWtiAjoYef271hXyzecvsnO5nyyXg53LjV2uTruaVh7dCvr1nYOEwxqbTc14fEKIxJIZ+iy9Z1cV//Wu7VOmW+ZibZERxE819Mzq558900J+Vjrrise/GXzszjUMBkI8faaF268rIM1hI81hY3leZswMXWvNo0cb6B4MxPz8hRZjhj4SCtMyQWcmIcTCkoA+SwVeF7eMmfkmWlWeh3SHjdNXZx7QA6Ewz59r5ZY1+Sg1fva8Mj+TP9paBsCd6woit68uzIopXTxU28kHf3yUH+yvjfn58y29eNLsAFyRShchlgQJ6EuYw26jusjL6caZB/SDNZ30DgcnfdP5xN3VfOxVq7m1ejSgrynI5ErHIH1mrfqjRxsBOFzbGbkmEApzua2fP1hlLPDWtUtAF2IpkIC+xK0t8nKqsXvGB3ftOdeC0654xaq8Ca/xedJ4/62rSHOM/jNYXWAsjJ5v7iUQCvNLcyfs4brRZh217QMEQprda5ah1OLO0PuHg/zR1/fO6k1PiFQjAX2JW1vspWcoSEPX+KbUk9l/qYNNZTlkps9s3Tu60uX3F9ro6B/htup8OvpHqDFn4hdajJTMuuJsCrJcXOmY2dgS6eWrPbxU08mh2o5FG4MQS4UE9CXOWtCcyQy0fzjIiYbumON8p6ss102G087Zpj4ePdJAdoaTD9+xGjDy6TBasrgi30OZL2NRZ+jWm0znQGCKK4VIfRLQl7jqwiyUImZh9ExTT6TKJJ7DdZ2EwjrS33QmbDbF6oJMjl7p5MnTzdyzoZC1RV6yXA4O1xkB/VxLH6W5GbjTHJTluhe1Fr2u3dgE1TkwsmhjEGKpSFQLunSl1E+UUheUUvuVUpUJHeU1zJ3moCrPwylzht49GOBP/nM/73nopQmP2j1wuQO7TbG1IndWv3N1QRaH67oYGAlx78YSbDbF5vLcyMLo+eZeVuVnAlDqc3O1Z2jSo3nnk7VTtUtm6EIkrAXd/UCn1nol8K/AF+Y6MDFqXXF2JOXy5afP09E/Ql3HAE+aR96Otf9SB+uLvTPOn1usPHqh18UNZtpma3kuZ5t76R4IcKmtn1Xm4mm5z43WzDjHnyi1kZSLzNCFSEgLOuB1wHfNrx8BblPxip/FrKwt8tLQNciRuk4e2lvDm7aWUu5z843nL42rfhkKhDh6pWtW+XOLVely76biyA7QLRU5aA2PHWtgJBhmpTlDL8s1NlZdWaS0S62ZcpEZuhCJa0FXAlwB0FoHgW5gXAI3VVrQLbS15sLo+394BJfTzifuquZP/6CKo1e6IguVlqNXuhgJhWMaVs/Utspc3rC5hHfcWBG5bVNZDkrBj1+6AowG/TKfG1ic0sWeoUBkMbRLZuhCJLYF3VRSpQXdQrOOAGjoGuT9t65kWVY6b9paSo7byTefjz2+9sDlDpSC7ZWzn6G70xw8+OZNlOa6I7dluZysKciK5PKtGXqB14XTrhaldNHa0FTgTZcqFyFIXAu6BqAMQCnlALKB9gSO85q2LCudAm86FX43795VCRhB9+07K/jty81cbhs97vbA5Q7WFGTF7Yo0V1vMRdbibFckP2+3KUpyFqd0scZMt2wszaFnKDAv/ViFSCYJaUEHPAa80/z6TeY18n9XAn31rVv49ju3k+6wR257+40VOG02/u2pc4TCmkAozKHazsjJiYm2pdwI6CsLYo8ALvPNT+ni78+3cfuDz02YTrEWRDeWGfn9sQeIzdTRK12Rht5CJKNEtaD7NuBXSl0APgJ8MhGDE6O2VvgiaQ5LfpaL97yiikePNvLmb+zjl8evMhgIzWlBdPIxGAF91ZhxlPnc1CU4oAdCYT732EkutPRxpK4r7jV17QPkZaZTkmMszM610uVvHz3Jx356bE6PkUq+v6+GxkWqXhKzM6O6Nq31HmCP+fXnom4fAv4okQMT0/OJu9ZQXZjFZx89yYd+chSYW/58MpV+N3912ypePaapR1mum86BAH3DwVmXSo714wN1kc5Jp6/2xD1krLajnwq/mxwzvTSXSpeeoQAnGroJa2jqHoo0Ar9WtfUN89lHT9E7HOQvdq9c7OGIaZKdoklOKcUfbi7hiQ/dzC1rlrF7zTKWZaXP2+/6yB2rI3XqljJfYksXe4YC/OtT59m53EeF382pxvht+GrbB6jwucl1pwFzq3Q5cKkDKwV/9Ern5BdfA5p7hgDoGQwu8kjETEhATxHFORn817t38NC7dyz47y4zq2ESFdC/+uxFOvpH+Myr17Ku2BuprIk2FAjR1DNEhd8TCehzqXTZe7GddIcNp11x5ErXrB8nVVhNS3qGpHoomUhAF3NWHqlFn3u+tb5zgO+8cJk3bC5hfUk2a4u81LYP0DsmsNR3DqA1VPjdkYqeuczQ915sY1tlLmuLvByTgE5rjxnQ57jQLBaWBHQxZzluJ5npDi63TXxg2HQ9fLCeYCjMx+5cAxjHHgC8fDW2z2lNm/FpoNzvxutyYLepWS+KtvcNc6apl5tW5LGpLIcT9d3XfAlkS6+RcukdkpRLMpGALuZMKcWulX4ePdo45x2b+y62saE0h2KzcsXaJTs2j24dylXp96CUIifDOeuUy4uXjLPUb1zhZ2NZDv0jIc63TN0oO5VJyiU5SUAXCfGRO9bQNxzka89dnPVjDIwEOVLXxU0rRuvo87PSyctMG3cefF17P1npDnLNdEuO20n3LAP63ottZKY7uL4km01lOQAcnaBU8lrRYqZcZIaeXCSgi4RYU5jF6zeV8NALNTR1D83qMQ5c7iAY1jEBXSnFdUXjF0ZrOwYo97sjDbBz3WmzTrnsu9jOjiofDruNqjwP2RlOjl7jefTWPsmhJyMJ6CJhPnzHasJa86Vnzs/q5/ddbMdpV2yriK2jX1eczfmW3pgz12vbB6jwj541k+NOm1XKpal7iEtt/ZE3EaUUG8tyrvmALjn05CQBXSRMmc/NW3aU8/BLV6iJOl9muvZebGdzeS4ZafaY29cVewmEdCSvHQpr6jsHqPB7ItfkuJ2zyt/vu2Rs9b8x6lPBprIczjX30j+c2GA2EgzzsZ8e41zz0s7Pa61p6RlGKRgMhBateYmYOQnoIqHef+tKnHYbn330JIHQ9ANB90CAk43d7FqRN+6+0YVRI+3S0DlIIKSp8I3O0HPdzlmlXPZeaCfH7eS6Qm/ktk1l2YQ1nGiIv6Fpto7Xd/HIoXqeOBm/MclS0TMUZDgYjhypMLZkVCxd0zk+16WUOqCUOqaUOqWU+rs415QrpZ41W9QdV0rdMz/DFUtdfpaLz712Lb8738aHf3J02uV/L15uR2u4aeX4g8Uq/R7caXZON/YQDmv+4ZensdtU5PRHMFIuQ4EwQ4HQjMZ7+moPm8pyIo08wDi9EUh42sXqyZroc28SrdVMt6xYZpzZI2mX5DGdGfowcKvWeiOwCbhLKbVzzDWfAR7WWm/GOJHxqwkdpUgqb9lRzqfurubx41f5m5+dGNdVKZ59F9vJcNojwTSa3aaoLszidGMPX37mAk+ebuYzr74u0mQDiNotOrNZelP3UKRE0uLPTKfc5054pcvhWuPxapd4QLcqXKzD4KR0MXlMeZKSeQyutWPEaf4Z+3+oBqzPrNlAY6IGKJLT+165gr7hIF9+5gLH6o0uSp39I2wqy+E779rO2A6Fey+2sb3KR5oj/hxjXXE2P36pjgM1HbxxSynvuqky5v7cqAO6irIz4jzCeEOBEO39IxR5xx/Eta0il1+euMrDB6/wR1tLx413prTWkRn6YrXrmy6rBl1m6Mlnuj1F7Uqpo0AL8Fut9f4xl3weeJtSqh74FfCBCR5HWtBdQz5yx2r++s41+DxpXFfk5frSHJ492zrurJSW3iHONffFlCuOtdZcGN1Yms3/fv36cQE2ZxYzdGsmGu9kxU/eXc2W8lw+/shx3v+jI1PWuJ9r7uXOf32edrPcb6yGrkFaeodZlpVOU8/QjFNDC8mqcInM0KV0MWlMK6BrrUNa601AKbBDKbV+zCVvAR7SWpcC9wDfV0qNe2xpQXdtUUrxl7es5Ifv3clX/mQLX33rFrLSHTz0Qk3MdfsuGs2tJgvot1Xn87pNxXz97VtxOe3j7p/NEbpXu42zZ+LN6PO9Lv77T2/g43et4YmTTdz3jX2Tpo72XmjjbHMvxydYSD1spm/u3ViM1lCfgHNv5ktr7zAup43iHOONTlIuyWNGVS5a6y7gWeCuMXfdDzxsXrMPcAHjyxXENc2T7uC+7WX86sTVyPGsI8EwX9tzkaJsV+TclnjyvS7+/Y83T5hOmSqH/olHjvOLIw0xtzWZY5jo7HO7TfEXu1fyqXuu42xzLw2TNHuoMbsn1U5Qrnm4tpMMp51XrS0AlnbapaV3mPwsF94M401SUi7JYzpVLsuUUjnm1xnAHcCZMZfVAbeZ11yHEdAlpyLGeeeNlYS05gcv1gLwtT0XOdPUyz/84XrsttnnqSeboYfCmkcO1/OrE1djbr/aPXlAt1idmk5OUsZo9TedaMHzcF0n15dmU7XMqJ1fypUuLT3D5Gelk5nmQClJuSST6czQi4BnlVLHgZcwcuiPj2lB91HgvUqpY8CPgHdJT1ERT7nfzW3VBfxgfx3H67v4j2fP87pNxdx2XcGcHtfltJPhtNPZP36G3to7TCisxwXRpu4hslyOKbssVRdm4bApjtdPEtDNmbnV5zTaUCDE6cYetlTksiwznQynPe51lk///AQPv3Rl0jHNp5beIfK96dhsisx0Bz0yQ08a06lyOQ5sjnN7dAu608CuxA5NpKp376rkqZebeeu39uN1Ofnb165LyOPmup10xZlNNpq58rqOAbTWkQXVq92DFE2j1ZzLaWd1QdaEG40CoXAkJ27N1KMdr+8mGNZsKc9FKUX5JD1Yr3YP8oP9dTT3DHHf9rIpxzYfWnqH+YNVxhqX1+WUHHoSkZ2iYsHdtMLPqvxMeoeCfP7edfg8aQl53Gx3Wtzt/1e7jNTKwEgocugUWL1Dp1fieH1pNicbuuMujDZ0DhIMa/Iy06nvGBy3mcoqV9xcngMYRyRMlEN/8lQzAM098atl5ttQIETvUDDSxjDL5ZA2dElEArpYcEop/umNG/ibe6p5zfVFU//ANBnb/8fPJq1qFoC6qFTH1e6huDXo8awvyaZzIBC3OuWyOSu/eXUeI6FwzO8DY0G0wu8mL9MIktYMPd6bw2/MYwGs0sGFZpVyWgHdm+GUrf9JRAK6WBRbK3w8cPOKOW/YiTbREbqNXaPB0cpdB0JhWvuGp1wQtWwoMSpw4i2MWpUtr1y9LOZ3gLWhqIst5aPHFFT43QwGYj8tAHT0j3CgpoN0h422vpFF6ZpkvZHkWwHdJTn0ZCIBXaQM48TF+DP0Ml8GNjVahdLSO4zWTCuHDlBdlIXTruLWmde0D+BJs7Ot0jj2NzqgX+kYpK1vmC1mugWierCOSbs89XIzobDm3o3FhMKajjgLvPPN2iWan2X8vXhdqTND/+8Xa/n5kfrFHsa8koAuUkaumUMPj5nZNnYPUen3UJSdQZ2ZHmky0yLTnaGnO4yF0Xgz9Jr2firzPBR5XaQ5bNRGLYwerDXa21nBHowcOoyviHnyVBMlORncWp0PJDbtEgrruM2vuwcDPPC9g5Ext1oB3RudQ0+NgP7Q3hq+t692sYcxrySgi5SR43YS1tA75hzzxi6jmqXC747M0K0a9Ome+wLGwujx+vELozVt/VT6PdhsRgVLdKB+qaaTLJcj5iCx0twMlIqtRe8bDvL8+TbuXFdIvpnXb0ngwuj/HK7ndV95gUutsY28D9d18uTpZv7jmQvG7+wdwmFT+MyNWt4MJ73DwXFvksmoo3+EhiW8QzcRJKCLlGGd5xJd6TISDNPWN0xRdgYVfndkUdRqk1c4zUVRMBZGuwdjF0atksXKPGPWXeFzx5QuHqzpYGtFbsymKZfTTqHXFRPQnzvbykgwzJ3rCiL560TO0J87Z+zzu9ASG9Ctv49fHG2gpWeIlp5h8jLTI8cJe11OtIb+kYXLozf3DPH+Hx5OaKonFNZ0DozQ0jvMcHDpnqMzVxLQRcqwTlyMrnRp7hlCayjOcVHu89DeP0LfcJCr3UNkOO14M6bcihFhLYxG16NbJYuVZvekCr8nUsHS2T/C+ZY+tlf6xj1Wuc8dU3Hzm1NN+D1pbKv0RSpMEjVDD4d15LycsXXyNe39OO2KYFjz3X01xrZ/M90CRsoFWNCF0RcvtfP48avsv9SRsMfsGhjB+mA12563yUACukgZ8U5cbOwaPYCr0m/lrvtp6h6iKNs1oyqbNYXmwmjUjlGrZLEyz2P+1x2pdz9Ua9Sfb4tqxGGJ3lxU297PU6ebedW6Auw2hctpJ8ftjCxQztWZpt7IAmvNmLx9XfsAK5Zl8qq1Bfz3i3XUdQxEPiEAUee5LFwe3crZn01gq77oBeZUTrtIQBcpY/RM9NH/ea1ceXGOi3L/6GLk1e7BaS+IWtIddtYUxi6MWiWL1gy9PGrB82BtJ0670XR6rHKfm5beYXqHAnzoJ0dx2hUfuHVV5P78rPTIAWZztfei0Te1ONsVs2ALRtVPhd/NAzcvp3swwOW2/sgnBIiaoS/g5qJuK6A3JS6gt/WN/puon+SQtWSXkBZ05nX3KaVOm9f8MPFDFWJyfo8RiFqjZraNUUfkWk2la9sHzF2iMwvoYKRdjtd3RWrErZLFvEzj04EV2Gva+jlY08GGkuy4x/1aby6f/NkJjtR18X/esCGmc1J+lmtWM/SnTjfzju8ciGns/MKFNqryPOyo8lHTNjpDD5vn21T6PWyt8EV2si7LGv178bqMN8mFrHSx0juJDOgyQx81ZQs6pdQq4FPALq31OuBDCR6nEFPKdjspycngWFRK5GrXEF6XA0+6cQiX35PG5bY+mnuHp12DHu2Vq/PpGQry45fqgNGSRSt1U5Kbgd2mON/Sx/H67rj5cxidyf/y+FXesLmE11xfHHN/flZ6zBvTdD1+vJHnz7XyP4eNeutAKMyByx3ctMJPZZ6Hxu7ByKJgU88QI8Fw5M3lvX+wHIACb5yUy/DCBXSrmcjF1r6YN6a56Og3/i7THLZJj0FOdlMGdG2YqgXde4GvaK07zZ9pSegohZimrRW5HKzpiJQWXu0ejJn5lvvdHKrtJBTW0z7HJdqd6wq4ocrHvzxxlq6BEaNk0cyfAzjtNkpyMnj8WCMjoXBM/Xk0K6CX5mbwd68bfzhZvtdFa+/wtPqxRrM2Pn11zwUCoTDHrnTRPxJi18o8Kv0etDY2O8HoAmmFz2M+t0L+z+s38JoNo28ui5lyCYY1l9r6prh6etrNGfp1hVmRdZVUlKgWdKuB1UqpF5RSLyqlxjbAsB5HWtCJebWtMpfmnuFIaWFjV2wT6Aqfm4utRiCb7jku0ZRSfP7edXQPBvjnJ84aJYvmDDfyO/xuGs3c/dY4C6IAPk8aH71jNV9/21ayzLRGtPysdEZC4Rl1YOodCnCptZ8t5Tlc6RjksaONvHChHaXgxuV+KsxxWkf9WlU21u12m+JPbign2z06HiugL+SiaPdgAK/5eydKuwwFQvzjr1+OPJepdPSPkJ3hpNzvubZn6DCtFnQOYBWwG6Md3X9aTTHGPI60oBPzygqgVoVJ45gjcsv9o7Pp2eTQAa4r8vL2nRX8cH9dTMmixQqQK/MzJzxJUinFB25bxfqS+F2arNLB5hnUop9q7AHgA7euYm2Rl688e4HfnW9lbZGXXE/aaH7fnJnXtA/gtKuYN7yx0h120h22BS1b7B4MsKk8F4dNcSZOQNda87GfHuMbz13il2OalkykvX8EvyeN4hwXV7uGUmKjVDyJakFXDzymtQ5orS8D5zACvBALqrrQS2a6g4O1HQyOhOgaCIyboVtmk0O3fPiO1ZGqmqq82IBuBc7tlfFn59NRMIvdoifMtYMNpdl84NaVXGrr52BtJ7tWGt0gc9xOvC5HZCdrXUc/ZbnuKTtFeTOcC7oo2j0YIM+TxoplmXFn6F96+gKPHzcCeX3n9Do/tfcN4/OkUZqTwYh5MFsqSlQLul9gzM5RSuVhpGAuJXCcQkyL3abYXJ7DwZrOqAqX0cBtzZ7T7LY5ncOe407jM69eS3aGk1X5WTH3WdU02yri58+nY3S36PQDz/GGbkpyMsjLTOfOdYWsys8ERptvK6WozPOMtstrH4gsiE7G63IsaF/RnsEA3gwnqwuzxgX0Xx6/yr8+dY43bClhY1lOZD1gKh39I/g8aZTkGm/uqZp2SVQLuieAdqXUaYwZ/F9rrdvnZ8hCTG5bhY+zzb2cM4NB9HktVgArnOGmonjeuLWUI5+9IybnDLBrpZ8/e+UK7lxfOOvHtk47nMn2/5MN3ZHdrDab4m/uuY7rS7PZUTX6xlLp91DbbuxkrW0fGJcuiidrAbsWhcKa3uEg2RlOqguzaOgajOTvr3QM8NGfHmVbRS7/+IYNlOVmcGWaM/SO/hH8mWmU5Bivf6qWLiaqBZ0GPmL+EWJRbavMRWsi+dXinNEZ+rLMdNxp9lnnz8eyxUlXuNMcfPLu6jk9bkaanax0x7RTLtamoDdtLY3cdkt1PreYJzdaKv1uHj/eSHPPMH3DwUi1zWS8Gc5I5cl8s1I72RnOyNjONfeytcLHt39/mVBY86W3bCbdYafM5+aJU02EwnrStFE4rOkcCOD3pEf+LVzLM3QhksqmshzsNsVTLxvt3KKDt1KKm1b4J6w+WUryvenTnqGfMssVN0ywyGqp8HsIa/j9hTbz+6kDepbLQe8CBfTuqIC+ptBIZZ1p6qVrYISfvHSFezeWRNZEynLdBEKapil21HYPBgiFNT5PGlkuYx3hmp2hC5FsPOkO1hZ5OdHQTV5mGumO2J2a33rn9kUa2czkZ7mmPUM/Mc2Abp0K+bx5+mLFNFIuiWwUfexKF/sutfNnr1wR937r92RnOCnNzSAz3cHZpl46+0cYDIR44OblkWvLfEZgv9IxQMkklTpWDbrf3M1bkuuWGboQycSagc/kvPOlxpihjwb0Cy29vHy1J+61xxu6Kc3NIHeKhV4rgP/ufCtKjQbFyXgz4reh6+wf4e8fP80vjjRM+RiWf/r1Gf7p12cm3NwTmaG7nSilWF2QybH6bh7aW8vuNcsis3aA0tz4nZ/GajcrWqxF8JKcjJTdXCQBXaSkbWbJYHT+PNlYB3RprdFa88D3DvHhnxyNe+2J+m6uL518dg7g96SRme6gcyBAcXbGuE8v8XhdTkaCYYYCxpEB4bDmRwfquOX/7uHbv7/Mp39+IhI0J1Pb3s++S0atxJ6z8TcWWgHdOkNmTaGXY1e6aOsbjpmdg/HaKkXcxt3RrHNcrIBempuRsikXCegiJVklg8k8Qy/wuhgOhukZCrL/cgeX2vq50DL+fJPugQB1HQNsKMmZ8jGN0kVjZjudBVEgsmuzdyiI1pp3P/QSn/rZCVYXZPH1t21lKBjmy2bHo8k8cqgepYzA+ty5+KeDROfQAdYUGKWXG0qyuXG5P+badIfRKGSqSpdIysU8vK04x0XvcHDBFnoXkgR0kZIKs1184q5q7ttWtthDmTXrGNvW3iF+dMA4DCze+SbTzZ9brLSLFdinYh1N0DMU4IUL7Tx3rpWP3rGanzywk7vWF3LftjJ+sL82pmHHWKGw5pFD9dy8ahl3rivkhQvtcQ/eGhvQraOH/3z3irhlpmW5buqnqEUfO0OfrHTxUmsfT55qmvTx5qqufSByWmeiSUAXKevPd69gbbF3sYcxa1Yt+rnmPn59ookbzHrysZttjjd0AdMP6NbZM+W+qRdEgUhXp57BAN94/iJ5mem89+blkQD7odtXYbcpHvzt2Qkf4/nzrVztHuLN28vYvWYZfcPByPEM0boHA6TZbbicRmjaXJ7Lno/t5p4NRXEft9Q3dS16R/8IWS4HaQ7jMa3NRfHy6J/++Un+8oeH561NXTAU5tVf+h1///jpeXl8CehCLFHWeS5ff+4iI6Ewn3n1Whw2xctXYwP60bouKv3ucRucJhKZoU+jZBFG89kHLnfwu/NtvHtXZcwZ7wVeF+/ZVcUvjjbGNP+I9tODV/B50rj9ugJ2rczDYVORPqfRrF2i0bPxyryJ33jKct009QxNGoCtc1wsVkXM2EqXc8297LvUTiCkOd+cmFMexzrR0E3vcDCyxpNoEtCFWKKs81yO13ezuTyHDaXZrMzP5GzTaKWL1prDdV1smUFd/c4qP2uLvNP+GSvl8vXnLuJOs/O2GyrGXfO+V64gx+3kge8d5Gt7LtIWtUja3jfMb0838/rNJaQ5bGSmO9hWmcues+Pz6N2DAbJn0Oe1zOdGa+NUzYlY57hY8jLT4p6L/r19NVj7k05M8MY0Vt9wkC89fZ7BkenN6PeavV3HrgckigR0IZaozHQH7jRjJvyWHeWA0dc0OuVypWOQtr7hGW2UKve7+dUH/yDyhjEVK+XSORDgzdvL4n4SyM5w8o23baXM5+YLvznDjf/4NG/82l7e/u39vPuhlwiEdMx6xu41+Zxp6h3XZs8I6NP7pAFQljtaiz4R4xyX0aYdSilKcmIrXXqGAvzscAOv31xKlssx4SeNsX5+pIEHf3uOX03z1Me9F9uoLszCn5k+9cWzkLAWdOa1b1RKaaXUtsQOU4hrU35WOlnpDl5zvZFDXlOYRWP3UGTx8FBdBwBbyudv56s1Q7fbFPe/omrC625Y7ucn77uRpz5yM++4sRKnXdE/HCQY0rx5W1lMDfkrVxvHZz83pnxxpgG91KzUmSyPPjblAka66cVL7VxoMVIrjxysZ2AkxLtuqmRdsZeTjfHr/cd66rSxG/mZOJ82xhoKhDhYM3r65XyYzmcbqwVdn1LKCfxeKfVrrfWL0RcppbKADwJjm18IIWbpvu1luJ123GnG/6rVZlA819zL9kofh2u7yEx3sLoga7KHmRNPmp0Mp5071hZENvNMZmV+Fp99zdpJr6kuzKLQ62LPuRbu2z46c+8ZDLJiWea0x1bodeG0q0gtesBcdHz95lL+fPcKtNZ09o/gy4wN6J+8+zre+q39vPkb+/je/Tv4/ou1kbTWhpJsvruvlkAojNM+8Zy3bzjIvovt2JSx8zYYCuOY5PrDdZ0MB8OR0y/nQ6Ja0AH8PfAFIDGtyoUQ/MXulbxr1+isuLrQqNo5Y+4YPVTbyebynCnPNJ8LpRQPv+9G/vfrx/a1mdtjvnL1Mn53vi2mhG+mM3S7zWjQYaVcnjzVzLnmPn5+xOip2jMYJBjW42boawqzePh9O0lz2Hj9V/dyua2fd95YCcD6kmxGguHI7H0ivzvXykgozDturKR3KH7VTrS9F9qx21TM6ZeJlpAWdEqpLUCZ1vqXUzyOtKATYg6Ksl1kuRycaeqlbzjImaYeNs9jusWyoTQ7bqu8udhSkUPvUDBSPhgOa3qGZhbQwah0uWLO0L+3rwYwSj3rOwdoN5tD+zPHH4mwfFkmD7/vRgq9Lgq86dy9wTjueF2xUf45VR79ty83k53h5EO3r8JpV1OmXfZebOP6efh7jDbnFnRKKRvwIPDRaTyOtKATYg6UUlSbC6PHr3QR1hP3LV3qrLPYL5t9QXuHg2jNzAO6L4P6jgHONPWw/3IHbzYXX5890xK1qSj+ImSZz1gg/n8feEXkGISqPA/uNPukAT0YCvPMmRZurc4nx53G9kofz56ZOKD3DgU4Vt89r+kWSEwLuixgPbBHKVUD7AQek4VRIebHmsIszjb3crC2E6WM44KTkVVfXmt2ULLOQvfOMKCX5rpp7x/hG89dIt1h45N3V1Puc/PMmRba+qxt/xMfWpaZ7ohs4gIjjTPVwuih2k66BgLcsbYAgFur8yOfCuJ5qaaDUFiza8X8LYhCAlrQaa27tdZ5WutKrXUl8CJwr9b64PwMWYhrW3Whl96hII8fb2RVfuaMZ7RLRX5WOhlOOzXmkQFjt/1PV5lZ6fKLow3cu7GYXE8at1bns/dieySdM9N2g+uKsznd2DPhFv2nXm4mzW7jZrNax2okMtEs/YUL7aQ5bDPaLzAbiWpBJ4RYIKOVLn1Jm24BI31U4XdTY6ZcZh3QzVp0reGdN1UCxox5OBiOdK2aaUBfX5LNYCDEpdbxC6Naa357upmdK/xkphvVR8vzPFT4jU8F8ey92M62ityYHbbzISEt6MbcvnvuwxJCTGR1VD33fNafL4RKv4fzLcZGqbnO0DeX57DePM/mhuU+3Gl2DtV2kpnumHEgXV9iVBOdbOxmlVkSGgyFudjaz/7L7dS0D8TU5CuluGVNPj86UMfgSIiMtNHf1zsU4OWrPXz49tUzGsNsyE5RIZKM1+WMnEcy3x/h51tFnpsrHYOEwnrWAd3vSeMtO8r4xF2jfVzTHfbIBp6Zzs4BVi7LJN1h42RDD8PBEF984gzrP/8Ed/7b83zu0VMUZbvGNQG/xfxU8FJNR8zttWZKaVXB9OvrZ0ta0AmRhK4rymJgJMjySQ6uSgZVfg8joTCNXYOjzS1mGNCVUvzjG64fd/ut1fn89nTzrAK6w27juiIvz51r5YULbZxp6uW1G4u5tXoZ64uzWb4sc1zt/3rzZM/zLX2R3DpAnVkjP93z5+dCAroQSeiTd1fT3jcS94zwZGKd/FjbPkD3YAC7TeFJS0ye+ZY1xkLlZBUuk1lf4uW/X6wjPyud77xrG7dWF0x6vdGE2hFZE7BYM/TpNOSeKwnoQiShlflZrMxf7FHMndVko6a9nx5zl2ii3qQKs128dmPxrMs633VTJT53Gve/Yvm0jiZWSlGV56GmPTag13X04/ekzeuGIosEdCHEoinIcuFy2qhp65/xtv/p+PJbxtVzTNvK/Cw+8qo1M/qZSr+Hw3WxRwDUtg9QvgCzc5BFUSHEIrLZFBU+DzVmymWm+fOlpjLPQ2PXYEzDjdr2ASoWIH8OEtCFEIuswu+mNirlksyq8tyE9ej57MPBEI3dg5T7F2bxWgK6EGJRVeV5qO0YoHMg+QP66Pk0RkCv7xxEa2SGLoS4NlT4PYwEw1zpHJhR+7mlqMosI7UqXeoWsMIFJKALIRaZ1ax6NictLjU57jRy3E4um5Uu1sFjS2ZRdDot6JRSH1FKnVZKHVdKPa2UGt9FVggh4qiM2hzlXYDSvvlW6fdEZui1HQO40+wsm6ceomNNZ4ZutaDbCGwC7lJK7RxzzRFgm9b6euAR4J8TOkohRMoq9LpIcxihKNln6GCkXaJTLuU+94JtAEtICzqt9bNaa+sg4BcxGmEIIcSUjNJFIyWRCgG90u+hsXuIoUCI2o6BBcufQ4Ja0I1xP/DrCR5HWtAJIcax0i4pEdCjdr/WdQxEjjdYCHNuQRdNKfU2YBvwxQkeR1rQCSHGsRZGk31jEYxWuuy/1MFIMLwgh3JZEtGCDgCl1O3ApzG6FQ0nZHRCiGvC6oIslDK6GCU769PGHrNp9EKmXKYs+lRKLQMCWuuuqBZ0XxhzzWbgG8BdWuvJW18LIcQYr99cQnWhl3yva+qLlzivy4nfk8a+S+0AVPiWVsplOi3ovghkAj9VSh1VSj02T+MVQqQgh93GhtLsxR5GwlTleRgKhHHYFMU5C/cmlZAWdFrr2xM8LiGESFqVeR4O1nZSkpuBw75w+zdlp6gQQiSYtTC6kBUuIAFdCCESzjqka6EO5bJIQBdCiASzatEXssIFJKALIUTCVRd6+YvdK3j19UUL+nuT+6xKIYRYguw2xcfvql7w3yszdCGESBES0IUQIkVIQBdCiBQhAV0IIVKEBHQhhEgREtCFECJFSEAXQogUIQFdCCFShNJaT33VfPxipVqB2ln+eB7QlsDhJItr8Xlfi88Zrs3nfS0+Z5j5867QWsdt+bZoAX0ulFIHtdbbFnscC+1afN7X4nOGa/N5X4vPGRL7vCXlIoQQKUICuhBCpIhkDejfXOwBLJJr8Xlfi88Zrs3nfS0+Z0jg807KHLoQQojxknWGLoQQYgwJ6EIIkSKSLqArpe5SSp1VSl1QSn1yscczH5RSZUqpZ5VSp5VSp5RSHzRv9ymlfquUOm/+N3exxzoflFJ2pdQRpdTj5vdVSqn95mv+E6VU2mKPMZGUUjlKqUeUUmeUUi8rpW68Fl5rpdSHzX/fJ5VSP1JKuVLxtVZKfUcp1aKUOhl1W9zXVxm+ZD7/40qpLTP5XUkV0JVSduArwN3AWuAtSqm1izuqeREEPqq1XgvsBP7SfJ6fBJ7WWq8Cnja/T0UfBF6O+v4LwL9qrVcCncD9izKq+fPvwG+01tXARoznntKvtVKqBPgrYJvWej1gB/6Y1HytHwLuGnPbRK/v3cAq888DwNdm8ouSKqADO4ALWutLWusR4MfA6xZ5TAmntb6qtT5sft2L8T94CcZz/a552XeBP1yUAc4jpVQp8GrgW+b3CrgVeMS8JKWet1IqG7gZ+DaA1npEa93FNfBaY7TAzFBKOQA3cJUUfK211s8DHWNunuj1fR3wPW14EchRSk27MWmyBfQS4ErU9/XmbSlLKVUJbAb2AwVa66vmXU1AwWKNax79G/BxIGx+7we6tNZB8/tUe82rgFbgv8w007eUUh5S/LXWWjcA/wLUYQTybuAQqf1aR5vo9Z1TjEu2gH5NUUplAv8DfEhr3RN9nzbqTVOq5lQp9RqgRWt9aLHHsoAcwBbga1rrzUA/Y9IrKfpa52LMRquAYsDD+LTENSGRr2+yBfQGoCzq+1LztpSjlHJiBPMfaK1/Zt7cbH38Mv/bsljjmye7gHuVUjUY6bRbMfLLOebHcki917weqNda7ze/fwQjwKf6a307cFlr3aq1DgA/w3j9U/m1jjbR6zunGJdsAf0lYJW5Ep6GsYjy2CKPKeHMvPG3gZe11g9G3fUY8E7z63cCjy702OaT1vpTWutSrXUlxmv7jNb6rcCzwJvMy1LqeWutm4ArSqk15k23AadJ8dcaI9WyUynlNv+9W887ZV/rMSZ6fR8D3mFWu+wEuqNSM1PTWifVH+Ae4BxwEfj0Yo9nnp7jKzA+gh0Hjpp/7sHIJz8NnAeeAnyLPdZ5/DvYDTxufr0cOABcAH4KpC/2+BL8XDcBB83X+xdA7rXwWgN/B5wBTgLfB9JT8bUGfoSxThDA+ER2/0SvL6AwKvkuAicwqoCm/btk678QQqSIZEu5CCGEmIAEdCGESBES0IUQIkVIQBdCiBQhAV0IIVKEBHQhhEgREtCFECJF/H+wFoy2g8gsJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate=0.01\n",
    "n_iters = 10000\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "# def trainIters(encoder=None, decoder= None, n_iters = None, print_every=1000, plot_every=100, learning_rate=0.01, encoder_optimizer = None, decoder_optimizer=None):\n",
    " \n",
    "trainIters(encoder = encoder1, decoder = attn_decoder1, n_iters = n_iters, print_every=500, encoder_optimizer = encoder_optimizer,  decoder_optimizer=decoder_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "romance-thunder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> рдо рдЕрдкрдиреА рдпрд╛рддрд░рд╛ рдХреА рджрд┐рд╢рд╛ рдХреЛ рдЙрдЬрд╛рдЧрд░ рдХрд░рди рдХ рд▓рд┐рдП рд╕рд╢рд░реА рд░рд╛рдЗрдирд╣рд╛рд░рдЯ рдХрд╛ рдЖрднрд╛рд░реА рд╣ редтАЭ\n",
      "= i am thankful to mrs . rinehart for highlighting the direction of our journey . тАЭ\n",
      "< i am thankful to to the people for the . . . . . . <EOS>\n",
      "\n",
      "> рдЬреЛ рд╣рдорд╛рд░ рд░рд╛рд╖тАНрдЯрд░реАрдп рдФрд░ рдХрд╖рддрд░реАрдп рд╡рд┐рдХрд╛рд╕ рдХреА рдПрдХ рдкрд░рд┐рд╕рдкрддрддрд┐ рд╣ ред\n",
      "= they are an asset in our national and regional development .\n",
      "< they are a to in of . . <EOS>\n",
      "\n",
      "> рдордЭ рдЗрд╕ рдмрд╛рдд рдХреА рдкрд░рд╕рдитАНрдирддрд╛ рд╣ рдХрд┐ рднрд╛рд░рдд рдо рд╕тАНрдЯрд╛рд░рдЯрдЕрдк рдХ рд▓рд┐рдП рдХтАНрд╡рд╛рд▓рдХрд╛рдо рди 150 рдорд┐рд▓рд┐рдпрди рдЕрдорд░рд┐рдХреА рдбреЙрд▓рд░ рдХреА рд╡рд┐рддрддреАрдп рд╕рд╣рд╛рдпрддрд╛ рдХреА рдШреЛрд╖рдг рдХреА рд╣ ред\n",
      "= i am delighted that qualcomm announced a fund of usd 150 million for startups in india .\n",
      "< i am happy that that the the of the of has for the has in . the . <EOS>\n",
      "\n",
      "> рдп рд▓реЛрдЧ рдЖрдкрдХреА рддрд╛рдХрдд рд╣ ред\n",
      "= they are your strength .\n",
      "< they are a of of . . . . . <EOS>\n",
      "\n",
      "> рдордЭ рдЖрдк рд╕рднреА рдХреЛ рдпрд╣ рд╕рдЪрд┐рдд рдХрд░рдд рд╣рдП рд╣рд░рд╖ рд╣реЛ рд░рд╣рд╛ рд╣ рдХрд┐ рдЖрдЬ рднрд╛рд░рдд рд╡рд╢рд╡рд┐рдХ рд╡рд┐рдХрд╛рд╕ рдХ рдПрдХ рдирдП рдЗрдЬрди рдХ рд░рдк рдо рдпреЛрдЧрджрд╛рди рдХрд░рди рдХреЛ рддрдпрд╛рд░ рд╣ ред\n",
      "= i am happy to tell you that today india is poised to contribute as a new engine of global growth .\n",
      "< i am happy that the be of of the of in . of the the of in <EOS>\n",
      "\n",
      "> рдо рдЗрд╕рдХ рд╕рдорджрдз рдЗрддрд┐рд╣рд╛рд╕ рд╕ рдЕрд╡рдЧрдд рд╣ ред\n",
      "= i am conscious of its rich history .\n",
      "< i am also happy that the . of . . <EOS>\n",
      "\n",
      "> рд╣рдо рдЗрд╕ рдмрд╛рдд рд╕ рдкрд░реА рддрд░рд╣ рдЕрд╡рдЧрдд рд╣ рдХрд┐ рдЬрдм рд╕ рд╣реЛрди рд╡рд╛рд▓рд╛ рдЦрд░рдЪ рд╣рдорд╢рд╛ рд╕ рдорд╣рд┐рд▓рд╛рдУ рдХреА рд╕рдордп рдкрд░ рд╕рд╡рд╛рд╕рдердп рд╕рдмрдзреА рджрдЦрд░рдЦ рдФрд░ рд╕рд╡рд╛рдУ рддрдХ рдкрд╣рдЪ рдХреА рд░рд╛рд╣ рдо рдкрд░рдордЦ рд░рдХрд╛рд╡рдЯ рд░рд╣рд╛ рд╣ ред\n",
      "= we are fully aware that out-of-pocket expenses remain a key barrier for women to access timely health care and services .\n",
      "< we are also that that that that the a of in to a of in . <EOS>\n",
      "\n",
      "> рд╣рдо рджреЛрдиреЛ рджрд╢реЛ рдХреА рдПрдХ рд╣реА рд╕реЛрдЪ рд╣ рдХрд┐ рд╣рдорд╛рд░ рд╡рдЬрдЮрд╛рдирд┐рдХ рдФрд░ рдЕрдирд╕рдзрд╛рдирдХрд░рддрд╛ рдПрдХ рд╕рд╛рде рдорд┐рд▓рдХрд░ рдЙрдкрд░реЛрдХтАНрдд рдХрд╖рддрд░реЛ рдо рджреЛрдиреЛ рджрд╢реЛ рдХ рд╣рд┐рдд рдо рд╕реЛрд▓тАНрдпрд╢рди рд╡рд┐рдХрд╕рд┐рдд, рдирд┐рд░рдорд┐рдд рдФрд░ рдХрд╛рд░рдпрд╛рдирд╡рд┐рдд рдХрд░рдЧ ред\n",
      "= we are of one view that together our scientists and researchers would develop, build and implement mutually beneficial solutions in the field .\n",
      "< we are confident that our and and to in and . and . . <EOS>\n",
      "\n",
      "> рдордЭ рд╡рд┐рд╢рд╡рд╛рд╕ рд╣ рдХрд┐ рдЕрдЧрд▓ рд╕рдордитАНрд╡рдпрдХ рджрд╢ рдХ рд░рдк рдо рд╡рд┐рдпрддрдирд╛рдо рдЗрди рд╕рдмрдзреЛ рдХреЛ рдирдИ рдКрдЪрд╛рдЗрдпреЛ рдкрд░ рд▓ рдЬрд╛рди рдо рдЕрдкрдирд╛ рдкрд░рд╛ рд╕рд╣рдпреЛрдЧ рджрдЧрд╛ ред\n",
      "= i am also confident that vietnam, as the next country-coordinator, will take our relationship to an even higher plane .\n",
      "< i am confident that this the will will be a the in to . . <EOS>\n",
      "\n",
      "> рд╣рдо рдЬрд╛рдирдХрд╛рд░реА, рдирд┐рд╡рд╢, рдФрд░ рдирд╡рд╛рдЪрд╛рд░ рдкрд░рд╛рдктАНрдд рдХрд░рди рдХрд╛ рдкрд░рд╕тАНрддрд╛рд╡ рдХрд░рдд рд╣ ред\n",
      "= we are open to ideas, investments and innovations:\n",
      "< we are all to all the of and . . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "increased-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 141)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x: len(x.split())).max(), df['en'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "million-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                False\n",
       "1                                                False\n",
       "2                                                False\n",
       "3                                                False\n",
       "4                                                False\n",
       "                             ...                      \n",
       "56826    рдкреНрд░рдзрд╛рди рдЖрдпреБрдХреНтАНрдд, рдбреАрдбреАрдП рд╕рджрд╕реНтАНрдп рд╕рдЪрд┐рд╡ рдХреЗ рд░реВрдк рдореЗрдВред\n",
       "56827                                            False\n",
       "56828                                            False\n",
       "56829                                            False\n",
       "56830                                            False\n",
       "Name: hi, Length: 56831, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x : x if len(x.split(' ')) <= 10  else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "limiting-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'рдкреНрд░рдзрд╛рди'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4cc74fb1dda6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m output_words, attentions = evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     encoder1, attn_decoder1, \"рдкреНрд░рдзрд╛рди рдЖрдпреБрдХреНтАНрдд, рдбреАрдбреАрдП рд╕рджрд╕реНтАНрдп рд╕рдЪрд┐рд╡ рдХреЗ рд░реВрдк рдореЗрдВред\")\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-097b00d341f5>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36mtensorFromSentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36mindexesFromSentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'рдкреНрд░рдзрд╛рди'"
     ]
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"рдкреНрд░рдзрд╛рди рдЖрдпреБрдХреНтАНрдд, рдбреАрдбреАрдП рд╕рджрд╕реНтАНрдп рд╕рдЪрд┐рд╡ рдХреЗ рд░реВрдк рдореЗрдВред\")\n",
    "plt.matshow(attentions.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "competitive-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рд╕рдорд┐рддрд┐ рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ рджрд┐рд▓реН\\u200dрд▓реА рдХреА рдЕрдирд╛рдзрд┐рдХреГрдд рдХрд╛рд▓реЛрдирд┐рдпреЛрдВ рдХреЗ рдирд┐рд╡рд╛рд╕рд┐рдпреЛрдВ рдХреЛ рд╕реНрд╡рд╛рдорд┐рддреНрд╡ рдкреНрд░рджрд╛рди рдХрд░рдиреЗ рдпрд╛ рд╣рд╕реНрддрд╛рдВрддрд░рдг/рдЧрд┐рд░рд╡реА рд░рдЦрдиреЗ рдХреЗ рдЕрдзрд┐рдХрд╛рд░ рдкреНрд░рджрд╛рди рдХрд░рдиреЗ рдХрд╛ рдорд╛рд░реНрдЧ рдкреНрд░рд╢рд╕реН\\u200dрдд рдХрд░реЗрдВрдЧреАред'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'][56829]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-roads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "simplified-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fabulous-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/disk_ext/nlp/seq2seq_torch/model_nmt_torch.pth'\n",
    "torch.save({\n",
    "            'modelA_state_dict': encoder1.state_dict(),\n",
    "            'modelB_state_dict': attn_decoder1.state_dict(), \n",
    "            'optimizerA_state_dict':encoder_optimizer.state_dict(),\n",
    "            'optimizerB_state_dict':decoder_optimizer.state_dict(), \n",
    "            'loss': 3.3227,\n",
    "            'epoch': 1000\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "absolute-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "encoder1.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "attn_decoder1.load_state_dict(checkpoint['modelB_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "closed-midwest",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-b7816889c371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "encoder_optimizer.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "encoder_optimizer.load_state_dict(checkpoint['optimizerB_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "introductory-prison",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-cf782920bd70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "honey-athletics",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c9d777c3aef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "encoder1.eval()\n",
    "attn_decoder1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-spectrum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
