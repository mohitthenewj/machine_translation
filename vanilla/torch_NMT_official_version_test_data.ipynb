{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naval-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crazy-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 11 09:04:15 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00002231:00:00.0 Off |                    0 |\r\n",
      "| N/A   50C    P0    73W / 149W |    876MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      7754      C   ...onda/envs/text/bin/python      484MiB |\r\n",
      "|    0   N/A  N/A     55696      C   ...onda/envs/text/bin/python      386MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "senior-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sixth-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?।])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./data/%s-%s.tsv' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bound-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "mediterranean-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "def trainIters(encoder=None, decoder= None, n_iters = None, print_every=1000, plot_every=100, learning_rate=0.01, encoder_optimizer = None, decoder_optimizer=None):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "oriented-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "sonic-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "active-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # help(pd.read_csv)\n",
    "\n",
    "# df = pd.read_csv('./data/hi-en.tsv', sep = '\\t', names=['en', 'hi'])\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "blond-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x : len(x.split('।'))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "opposite-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 56831 sentence pairs\n",
      "Trimmed to 1340 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "hi 3990\n",
      "eng 3850\n",
      "['आप हमारी जनसख\\u200dया और हमारी जररत स भी अवगत ह ।', 'you are also familiar with our demography and our demand .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'hi', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "educated-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 24s (- 7m 38s) (500 5%) 4.7306\n",
      "0m 48s (- 7m 13s) (1000 10%) 4.5652\n",
      "1m 11s (- 6m 45s) (1500 15%) 4.2484\n",
      "1m 34s (- 6m 19s) (2000 20%) 4.1869\n",
      "1m 58s (- 5m 54s) (2500 25%) 3.9928\n",
      "2m 21s (- 5m 30s) (3000 30%) 4.1208\n",
      "2m 45s (- 5m 7s) (3500 35%) 3.9841\n",
      "3m 9s (- 4m 43s) (4000 40%) 3.8031\n",
      "3m 31s (- 4m 18s) (4500 45%) 3.8553\n",
      "3m 55s (- 3m 55s) (5000 50%) 3.7164\n",
      "4m 18s (- 3m 31s) (5500 55%) 3.7141\n",
      "4m 42s (- 3m 8s) (6000 60%) 3.6709\n",
      "5m 4s (- 2m 44s) (6500 65%) 3.4921\n",
      "5m 29s (- 2m 21s) (7000 70%) 3.6004\n",
      "5m 53s (- 1m 57s) (7500 75%) 3.5944\n",
      "6m 17s (- 1m 34s) (8000 80%) 3.4464\n",
      "6m 41s (- 1m 10s) (8500 85%) 3.4925\n",
      "7m 5s (- 0m 47s) (9000 90%) 3.4365\n",
      "7m 30s (- 0m 23s) (9500 95%) 3.3688\n",
      "7m 54s (- 0m 0s) (10000 100%) 3.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate=0.01\n",
    "n_iters = 10000\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "# def trainIters(encoder=None, decoder= None, n_iters = None, print_every=1000, plot_every=100, learning_rate=0.01, encoder_optimizer = None, decoder_optimizer=None):\n",
    " \n",
    "trainIters(encoder = encoder1, decoder = attn_decoder1, n_iters = n_iters, print_every=500, encoder_optimizer = encoder_optimizer,  decoder_optimizer=decoder_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "romance-thunder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> म अपनी यातरा की दिशा को उजागर करन क लिए सशरी राइनहारट का आभारी ह ।”\n",
      "= i am thankful to mrs . rinehart for highlighting the direction of our journey . ”\n",
      "< i am thankful to to the people for the . . . . . . <EOS>\n",
      "\n",
      "> जो हमार राष‍टरीय और कषतरीय विकास की एक परिसपतति ह ।\n",
      "= they are an asset in our national and regional development .\n",
      "< they are a to in of . . <EOS>\n",
      "\n",
      "> मझ इस बात की परसन‍नता ह कि भारत म स‍टारटअप क लिए क‍वालकाम न 150 मिलियन अमरिकी डॉलर की विततीय सहायता की घोषण की ह ।\n",
      "= i am delighted that qualcomm announced a fund of usd 150 million for startups in india .\n",
      "< i am happy that that the the of the of has for the has in . the . <EOS>\n",
      "\n",
      "> य लोग आपकी ताकत ह ।\n",
      "= they are your strength .\n",
      "< they are a of of . . . . . <EOS>\n",
      "\n",
      "> मझ आप सभी को यह सचित करत हए हरष हो रहा ह कि आज भारत वशविक विकास क एक नए इजन क रप म योगदान करन को तयार ह ।\n",
      "= i am happy to tell you that today india is poised to contribute as a new engine of global growth .\n",
      "< i am happy that the be of of the of in . of the the of in <EOS>\n",
      "\n",
      "> म इसक समदध इतिहास स अवगत ह ।\n",
      "= i am conscious of its rich history .\n",
      "< i am also happy that the . of . . <EOS>\n",
      "\n",
      "> हम इस बात स परी तरह अवगत ह कि जब स होन वाला खरच हमशा स महिलाओ की समय पर सवासथय सबधी दखरख और सवाओ तक पहच की राह म परमख रकावट रहा ह ।\n",
      "= we are fully aware that out-of-pocket expenses remain a key barrier for women to access timely health care and services .\n",
      "< we are also that that that that the a of in to a of in . <EOS>\n",
      "\n",
      "> हम दोनो दशो की एक ही सोच ह कि हमार वजञानिक और अनसधानकरता एक साथ मिलकर उपरोक‍त कषतरो म दोनो दशो क हित म सोल‍यशन विकसित, निरमित और कारयानवित करग ।\n",
      "= we are of one view that together our scientists and researchers would develop, build and implement mutually beneficial solutions in the field .\n",
      "< we are confident that our and and to in and . and . . <EOS>\n",
      "\n",
      "> मझ विशवास ह कि अगल समन‍वयक दश क रप म वियतनाम इन सबधो को नई ऊचाइयो पर ल जान म अपना परा सहयोग दगा ।\n",
      "= i am also confident that vietnam, as the next country-coordinator, will take our relationship to an even higher plane .\n",
      "< i am confident that this the will will be a the in to . . <EOS>\n",
      "\n",
      "> हम जानकारी, निवश, और नवाचार पराप‍त करन का परस‍ताव करत ह ।\n",
      "= we are open to ideas, investments and innovations:\n",
      "< we are all to all the of and . . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "increased-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 141)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x: len(x.split())).max(), df['en'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "million-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                False\n",
       "1                                                False\n",
       "2                                                False\n",
       "3                                                False\n",
       "4                                                False\n",
       "                             ...                      \n",
       "56826    प्रधान आयुक्‍त, डीडीए सदस्‍य सचिव के रूप में।\n",
       "56827                                            False\n",
       "56828                                            False\n",
       "56829                                            False\n",
       "56830                                            False\n",
       "Name: hi, Length: 56831, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'].apply(lambda x : x if len(x.split(' ')) <= 10  else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "limiting-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'प्रधान'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4cc74fb1dda6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m output_words, attentions = evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     encoder1, attn_decoder1, \"प्रधान आयुक्‍त, डीडीए सदस्‍य सचिव के रूप में।\")\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-097b00d341f5>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36mtensorFromSentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36mindexesFromSentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f8856d30d4b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexesFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'प्रधान'"
     ]
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"प्रधान आयुक्‍त, डीडीए सदस्‍य सचिव के रूप में।\")\n",
    "plt.matshow(attentions.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "competitive-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'समिति की सिफारिशें दिल्\\u200dली की अनाधिकृत कालोनियों के निवासियों को स्वामित्व प्रदान करने या हस्तांतरण/गिरवी रखने के अधिकार प्रदान करने का मार्ग प्रशस्\\u200dत करेंगी।'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hi'][56829]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-roads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "simplified-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fabulous-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/disk_ext/nlp/seq2seq_torch/model_nmt_torch.pth'\n",
    "torch.save({\n",
    "            'modelA_state_dict': encoder1.state_dict(),\n",
    "            'modelB_state_dict': attn_decoder1.state_dict(), \n",
    "            'optimizerA_state_dict':encoder_optimizer.state_dict(),\n",
    "            'optimizerB_state_dict':decoder_optimizer.state_dict(), \n",
    "            'loss': 3.3227,\n",
    "            'epoch': 1000\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "absolute-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "encoder1.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "attn_decoder1.load_state_dict(checkpoint['modelB_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "closed-midwest",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-b7816889c371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "encoder_optimizer.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "encoder_optimizer.load_state_dict(checkpoint['optimizerB_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "introductory-prison",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-cf782920bd70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "honey-athletics",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c9d777c3aef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerA_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerB_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/text/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    116\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "encoder1.eval()\n",
    "attn_decoder1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-spectrum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
